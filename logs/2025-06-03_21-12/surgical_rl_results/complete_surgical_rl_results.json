{
  "method_1_il_baseline": {
    "method": "Imitation Learning (Baseline)",
    "approach": "Supervised learning on expert demonstrations",
    "model_path": "logs/2025-06-03_21-12/checkpoints/supervised_best_epoch_1.pt",
    "evaluation": {
      "mAP": 0.2378136989585344,
      "exact_match_accuracy": 0.34582599506868617,
      "hamming_accuracy": 0.9886350827756252,
      "evaluation_samples": 56780
    },
    "status": "success",
    "training_time": "recorded",
    "key_insight": "Optimized for action mimicry - should excel at traditional metrics"
  },
  "method_2_rl_world_model": {
    "method": "RL with World Model Simulation",
    "approach": "World model as environment simulator for RL training",
    "world_model_path": "logs/2025-06-03_21-12/checkpoints/supervised_best_epoch_1.pt",
    "rl_models": {
      "ppo": {
        "algorithm": "PPO_Final_Fixed",
        "mean_reward": 103.11468799999997,
        "std_reward": 22.327511213136066,
        "model_path": "logs/2025-06-03_21-12/rl_training/ppo_model_final_fixed.zip",
        "status": "success",
        "episode_stats": {
          "avg_length": 50.0,
          "avg_reward": 118.96968391423152,
          "episodes": 100,
          "last_length": 50,
          "last_reward": 71.40505376344086
        },
        "training_timesteps": 10000
      },
      "a2c": {
        "algorithm": "A2C_Final_Fixed",
        "mean_reward": 88.5492204,
        "std_reward": 24.405445466676657,
        "model_path": "logs/2025-06-03_21-12/rl_training/a2c_model_final_fixed.zip",
        "status": "success",
        "episode_stats": {
          "avg_length": 50.0,
          "avg_reward": 110.33573633177201,
          "episodes": 100,
          "last_length": 50,
          "last_reward": 134.89505154639176
        },
        "training_timesteps": 10000
      }
    },
    "evaluation": {
      "ppo": {
        "mean_reward": 103.11468799999997,
        "std_reward": 22.327511213136066,
        "training_successful": true,
        "model_available": true
      },
      "a2c": {
        "mean_reward": 88.5492204,
        "std_reward": 24.405445466676657,
        "training_successful": true,
        "model_available": true
      }
    },
    "status": "success",
    "key_insight": "Can explore beyond expert demonstrations using learned dynamics"
  },
  "method_3_rl_offline_videos": {
    "method": "RL with Offline Video Episodes",
    "approach": "Direct RL on video sequences without world model simulation",
    "rl_models": {
      "ppo": {
        "algorithm": "PPO_DirectVideo",
        "approach": "Direct RL on video sequences (no world model)",
        "mean_reward": 80.9772062,
        "std_reward": 6.473793753447741,
        "model_path": "logs/2025-06-03_21-12/direct_video_rl/ppo_direct_video.zip",
        "status": "success",
        "training_timesteps": 10000,
        "uses_world_model": false,
        "uses_real_frames": true,
        "episode_stats": {
          "avg_length": 50.0,
          "avg_reward": 58.352422751755576,
          "episodes": 100,
          "last_length": 50,
          "last_reward": 78.73742574257426,
          "using_real_frames": true
        }
      },
      "a2c": {
        "algorithm": "A2C_DirectVideo",
        "approach": "Direct RL on video sequences (no world model)",
        "mean_reward": 73.91818359999999,
        "std_reward": 5.495350885775196,
        "model_path": "logs/2025-06-03_21-12/direct_video_rl/a2c_direct_video.zip",
        "status": "success",
        "training_timesteps": 10000,
        "uses_world_model": false,
        "uses_real_frames": true,
        "episode_stats": {
          "avg_length": 50.0,
          "avg_reward": 55.59593766678564,
          "episodes": 100,
          "last_length": 50,
          "last_reward": 66.19044673539517,
          "using_real_frames": true
        }
      }
    },
    "evaluation": {
      "ppo": {
        "mean_reward": 80.9772062,
        "std_reward": 6.473793753447741,
        "episode_stats": {
          "avg_length": 50.0,
          "avg_reward": 58.352422751755576,
          "episodes": 100,
          "last_length": 50,
          "last_reward": 78.73742574257426,
          "using_real_frames": true
        },
        "training_successful": true,
        "model_available": true,
        "uses_real_frames": true,
        "uses_world_model": false
      },
      "a2c": {
        "mean_reward": 73.91818359999999,
        "std_reward": 5.495350885775196,
        "episode_stats": {
          "avg_length": 50.0,
          "avg_reward": 55.59593766678564,
          "episodes": 100,
          "last_length": 50,
          "last_reward": 66.19044673539517,
          "using_real_frames": true
        },
        "training_successful": true,
        "model_available": true,
        "uses_real_frames": true,
        "uses_world_model": false
      }
    },
    "status": "success",
    "key_insight": "Limited to existing video data, no simulation capability",
    "trainer_save_dir": "logs/2025-06-03_21-12/direct_video_rl"
  },
  "comparative_analysis": {
    "evaluation_approaches": {
      "traditional": "Action matching (IL-biased)",
      "clinical": "Surgical outcomes (fair comparison)"
    },
    "method_results": {
      "Imitation_Learning": {
        "method_name": "IL",
        "traditional_metrics": {
          "mAP": 0.2378136989585344,
          "exact_match_accuracy": 0.34582599506868617,
          "hamming_accuracy": 0.9886350827756252,
          "top_1_accuracy": 0.5348468647368823,
          "top_3_accuracy": 0.778927671274727,
          "top_5_accuracy": 0.8065187504773543,
          "precision": 0.6356152512998267,
          "recall": 0.4864058355437666,
          "f1_score": 0.5510894064613073,
          "action_similarity": 0.9886350827756252
        },
        "clinical_metrics": {
          "phase_completion_rate": 0.014788732394366197,
          "safety_score": 1.0,
          "efficiency_score": 0.0,
          "procedure_success_rate": 0.4059154929577465,
          "complication_rate": 0.0,
          "innovation_score": 0.0,
          "overall_clinical_score": 0.3348802816901409
        },
        "evaluation_notes": "IL naturally excels at traditional metrics (action matching)"
      },
      "RL_RL_WM_PPO": {
        "method_name": "RL_RL_WM_PPO",
        "traditional_metrics": {
          "mAP": 0.109375,
          "exact_match_accuracy": 0.1328125,
          "hamming_accuracy": 0.987265625,
          "top_1_accuracy": 0.0,
          "top_3_accuracy": 0.0,
          "top_5_accuracy": 0.0,
          "precision": 0.0,
          "recall": 0.0,
          "f1_score": 0.0,
          "action_similarity": 0.987265625
        },
        "clinical_metrics": {
          "phase_completion_rate": 0.014788732394366197,
          "safety_score": 1.0,
          "efficiency_score": 0.08312786192321242,
          "procedure_success_rate": 0.42254106534238894,
          "complication_rate": 0.0,
          "innovation_score": 0.0,
          "overall_clinical_score": 0.3548309685517118
        },
        "evaluation_notes": "RL optimized for outcomes, may differ from expert actions"
      },
      "RL_RL_WM_A2C": {
        "method_name": "RL_RL_WM_A2C",
        "traditional_metrics": {
          "mAP": 0.109375,
          "exact_match_accuracy": 0.203125,
          "hamming_accuracy": 0.98796875,
          "top_1_accuracy": 0.0,
          "top_3_accuracy": 0.0,
          "top_5_accuracy": 0.0,
          "precision": 0.0,
          "recall": 0.0,
          "f1_score": 0.0,
          "action_similarity": 0.98796875
        },
        "clinical_metrics": {
          "phase_completion_rate": 0.014788732394366197,
          "safety_score": 1.0,
          "efficiency_score": 0.0,
          "procedure_success_rate": 0.4059154929577465,
          "complication_rate": 0.0,
          "innovation_score": 0.0,
          "overall_clinical_score": 0.3348802816901409
        },
        "evaluation_notes": "RL optimized for outcomes, may differ from expert actions"
      }
    },
    "bias_analysis": {
      "traditional_winner": "Imitation_Learning",
      "clinical_winner": "RL_RL_WM_PPO",
      "winner_changed": true,
      "traditional_scores": {
        "Imitation_Learning": 0.2378136989585344,
        "RL_RL_WM_PPO": 0.109375,
        "RL_RL_WM_A2C": 0.109375
      },
      "clinical_scores": {
        "Imitation_Learning": 0.3348802816901409,
        "RL_RL_WM_PPO": 0.3548309685517118,
        "RL_RL_WM_A2C": 0.3348802816901409
      }
    },
    "comparison_summary": {
      "traditional_comparison": {
        "results": [
          [
            "Imitation_Learning",
            0.2378136989585344
          ],
          [
            "RL_RL_WM_PPO",
            0.109375
          ],
          [
            "RL_RL_WM_A2C",
            0.109375
          ]
        ],
        "winner": "Imitation_Learning"
      },
      "clinical_comparison": {
        "results": [
          [
            "RL_RL_WM_PPO",
            0.3548309685517118
          ],
          [
            "Imitation_Learning",
            0.3348802816901409
          ],
          [
            "RL_RL_WM_A2C",
            0.3348802816901409
          ]
        ],
        "winner": "RL_RL_WM_PPO"
      }
    },
    "research_insights": {}
  },
  "model_paths": {
    "method1_il": "logs/2025-06-03_21-12/checkpoints/supervised_best_epoch_1.pt"
  },
  "config": {
    "debug": false,
    "training_mode": "supervised",
    "preprocess": {
      "extract_rewards": false,
      "rewards": {
        "imitation": {
          "action_distribution": true
        },
        "expert_knowledge": {
          "risk_score": true,
          "frame_risk_agg": "max"
        },
        "grounded": {
          "phase_progression": true,
          "global_progression": true,
          "phase_completion": true,
          "phase_transition": true
        }
      },
      "value": {
        "global_outcome": true
      }
    },
    "experiment": {
      "max_videos": 2,
      "train": {
        "max_videos": 2
      },
      "test": {
        "max_videos": 1
      },
      "dual_world_model": {
        "train": true,
        "inference": true,
        "best_model_path": null
      },
      "il_experiments": {
        "enabled": true,
        "il_model_path": "logs/2025-06-02_14-07-20/checkpoints/supervised_best_epoch_1.pt"
      },
      "rl_experiments": {
        "enabled": true,
        "run_after_supervised": true,
        "algorithms": [
          "ppo",
          "dqn"
        ],
        "timesteps": 10000,
        "eval_episodes": 20
      },
      "recognition": {
        "train": false,
        "inference": false
      },
      "world_model": {
        "train": false,
        "inference": false
      }
    },
    "training": {
      "epochs": 1,
      "batch_size": 16,
      "learning_rate": 0.0001,
      "log_every_n_steps": 100,
      "scheduler": {
        "type": "cosine",
        "warmup_steps": 1000
      },
      "weight_decay": 0.01,
      "gradient_clip_val": 1.0,
      "dropout": 0.1,
      "num_workers": 4,
      "pin_memory": true,
      "log_dir": "logs",
      "checkpoint_dir": "checkpoints",
      "eval_epoch_interval": 1,
      "save_model": true
    },
    "fair_evaluation": {
      "enabled": true,
      "include_traditional_metrics": true,
      "include_clinical_metrics": true,
      "clinical_outcome_weights": {
        "phase_progression": 2.0,
        "safety": 3.0,
        "efficiency": 1.5,
        "innovation": 0.5
      }
    },
    "rl_training": {
      "outcome_based_rewards": true,
      "rl_horizon": 50,
      "reward_mode": "dense",
      "normalize_rewards": true,
      "early_termination": true,
      "reward_weights": {
        "phase_completion": 1.0,
        "phase_initiation": 0.5,
        "phase_progression": 1.0,
        "global_progression": 0.8,
        "action_probability": 0.3,
        "risk_penalty": -0.5
      },
      "ppo": {
        "learning_rate": 0.0003,
        "n_steps": 2048,
        "batch_size": 64,
        "n_epochs": 10,
        "gamma": 0.99,
        "gae_lambda": 0.95,
        "clip_range": 0.2,
        "entropy_coef": 0.01,
        "value_coef": 0.5
      },
      "sac": {
        "learning_rate": 0.0003,
        "buffer_size": 100000,
        "learning_starts": 1000,
        "batch_size": 256,
        "tau": 0.005,
        "gamma": 0.99,
        "alpha": 0.2
      }
    },
    "evaluation": {
      "supervised": {
        "action_prediction": {
          "top_ks": [
            1,
            3,
            5,
            10
          ],
          "horizons": [
            1,
            3,
            5,
            10,
            15
          ],
          "temperature": 1.0,
          "nucleus_p": 0.9
        }
      },
      "rl": {
        "rollout_horizon": 15,
        "eval_horizons": [
          1,
          3,
          5,
          10,
          15
        ],
        "eval_episodes": 20,
        "use_best_actions": true
      },
      "comparison": {
        "statistical_tests": true,
        "significance_level": 0.05,
        "effect_size_threshold": 0.2
      },
      "world_model": {
        "use_memory": false,
        "max_horizon": 15,
        "overall_horizon": 1
      }
    },
    "data": {
      "context_length": 20,
      "train_shift": 1,
      "padding_value": 0.0,
      "max_horizon": 15,
      "paths": {
        "data_dir": "/home/maxboels/datasets/CholecT50",
        "class_labels_file_path": "./data/labels.json",
        "fold": 0,
        "metadata_file": "embeddings_f0_swin_bas_129_phase_complet_phase_transit_prog_prob_action_risk_glob_outcome.csv",
        "video_global_outcome_file": "embeddings_f0_swin_bas_129_with_enhanced_global_metrics.csv"
      },
      "risk_score_path": null,
      "max_videos": 2,
      "frame_risk_agg": "max"
    },
    "models": {
      "dual_world_model": {
        "hidden_dim": 768,
        "embedding_dim": 1024,
        "action_embedding_dim": 128,
        "n_layer": 6,
        "max_length": 1024,
        "dropout": 0.1,
        "enable_autoregressive_prediction": true,
        "enable_rl_prediction": true,
        "enable_reward_prediction": true,
        "num_action_classes": 100,
        "num_phase_classes": 7,
        "loss_weights": {
          "state": 1.0,
          "action": 1.0,
          "reward": 0.5,
          "phase": 0.3
        }
      },
      "rl_agents": {
        "ppo": {
          "hidden_dim": 256,
          "learning_rate": 0.0003,
          "clip_ratio": 0.2,
          "entropy_coef": 0.01,
          "value_coef": 0.5
        },
        "sac": {
          "hidden_dim": 256,
          "learning_rate": 0.0003,
          "tau": 0.005,
          "alpha": 0.2
        }
      },
      "recognition": {
        "transformer": {
          "embedding_dim": 1024,
          "hidden_dim": 768,
          "num_action_classes": 100,
          "num_instrument_classes": 6,
          "dropout": 0.1,
          "num_heads": 8,
          "num_layers": 2
        }
      },
      "world_model": {
        "hidden_dim": 768,
        "embedding_dim": 1024,
        "action_embedding_dim": 100,
        "n_layer": 6,
        "use_head": true,
        "action_conditioning": true,
        "imitation_learning": true,
        "action_learning": true,
        "phase_learning": true,
        "reward_learning": true,
        "num_action_classes": 100,
        "num_phase_classes": 7,
        "num_outcomes": 1,
        "targets_dims": {
          "_z": 512,
          "_a": 100,
          "_r": 1,
          "_q": 1,
          "_R": 1
        },
        "target_heads": [
          "_a"
        ],
        "loss_weights": {
          "w_z": 1.0,
          "w_a": 1.0,
          "w_r": 1.0,
          "w_q": null,
          "w_R": null
        }
      }
    },
    "supervised_learning": {
      "augmentation": {
        "noise_std": 0.01,
        "action_dropout": 0.1,
        "temporal_shift": 0.1
      },
      "autoregressive": {
        "context_length": 20,
        "prediction_horizon": 15,
        "use_teacher_forcing": true,
        "teacher_forcing_ratio": 0.8
      },
      "action_prediction": {
        "loss_type": "bce",
        "class_weights": null,
        "label_smoothing": 0.1
      }
    },
    "research_comparison": {
      "methods": [
        {
          "name": "Imitation Learning",
          "type": "supervised",
          "model_type": "dual_world_model",
          "mode": "supervised"
        },
        {
          "name": "PPO (World Model)",
          "type": "rl",
          "algorithm": "ppo",
          "world_model": true
        },
        {
          "name": "SAC (World Model)",
          "type": "rl",
          "algorithm": "sac",
          "world_model": true
        },
        {
          "name": "Random Baseline",
          "type": "baseline",
          "algorithm": "random"
        }
      ],
      "evaluation_metrics": {
        "primary": "mAP",
        "secondary": [
          "top_1_accuracy",
          "top_3_accuracy",
          "f1_score",
          "exact_match"
        ],
        "clinical": [
          "critical_action_performance",
          "phase_awareness",
          "risk_assessment"
        ],
        "planning": [
          "trajectory_coherence",
          "horizon_degradation",
          "planning_efficiency"
        ]
      },
      "statistical_analysis": {
        "perform_tests": true,
        "tests": [
          "t_test",
          "wilcoxon",
          "bootstrap"
        ],
        "multiple_comparison_correction": "bonferroni",
        "confidence_level": 0.95
      }
    },
    "advanced": {
      "mixed_precision": true,
      "gradient_accumulation_steps": 1,
      "find_unused_parameters": false,
      "distributed": false,
      "world_size": 1,
      "rank": 0,
      "seed": 42,
      "deterministic": false,
      "wandb": {
        "enabled": false,
        "project": "surgical_world_model_comparison",
        "entity": null,
        "tags": [
          "world_model",
          "surgical_robotics",
          "il_vs_rl"
        ]
      },
      "analysis": {
        "save_attention_maps": false,
        "save_hidden_states": false,
        "analyze_action_patterns": true,
        "generate_trajectory_videos": false
      }
    },
    "hardware": {
      "gpu_memory_fraction": 0.9,
      "allow_growth": true,
      "num_threads": 4,
      "prefetch_factor": 2,
      "persistent_workers": true
    },
    "training_phases": {
      "supervised": {
        "epochs": 1,
        "learning_rate": 0.0001,
        "focus_on": [
          "state_prediction",
          "action_prediction"
        ],
        "loss_weights": {
          "state": 1.0,
          "action": 1.0,
          "reward": 0.1,
          "phase": 0.1
        }
      },
      "rl": {
        "episodes": 2000,
        "learning_rate": 5e-05,
        "focus_on": [
          "state_prediction",
          "reward_prediction"
        ],
        "loss_weights": {
          "state": 1.0,
          "action": 0.5,
          "reward": 1.0,
          "phase": 0.3
        }
      },
      "mixed": {
        "epochs": 1,
        "learning_rate": 2e-05,
        "alternating_batches": true,
        "supervised_ratio": 0.7
      }
    },
    "results": {
      "save_predictions": true,
      "create_visualizations": true,
      "generate_report": true,
      "latex_tables": true,
      "visualization": {
        "create_interactive": true,
        "save_trajectories": true,
        "plot_attention": false,
        "plot_performance_curves": true
      },
      "report": {
        "include_statistical_analysis": true,
        "include_clinical_insights": true,
        "include_method_comparison": true,
        "format": [
          "markdown",
          "latex",
          "html"
        ]
      }
    }
  },
  "experiment_metadata": {
    "start_time": "2025-06-03T21:12:52.436691",
    "device": "cuda",
    "config_path": "config_local_debug.yaml"
  }
}