{
  "train_state_loss": [
    1.2084299240793501
  ],
  "train_reward_phase_progression_loss": [
    3.012932871069227
  ],
  "train_reward_phase_completion_loss": [
    2.7658828582082475
  ],
  "train_reward_phase_initiation_loss": [
    2.3102172783442905
  ],
  "train_reward_safety_loss": [
    6.863882984433856
  ],
  "train_reward_efficiency_loss": [
    2.344351828098297
  ],
  "train_reward_action_probability_loss": [
    3.307227909564972
  ],
  "train_reward_risk_penalty_loss": [
    2.7450216582843234
  ],
  "train_total_reward_loss": [
    3.3356455734797885
  ],
  "train_phase_loss": [
    2.061644290174757
  ],
  "train_total_loss": [
    11.327403102602277
  ],
  "val_state_loss": [
    1.0049343271688982
  ],
  "val_reward_phase_progression_loss": [
    1.9131280183792114
  ],
  "val_reward_phase_completion_loss": [
    1.7260859391906045
  ],
  "val_reward_phase_initiation_loss": [
    0.9986498897725885
  ],
  "val_reward_safety_loss": [
    1.2284767031669617
  ],
  "val_reward_efficiency_loss": [
    0.8285250528292223
  ],
  "val_reward_action_probability_loss": [
    0.9684474224394019
  ],
  "val_reward_risk_penalty_loss": [
    1.2581303444775669
  ],
  "val_total_reward_loss": [
    1.2744919928637417
  ],
  "val_phase_loss": [
    2.451769454912706
  ],
  "val_total_loss": [
    6.7896716811440205
  ]
}