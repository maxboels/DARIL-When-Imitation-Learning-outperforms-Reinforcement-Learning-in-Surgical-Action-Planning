{
  "experiment_name": "fixed_rl_2025-06-13_19-28-06",
  "config": {
    "debug": false,
    "training_mode": "rl",
    "preprocess": {
      "extract_rewards": false,
      "rewards": {
        "grounded": {
          "phase_completion": true,
          "phase_transition": true,
          "phase_progression": true,
          "global_progression": true
        },
        "imitation": {
          "action_distribution": true
        },
        "expert_knowledge": {
          "risk_score": true,
          "frame_risk_agg": "max"
        }
      }
    },
    "experiment": {
      "max_videos": 50,
      "train": {
        "max_videos": 2
      },
      "test": {
        "max_videos": 2
      },
      "dual_world_model": {
        "train": true,
        "best_model_path": null
      },
      "autoregressive_il": {
        "enabled": false,
        "il_model_path": "results/2025-06-10_19-45-51/logs/checkpoints/autoregressive_il_best_epoch_1.pt"
      },
      "world_model": {
        "enabled": true,
        "wm_model_path": "results/fixed_rl_2025-06-13_16-30-50/logs/checkpoints/world_model_final.pt"
      },
      "rl_experiments": {
        "enabled": true,
        "eval_episodes": 10
      }
    },
    "training": {
      "epochs": 2,
      "batch_size": 16,
      "learning_rate": 0.0001,
      "log_every_n_steps": 50,
      "scheduler": {
        "type": "cosine",
        "warmup_steps": 100
      },
      "weight_decay": 0.01,
      "gradient_clip_val": 1.0,
      "dropout": 0.1,
      "num_workers": 4,
      "pin_memory": true,
      "log_dir": "logs",
      "checkpoint_dir": "checkpoints",
      "eval_epoch_interval": 1,
      "save_model": true
    },
    "evaluation": {
      "prediction_horizon": 15,
      "supervised": {
        "action_prediction": true
      },
      "rl": {
        "rollout_horizon": 15,
        "use_best_actions": true
      },
      "comparison": {
        "statistical_tests": true,
        "effect_size_threshold": 0.2
      },
      "world_model": {
        "use_memory": false,
        "overall_horizon": 1
      }
    },
    "rl_training": {
      "outcome_based_rewards": true,
      "rl_horizon": 30,
      "reward_mode": "dense",
      "normalize_rewards": true,
      "early_termination": true,
      "timesteps": 1000,
      "reward_weights": {
        "expert_matching": 10.0,
        "action_sparsity": 1.0,
        "world_model_rewards": 0.5,
        "completion_bonus": 5.0,
        "consistency_bonus": 1.0,
        "phase_completion": 1.0,
        "risk_penalty": -0.5
      },
      "ppo": {
        "learning_rate": "5e-5",
        "n_steps": 512,
        "batch_size": 64,
        "n_epochs": 10,
        "gamma": 0.95,
        "gae_lambda": 0.9,
        "clip_range": 0.1,
        "ent_coef": 0.05,
        "vf_coef": 0.5,
        "max_grad_norm": 0.5
      },
      "a2c": {
        "learning_rate": "1e-4",
        "n_steps": 32,
        "gamma": 0.95,
        "gae_lambda": 0.9,
        "ent_coef": 0.05,
        "vf_coef": 0.25,
        "max_grad_norm": 0.5
      }
    },
    "data": {
      "context_length": 20,
      "train_shift": 1,
      "padding_value": 0.0,
      "max_horizon": 15,
      "paths": {
        "data_dir": "/home/maxboels/datasets/CholecT50",
        "class_labels_file_path": "./data/labels.json",
        "fold": 0,
        "metadata_file": "embeddings_f0_swin_bas_129_phase_complet_phase_transit_prog_prob_action_risk_glob_outcome.csv",
        "video_global_outcome_file": "embeddings_f0_swin_bas_129_with_enhanced_global_metrics.csv"
      },
      "frame_risk_agg": "max"
    },
    "models": {
      "autoregressive_il": {
        "hidden_dim": 768,
        "embedding_dim": 1024,
        "n_layer": 6,
        "num_action_classes": 100,
        "num_phase_classes": 7,
        "dropout": 0.1,
        "max_length": 1024
      },
      "conditional_world_model": {
        "hidden_dim": 768,
        "embedding_dim": 1024,
        "action_embedding_dim": 128,
        "n_layer": 6,
        "num_action_classes": 100,
        "num_phase_classes": 7,
        "dropout": 0.1,
        "max_sequence_length": 512
      }
    },
    "fair_evaluation": {
      "enabled": true,
      "include_traditional_metrics": true,
      "include_clinical_metrics": true,
      "clinical_outcome_weights": {
        "phase_progression": 2.0,
        "innovation": 0.5
      }
    },
    "supervised_learning": {
      "data_augmentation": false
    },
    "research_comparison": {
      "methods": [
        "autoregressive_il",
        "conditional_world_model",
        "direct_video_rl"
      ]
    },
    "advanced": {
      "mixed_precision": false
    },
    "hardware": {
      "persistent_workers": true
    },
    "rl_debugging": {
      "enabled": true,
      "save_training_curves": true,
      "monitor_expert_matching": true,
      "log_action_distributions": true,
      "convergence_analysis": true,
      "episode_log_frequency": 10,
      "eval_frequency": 1000,
      "reward_improvement_threshold": 0.1,
      "expert_matching_threshold": 0.5,
      "debug_dir": "rl_debug",
      "plot_dir": "rl_plots"
    }
  },
  "timestamp": "2025-06-13_19-28-06",
  "results_dir": "results/fixed_rl_2025-06-13_19-28-06",
  "method_1_autoregressive_il": {
    "status": "skipped",
    "reason": "Autoregressive IL disabled in config"
  },
  "method_2_conditional_world_model": {
    "status": "success",
    "world_model_path": "results/fixed_rl_2025-06-13_19-28-06/logs/checkpoints/world_model_best_epoch_2.pt",
    "world_model_evaluation": {
      "overall_metrics": {
        "state_loss": 0.41404252839423916,
        "reward_risk_penalty_loss": 1.4773242401568485,
        "reward_phase_completion_loss": 0.013168038846682825,
        "reward_phase_initiation_loss": 0.017963919392041915,
        "reward_phase_progression_loss": 0.09051156411363301,
        "reward_action_probability_loss": 0.03831576780939577,
        "total_reward_loss": 0.32745671013567423,
        "phase_loss": 1.1483700234877614,
        "total_loss": 2.471226013721251
      },
      "model_type": "ConditionalWorldModel",
      "evaluation_summary": {
        "best_metric": "state_loss",
        "best_value": 0.41404252839423916,
        "strength": "Action-conditioned state-reward prediction",
        "architecture": "ConditionalWorldModel with action conditioning"
      }
    },
    "world_model_pretrained": false,
    "rl_models": {
      "world_model_ppo": {
        "algorithm": "PPO_WorldModel",
        "mean_reward": -424.0473277,
        "std_reward": 171.59616536106367,
        "model_path": "results/fixed_rl_2025-06-13_19-28-06/logs/rl_training/ppo_world_model_final.zip",
        "status": "success",
        "training_timesteps": 1000,
        "episode_stats": {
          "avg_length": 30.0,
          "avg_reward": -720.0,
          "std_reward": 0.0,
          "episodes": 34,
          "last_reward": -720.0,
          "reward_trend": "stable",
          "avg_expert_matching": 0.6830043948613929,
          "std_expert_matching": 0.008329535407752584,
          "last_expert_matching": 0.6779310344827586
        },
        "monitoring_data": [
          {
            "timestep": 1000,
            "mean_reward": -423.85433759999995,
            "std_reward": 171.40657818785908
          }
        ],
        "expert_matching_enabled": true,
        "reward_design": "expert_demonstration_matching",
        "optimal_threshold": 0.3,
        "threshold_map": 0.375
      },
      "direct_video_ppo": {
        "algorithm": "PPO_DirectVideo",
        "status": "failed",
        "error": "No module named 'rl_environment'"
      }
    },
    "model_type": "ConditionalWorldModel",
    "approach": "FIXED: Action-conditioned world model + improved RL (TRAINED)",
    "method_description": "World model-based RL with fixed rewards and debugging (trained WM)",
    "improvements": [
      "Expert demonstration matching rewards",
      "Proper action space handling",
      "Enhanced monitoring and debugging",
      "Optimized hyperparameters",
      "Trained world model from scratch"
    ]
  },
  "method_3_direct_video_rl": {
    "status": "success",
    "rl_models": {
      "ppo": {
        "algorithm": "PPO_DirectVideo",
        "approach": "Direct RL on video sequences (no world model)",
        "mean_reward": 48.0790452,
        "std_reward": 4.914626671796481,
        "model_path": "results/fixed_rl_2025-06-13_19-28-06/logs/direct_video_rl/ppo_direct_video.zip",
        "status": "success",
        "training_timesteps": 1000,
        "uses_world_model": false,
        "uses_real_frames": true,
        "simulation_based": false,
        "episode_stats": {
          "avg_length": 30.0,
          "avg_reward": 36.04021962060251,
          "episodes": 47,
          "last_length": 30,
          "last_reward": 53.22497695852534,
          "using_real_frames": true
        }
      },
      "a2c": {
        "algorithm": "A2C_DirectVideo",
        "approach": "Direct RL on video sequences (no world model)",
        "mean_reward": 46.179376000000005,
        "std_reward": 2.146000413687379,
        "model_path": "results/fixed_rl_2025-06-13_19-28-06/logs/direct_video_rl/a2c_direct_video.zip",
        "status": "success",
        "training_timesteps": 1000,
        "uses_world_model": false,
        "uses_real_frames": true,
        "simulation_based": false,
        "episode_stats": {
          "avg_length": 30.0,
          "avg_reward": 37.08798898352204,
          "episodes": 47,
          "last_length": 30,
          "last_reward": 42.86461538461538,
          "using_real_frames": true
        }
      }
    },
    "model_type": "DirectVideoRL",
    "approach": "FIXED: Direct RL on video sequences with improved rewards",
    "method_description": "Model-free RL on offline video episodes with fixed reward design",
    "improvements": [
      "Expert demonstration matching rewards",
      "Proper continuous action space [0,1]",
      "Better episode termination",
      "Meaningful reward functions"
    ]
  },
  "comprehensive_evaluation": {
    "evaluator": "<evaluation.integrated_evaluation.IntegratedEvaluationFramework object at 0x78d048723bf0>",
    "results": {
      "status": "success",
      "evaluation_type": "comprehensive_evaluation_with_proper_batches",
      "num_models": 3,
      "num_videos": 2,
      "horizon": 15,
      "video_results": {
        "VID02": {
          "video_id": "VID02",
          "evaluation_type": "comprehensive_fair_evaluation_with_proper_batches",
          "single_step_evaluation": {
            "WorldModelRL_world_model_ppo": {
              "metrics": {
                "mAP": 0.0628311257139544,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "28",
                  "subset_action_sparsity": 0.7021276595744681
                },
                "mAP_standard_with_null_verb": 0.6784147726924948,
                "mAP_present_only_with_null_verb": 0.05416109615439709,
                "mAP_freq_weighted_with_null_verb": 0.2790563123667317,
                "mAP_sample_wise_with_null_verb": 0.0923865024113352,
                "mAP_standard_all_actions": 0.6784147726924948,
                "mAP_present_only_all_actions": 0.05416109615439709,
                "mAP_freq_weighted_all_actions": 0.2790563123667317,
                "mAP_sample_wise_all_actions": 0.0923865024113352,
                "exact_match_with_null_verb": 0.07713983797111659,
                "hamming_accuracy_with_null_verb": 0.9856533990841846,
                "precision_with_null_verb": 0.4928266995420923,
                "recall_with_null_verb": 0.5,
                "f1_with_null_verb": 0.49638743576234595,
                "num_predictions": 2839,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "34",
                "action_sparsity_with_null_verb": 0.6599999999999999,
                "task": "single_step_action_prediction",
                "method_name": "WorldModelRL_world_model_ppo",
                "exclude_last_n": 6,
                "mAP_standard": 0.7208433140424545,
                "mAP_present_only": 0.0628311257139544,
                "mAP_freq_weighted": 0.2946714823317537,
                "exact_match": 0.11165903487143361,
                "hamming_accuracy": 0.9856332391537326,
                "precision": 0.4928166195768663,
                "recall": 0.5,
                "f1": 0.49638232263567705,
                "num_actions_total": 94,
                "num_actions_present": "28",
                "action_sparsity": 0.7021276595744681
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": false
            },
            "DirectVideoRL_ppo": {
              "metrics": {
                "mAP": 0.05945901849123593,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "28",
                  "subset_action_sparsity": 0.7021276595744681
                },
                "mAP_standard_with_null_verb": 0.6774711241398418,
                "mAP_present_only_with_null_verb": 0.051385659234829094,
                "mAP_freq_weighted_with_null_verb": 0.27960064272872154,
                "mAP_sample_wise_with_null_verb": 0.20742212850031075,
                "mAP_standard_all_actions": 0.6774711241398418,
                "mAP_present_only_all_actions": 0.051385659234829094,
                "mAP_freq_weighted_all_actions": 0.27960064272872154,
                "mAP_sample_wise_all_actions": 0.20742212850031075,
                "exact_match_with_null_verb": 0.07713983797111659,
                "hamming_accuracy_with_null_verb": 0.9856533990841846,
                "precision_with_null_verb": 0.4928266995420923,
                "recall_with_null_verb": 0.5,
                "f1_with_null_verb": 0.49638743576234595,
                "num_predictions": 2839,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "34",
                "action_sparsity_with_null_verb": 0.6599999999999999,
                "task": "single_step_action_prediction",
                "method_name": "DirectVideoRL_ppo",
                "exclude_last_n": 6,
                "mAP_standard": 0.7198388565718575,
                "mAP_present_only": 0.05945901849123593,
                "mAP_freq_weighted": 0.2954087593531596,
                "exact_match": 0.11165903487143361,
                "hamming_accuracy": 0.9856332391537326,
                "precision": 0.4928166195768663,
                "recall": 0.5,
                "f1": 0.49638232263567705,
                "num_actions_total": 94,
                "num_actions_present": "28",
                "action_sparsity": 0.7021276595744681
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": false
            },
            "DirectVideoRL_a2c": {
              "metrics": {
                "mAP": 0.05985152158088704,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "28",
                  "subset_action_sparsity": 0.7021276595744681
                },
                "mAP_standard_with_null_verb": 0.677838013665418,
                "mAP_present_only_with_null_verb": 0.052464746074758754,
                "mAP_freq_weighted_with_null_verb": 0.18544053054006807,
                "mAP_sample_wise_with_null_verb": 0.08719663465420537,
                "mAP_standard_all_actions": 0.677838013665418,
                "mAP_present_only_all_actions": 0.052464746074758754,
                "mAP_freq_weighted_all_actions": 0.18544053054006807,
                "mAP_sample_wise_all_actions": 0.08719663465420537,
                "exact_match_with_null_verb": 0.07713983797111659,
                "hamming_accuracy_with_null_verb": 0.9856533990841846,
                "precision_with_null_verb": 0.4928266995420923,
                "recall_with_null_verb": 0.5,
                "f1_with_null_verb": 0.49638743576234595,
                "num_predictions": 2839,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "34",
                "action_sparsity_with_null_verb": 0.6599999999999999,
                "task": "single_step_action_prediction",
                "method_name": "DirectVideoRL_a2c",
                "exclude_last_n": 6,
                "mAP_standard": 0.7199557723857962,
                "mAP_present_only": 0.05985152158088704,
                "mAP_freq_weighted": 0.1949620736289348,
                "exact_match": 0.11165903487143361,
                "hamming_accuracy": 0.9856332391537326,
                "precision": 0.4928166195768663,
                "recall": 0.5,
                "f1": 0.49638232263567705,
                "num_actions_total": 94,
                "num_actions_present": "28",
                "action_sparsity": 0.7021276595744681
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": false
            }
          },
          "planning_evaluation": {
            "WorldModelRL_world_model_ppo": {},
            "DirectVideoRL_ppo": {},
            "DirectVideoRL_a2c": {}
          },
          "summary": {
            "primary_comparison": {
              "WorldModelRL_world_model_ppo": {
                "mAP": 0.0628311257139544,
                "exact_match": 0.11165903487143361,
                "task": "single_step_action_prediction"
              },
              "DirectVideoRL_ppo": {
                "mAP": 0.05945901849123593,
                "exact_match": 0.11165903487143361,
                "task": "single_step_action_prediction"
              },
              "DirectVideoRL_a2c": {
                "mAP": 0.05985152158088704,
                "exact_match": 0.11165903487143361,
                "task": "single_step_action_prediction"
              }
            },
            "secondary_analysis": {},
            "overall_ranking": {},
            "paradigm_insights": {
              "fair_comparison_task": "single_step_action_prediction",
              "planning_analysis": "shows_method_specific_strengths",
              "evaluation_approach": "respects_training_paradigms"
            }
          },
          "fairness_report": {
            "evaluation_design": {
              "primary_evaluation": "single_step_fair_comparison",
              "secondary_evaluation": "method_specific_planning_analysis",
              "data_handling": "uses_dataloader_batches_like_training",
              "temporal_structure": "maintained_for_il_model",
              "ground_truth_leakage": "eliminated"
            },
            "method_fairness": {
              "AutoregressiveIL": "evaluated_with_proper_temporal_sequences",
              "WorldModelRL": "evaluated_with_consistent_batch_approach",
              "DirectVideoRL": "evaluated_with_consistent_batch_approach"
            },
            "data_integrity": {
              "temporal_context": "preserved_for_models_that_need_it",
              "batch_structure": "mirrors_training_approach",
              "evaluation_consistency": "matches_model_training_interface"
            },
            "comparison_validity": {
              "single_step_comparison": "valid_and_fair_with_proper_data_handling",
              "planning_comparison": "method_specific_respecting_capabilities",
              "overall_approach": "methodologically_sound_and_consistent_with_training"
            }
          }
        },
        "VID06": {
          "video_id": "VID06",
          "evaluation_type": "comprehensive_fair_evaluation_with_proper_batches",
          "single_step_evaluation": {
            "WorldModelRL_world_model_ppo": {
              "metrics": {
                "mAP": 0.08717632804024562,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "26",
                  "subset_action_sparsity": 0.7234042553191489
                },
                "mAP_standard_with_null_verb": 0.7243711585305825,
                "mAP_present_only_with_null_verb": 0.08123719510194216,
                "mAP_freq_weighted_with_null_verb": 0.46370729273787165,
                "mAP_sample_wise_with_null_verb": 0.12799453414727324,
                "mAP_standard_all_actions": 0.7243711585305825,
                "mAP_present_only_all_actions": 0.08123719510194216,
                "mAP_freq_weighted_all_actions": 0.46370729273787165,
                "mAP_sample_wise_all_actions": 0.12799453414727324,
                "exact_match_with_null_verb": 0.030190431955411056,
                "hamming_accuracy_with_null_verb": 0.9825963771481654,
                "precision_with_null_verb": 0.4912981885740827,
                "recall_with_null_verb": 0.5,
                "f1_with_null_verb": 0.4956109011767517,
                "num_predictions": 2153,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "30",
                "action_sparsity_with_null_verb": 0.7,
                "task": "single_step_action_prediction",
                "method_name": "WorldModelRL_world_model_ppo",
                "exclude_last_n": 6,
                "mAP_standard": 0.7475168566919828,
                "mAP_present_only": 0.08717632804024562,
                "mAP_freq_weighted": 0.4942729288931215,
                "exact_match": 0.04412447747329308,
                "hamming_accuracy": 0.9828443240999694,
                "precision": 0.4914221620499847,
                "recall": 0.5,
                "f1": 0.4956739730669936,
                "num_actions_total": 94,
                "num_actions_present": "26",
                "action_sparsity": 0.7234042553191489
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": false
            },
            "DirectVideoRL_ppo": {
              "metrics": {
                "mAP": 0.07383276007906184,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "26",
                  "subset_action_sparsity": 0.7234042553191489
                },
                "mAP_standard_with_null_verb": 0.7208488290829473,
                "mAP_present_only_with_null_verb": 0.06949609694315735,
                "mAP_freq_weighted_with_null_verb": 0.404860437572357,
                "mAP_sample_wise_with_null_verb": 0.44823313911330515,
                "mAP_standard_all_actions": 0.7208488290829473,
                "mAP_present_only_all_actions": 0.06949609694315735,
                "mAP_freq_weighted_all_actions": 0.404860437572357,
                "mAP_sample_wise_all_actions": 0.44823313911330515,
                "exact_match_with_null_verb": 0.030190431955411056,
                "hamming_accuracy_with_null_verb": 0.9825963771481654,
                "precision_with_null_verb": 0.4912981885740827,
                "recall_with_null_verb": 0.5,
                "f1_with_null_verb": 0.4956109011767517,
                "num_predictions": 2153,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "30",
                "action_sparsity_with_null_verb": 0.7,
                "task": "single_step_action_prediction",
                "method_name": "DirectVideoRL_ppo",
                "exclude_last_n": 6,
                "mAP_standard": 0.7438260825750597,
                "mAP_present_only": 0.07383276007906184,
                "mAP_freq_weighted": 0.43136123883616834,
                "exact_match": 0.04412447747329308,
                "hamming_accuracy": 0.9828443240999694,
                "precision": 0.4914221620499847,
                "recall": 0.5,
                "f1": 0.4956739730669936,
                "num_actions_total": 94,
                "num_actions_present": "26",
                "action_sparsity": 0.7234042553191489
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": false
            },
            "DirectVideoRL_a2c": {
              "metrics": {
                "mAP": 0.08359516770485995,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "26",
                  "subset_action_sparsity": 0.7234042553191489
                },
                "mAP_standard_with_null_verb": 0.7247502418693001,
                "mAP_present_only_with_null_verb": 0.08250080623100028,
                "mAP_freq_weighted_with_null_verb": 0.3291107554691754,
                "mAP_sample_wise_with_null_verb": 0.10320973562161531,
                "mAP_standard_all_actions": 0.7247502418693001,
                "mAP_present_only_all_actions": 0.08250080623100028,
                "mAP_freq_weighted_all_actions": 0.3291107554691754,
                "mAP_sample_wise_all_actions": 0.10320973562161531,
                "exact_match_with_null_verb": 0.030190431955411056,
                "hamming_accuracy_with_null_verb": 0.9825963771481654,
                "precision_with_null_verb": 0.4912981885740827,
                "recall_with_null_verb": 0.5,
                "f1_with_null_verb": 0.4956109011767517,
                "num_predictions": 2153,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "30",
                "action_sparsity_with_null_verb": 0.7,
                "task": "single_step_action_prediction",
                "method_name": "DirectVideoRL_a2c",
                "exclude_last_n": 6,
                "mAP_standard": 0.7465263229821953,
                "mAP_present_only": 0.08359516770485995,
                "mAP_freq_weighted": 0.34692069852768875,
                "exact_match": 0.04412447747329308,
                "hamming_accuracy": 0.9828443240999694,
                "precision": 0.4914221620499847,
                "recall": 0.5,
                "f1": 0.4956739730669936,
                "num_actions_total": 94,
                "num_actions_present": "26",
                "action_sparsity": 0.7234042553191489
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": false
            }
          },
          "planning_evaluation": {
            "WorldModelRL_world_model_ppo": {},
            "DirectVideoRL_ppo": {},
            "DirectVideoRL_a2c": {}
          },
          "summary": {
            "primary_comparison": {
              "WorldModelRL_world_model_ppo": {
                "mAP": 0.08717632804024562,
                "exact_match": 0.04412447747329308,
                "task": "single_step_action_prediction"
              },
              "DirectVideoRL_ppo": {
                "mAP": 0.07383276007906184,
                "exact_match": 0.04412447747329308,
                "task": "single_step_action_prediction"
              },
              "DirectVideoRL_a2c": {
                "mAP": 0.08359516770485995,
                "exact_match": 0.04412447747329308,
                "task": "single_step_action_prediction"
              }
            },
            "secondary_analysis": {},
            "overall_ranking": {},
            "paradigm_insights": {
              "fair_comparison_task": "single_step_action_prediction",
              "planning_analysis": "shows_method_specific_strengths",
              "evaluation_approach": "respects_training_paradigms"
            }
          },
          "fairness_report": {
            "evaluation_design": {
              "primary_evaluation": "single_step_fair_comparison",
              "secondary_evaluation": "method_specific_planning_analysis",
              "data_handling": "uses_dataloader_batches_like_training",
              "temporal_structure": "maintained_for_il_model",
              "ground_truth_leakage": "eliminated"
            },
            "method_fairness": {
              "AutoregressiveIL": "evaluated_with_proper_temporal_sequences",
              "WorldModelRL": "evaluated_with_consistent_batch_approach",
              "DirectVideoRL": "evaluated_with_consistent_batch_approach"
            },
            "data_integrity": {
              "temporal_context": "preserved_for_models_that_need_it",
              "batch_structure": "mirrors_training_approach",
              "evaluation_consistency": "matches_model_training_interface"
            },
            "comparison_validity": {
              "single_step_comparison": "valid_and_fair_with_proper_data_handling",
              "planning_comparison": "method_specific_respecting_capabilities",
              "overall_approach": "methodologically_sound_and_consistent_with_training"
            }
          }
        }
      },
      "aggregate_results": {
        "single_step_comparison": {
          "WorldModelRL_world_model_ppo": {
            "mean_mAP": 0.07500372687710001,
            "std_mAP": 0.012172601163145613,
            "mean_exact_match": 0.07789175617236335,
            "std_exact_match": 0.033767278699070265,
            "num_videos": 2,
            "evaluation_type": "single_step_fair_comparison"
          },
          "DirectVideoRL_a2c": {
            "mean_mAP": 0.0717233446428735,
            "std_mAP": 0.011871823061986454,
            "mean_exact_match": 0.07789175617236335,
            "std_exact_match": 0.033767278699070265,
            "num_videos": 2,
            "evaluation_type": "single_step_fair_comparison"
          },
          "DirectVideoRL_ppo": {
            "mean_mAP": 0.06664588928514889,
            "std_mAP": 0.007186870793912954,
            "mean_exact_match": 0.07789175617236335,
            "std_exact_match": 0.033767278699070265,
            "num_videos": 2,
            "evaluation_type": "single_step_fair_comparison"
          }
        },
        "planning_analysis": {},
        "method_rankings": {
          "single_step_ranking": [
            [
              "WorldModelRL_world_model_ppo",
              0.07500372687710001
            ],
            [
              "DirectVideoRL_a2c",
              0.0717233446428735
            ],
            [
              "DirectVideoRL_ppo",
              0.06664588928514889
            ]
          ],
          "planning_ranking": []
        }
      },
      "statistical_tests": {
        "WorldModelRL_world_model_ppo_vs_DirectVideoRL_a2c": {
          "t_statistic": 0.1929261467264568,
          "p_value": 0.8648325652600306,
          "cohens_d": 0.27283877323693695,
          "significant": "False",
          "mean_diff": 0.0032803822342265115,
          "method1_mean": 0.07500372687710001,
          "method2_mean": 0.0717233446428735
        },
        "WorldModelRL_world_model_ppo_vs_DirectVideoRL_ppo": {
          "t_statistic": 0.5912495602676741,
          "p_value": 0.6142765183946182,
          "cohens_d": 0.8361531468776732,
          "significant": "False",
          "mean_diff": 0.00835783759195112,
          "method1_mean": 0.07500372687710001,
          "method2_mean": 0.06664588928514889
        },
        "DirectVideoRL_a2c_vs_DirectVideoRL_ppo": {
          "t_statistic": 0.3658708314941356,
          "p_value": 0.7495363662770117,
          "cohens_d": 0.5174194919757279,
          "significant": "False",
          "mean_diff": 0.005077455357724608,
          "method1_mean": 0.0717233446428735,
          "method2_mean": 0.06664588928514889
        }
      },
      "evaluation_design": {
        "data_handling": "uses_dataloader_batches_like_training",
        "temporal_structure": "maintained_properly",
        "model_interfaces": "consistent_with_training",
        "primary_evaluation": "single_step_action_prediction_with_proper_context",
        "secondary_evaluation": "multi_step_planning_analysis",
        "fairness_approach": "respects_training_paradigms_and_data_structure"
      },
      "timestamp": "2025-06-13 19:29:12.959376"
    },
    "file_paths": {
      "evaluation": "results/fixed_rl_2025-06-13_19-28-06/integrated_evaluation/evaluation_results.json",
      "fair_comparison": "results/fixed_rl_2025-06-13_19-28-06/integrated_evaluation/fair_single_step_comparison.csv",
      "planning_analysis": "results/fixed_rl_2025-06-13_19-28-06/integrated_evaluation/planning_capability_analysis.csv"
    }
  }
}