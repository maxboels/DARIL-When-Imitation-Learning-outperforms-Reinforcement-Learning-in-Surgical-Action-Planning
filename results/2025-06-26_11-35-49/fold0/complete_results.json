{
  "experiment_name": "2025-06-26_11-35-49",
  "config": {
    "debug": false,
    "experiment": {
      "train": {
        "max_videos": 40
      },
      "test": {
        "max_videos": 10,
        "test_on_train": false
      },
      "autoregressive_il": {
        "enabled": true,
        "train": true,
        "evaluate": true,
        "il_model_path": null,
        "recognition": {
          "enabled": false,
          "ivt_map": 36.1
        }
      },
      "world_model": {
        "enabled": false,
        "wm_model_path": "results/fixed_rl_2025-06-13_19-22-25/logs/checkpoints/world_model_best_epoch_1.pt"
      },
      "rl_experiments": {
        "enabled": false,
        "eval_episodes": 10
      }
    },
    "training": {
      "epochs": 4,
      "batch_size": 16,
      "learning_rate": 3e-05,
      "log_every_n_steps": 50,
      "scheduler": {
        "type": "cosine",
        "warmup_steps": 100
      },
      "weight_decay": 0.01,
      "gradient_clip_val": 1.0,
      "dropout": 0.1,
      "num_workers": 4,
      "pin_memory": true,
      "log_dir": "logs",
      "checkpoint_dir": "checkpoints",
      "eval_epoch_interval": 1,
      "save_model": true
    },
    "evaluation": {
      "prediction_horizon": 15,
      "supervised": {
        "action_prediction": true
      },
      "rl": {
        "rollout_horizon": 15,
        "use_best_actions": true
      },
      "comparison": {
        "statistical_tests": true,
        "effect_size_threshold": 0.2
      },
      "world_model": {
        "use_memory": false,
        "overall_horizon": 1
      }
    },
    "rl_training": {
      "action_space_type": "continuous",
      "outcome_based_rewards": true,
      "rl_horizon": 30,
      "reward_mode": "dense",
      "normalize_rewards": true,
      "early_termination": true,
      "timesteps": 50000,
      "reward_weights": {
        "expert_matching": 10.0,
        "action_sparsity": 1.0,
        "world_model_rewards": 0.5,
        "completion_bonus": 5.0,
        "consistency_bonus": 1.0,
        "phase_completion": 1.0,
        "risk_penalty": -0.5
      },
      "ppo": {
        "learning_rate": "5e-5",
        "n_steps": 512,
        "batch_size": 64,
        "n_epochs": 10,
        "gamma": 0.95,
        "gae_lambda": 0.9,
        "clip_range": 0.1,
        "ent_coef": 0.05,
        "vf_coef": 0.5,
        "max_grad_norm": 0.5
      },
      "a2c": {
        "learning_rate": "1e-4",
        "n_steps": 32,
        "gamma": 0.95,
        "gae_lambda": 0.9,
        "ent_coef": 0.05,
        "vf_coef": 0.25,
        "max_grad_norm": 0.5
      }
    },
    "data": {
      "context_length": 20,
      "train_shift": 1,
      "padding_value": 0.0,
      "max_horizon": 15,
      "paths": {
        "data_dir": "/nfs/home/mboels/datasets/CholecT50",
        "class_labels_file_path": "./data/labels.json",
        "fold": 0,
        "metadata_file": "embeddings_f0_swin_bas_129_phase_complet_phase_transit_prog_prob_action_risk_glob_outcome.csv",
        "video_global_outcome_file": "embeddings_f1_swin_bas_129_with_enhanced_global_metrics.csv"
      },
      "frame_risk_agg": "max"
    },
    "training_mode": "rl",
    "preprocess": {
      "extract_rewards": false,
      "analyze_rewards": false,
      "rewards": {
        "grounded": {
          "phase_completion": true,
          "phase_transition": true,
          "phase_progression": true,
          "global_progression": true
        },
        "imitation": {
          "action_distribution": true
        },
        "expert_knowledge": {
          "risk_score": true,
          "frame_risk_agg": "max"
        }
      }
    },
    "models": {
      "autoregressive_il": {
        "hidden_dim": 768,
        "embedding_dim": 1024,
        "n_layer": 6,
        "num_action_classes": 100,
        "num_phase_classes": 7,
        "dropout": 0.1,
        "max_length": 1024
      },
      "conditional_world_model": {
        "hidden_dim": 512,
        "embedding_dim": 1024,
        "action_embedding_dim": 128,
        "n_layer": 4,
        "num_action_classes": 100,
        "num_phase_classes": 7,
        "dropout": 0.1,
        "max_sequence_length": 512
      }
    },
    "fair_evaluation": {
      "enabled": true,
      "include_traditional_metrics": true,
      "include_clinical_metrics": true,
      "clinical_outcome_weights": {
        "phase_progression": 2.0,
        "innovation": 0.5
      }
    },
    "supervised_learning": {
      "data_augmentation": false
    },
    "research_comparison": {
      "methods": [
        "autoregressive_il",
        "conditional_world_model",
        "direct_video_rl"
      ]
    },
    "advanced": {
      "mixed_precision": false
    },
    "hardware": {
      "persistent_workers": true
    },
    "rl_debugging": {
      "enabled": true,
      "save_training_curves": true,
      "monitor_expert_matching": true,
      "log_action_distributions": true,
      "convergence_analysis": true,
      "episode_log_frequency": 10,
      "eval_frequency": 1000,
      "reward_improvement_threshold": 0.1,
      "expert_matching_threshold": 0.5,
      "debug_dir": "rl_debug",
      "plot_dir": "rl_plots"
    }
  },
  "timestamp": "2025-06-26_11-35-49",
  "results_dir": "results/2025-06-26_11-35-49/fold0",
  "method_1_autoregressive_il": {
    "status": "success",
    "model_path": "results/2025-06-26_11-35-49/fold0/logs/checkpoints/autoregressive_il_best_epoch_1.pt",
    "model_type": "AutoregressiveIL",
    "approach": "Causal frame generation \u2192 action anticipation",
    "evaluation": {
      "overall_metrics": {
        "ivt_current_mAP": 0.350348106735549,
        "ivt_rec_i_mAP": 0.913993052472963,
        "ivt_rec_v_mAP": 0.7173132604732751,
        "ivt_rec_t_mAP": 0.5322551681302852,
        "ivt_rec_iv_mAP": 0.4293392168151872,
        "ivt_rec_it_mAP": 0.4335535187206386,
        "ivt_next_mAP": 0.2830151019180971,
        "ivt_i_mAP": 0.8773944850045786,
        "ivt_v_mAP": 0.66512208230382,
        "ivt_t_mAP": 0.5091006499399938,
        "ivt_iv_mAP": 0.3638033787881467,
        "ivt_it_mAP": 0.3741750328086159,
        "total_loss": 0.47376738292268594,
        "consistency_loss": 0.0021683282069955632,
        "action_loss": 0.03358681972358468,
        "frame_loss": 0.1640859511579041,
        "action_rec_loss": 0.04288652087936328,
        "phase_loss": 1.0191150726388944,
        "action_mAP": 0.47378119168447325,
        "action_mAP_standard": 0.8350408287538011,
        "action_mAP_freq_weighted": 0.7575291917623126,
        "action_exact_match": 0.46999577999671194,
        "action_hamming_accuracy": 0.9913121746342641,
        "action_precision": 0.874217799842054,
        "action_recall": 0.8151553803870814,
        "action_f1": 0.8416679424827762,
        "action_sparsity": 0.7308510638297873,
        "num_actions_present": 25.3,
        "action_mAP_with_null_verb": 0.4276072886670354,
        "action_exact_match_with_null_verb": 0.419631889054496,
        "action_sparsity_with_null_verb": 0.7030000000000001,
        "num_actions_total": 94.0,
        "num_actions_total_with_null_verb": 100.0,
        "action_mAP_std": 0.08984882293678319,
        "action_exact_match_std": 0.036947968908790055,
        "action_sparsity_std": 0.05729886387019247,
        "planning_1s_mAP": 0.22600061733111892,
        "planning_2s_mAP": 0.2240916159214069,
        "planning_3s_mAP": 0.21197919675364713,
        "planning_5s_mAP": 0.19421194416102275,
        "planning_available": true
      },
      "detailed_video_metrics": {
        "VID02": {
          "mAP": 0.43253052957391186,
          "mAP_info": {
            "calculated_from": "subset_excluding_last_classes_present_actions_only",
            "excluded_classes": 6,
            "subset_size": 94,
            "present_actions_in_subset": "28",
            "subset_action_sparsity": 0.7021276595744681
          },
          "mAP_standard_with_null_verb": 0.7318152247334068,
          "mAP_present_only_with_null_verb": 0.3876918374511963,
          "mAP_freq_weighted_with_null_verb": 0.7033258895239699,
          "mAP_sample_wise_with_null_verb": 0.7199898963468728,
          "mAP_standard_all_actions": 0.7318152247334068,
          "mAP_present_only_all_actions": 0.3876918374511963,
          "mAP_freq_weighted_all_actions": 0.7033258895239699,
          "mAP_sample_wise_all_actions": 0.7199898963468728,
          "exact_match_with_null_verb": 0.4008453680873547,
          "hamming_accuracy_with_null_verb": 0.9901162381120113,
          "precision_with_null_verb": 0.8469564106428293,
          "recall_with_null_verb": 0.7699767457686457,
          "f1_with_null_verb": 0.8034982876249539,
          "num_predictions": 2839,
          "num_actions_total_with_null_verb": 100,
          "num_actions_present_with_null_verb": "34",
          "action_sparsity_with_null_verb": 0.6599999999999999,
          "task": "single_step_action_prediction",
          "method_name": "AutoregressiveIL_video_VID02_epoch_-1",
          "exclude_last_n": 6,
          "mAP_standard": 0.7671367534901015,
          "mAP_present_only": 0.43253052957391186,
          "mAP_freq_weighted": 0.7273341986689579,
          "exact_match": 0.4339556181754139,
          "hamming_accuracy": 0.9906170137821978,
          "precision": 0.8576707432307813,
          "recall": 0.7807549420114153,
          "f1": 0.8144221896563892,
          "num_actions_total": 94,
          "num_actions_present": "28",
          "action_sparsity": 0.7021276595744681
        },
        "VID06": {
          "mAP": 0.47588323416516853,
          "mAP_info": {
            "calculated_from": "subset_excluding_last_classes_present_actions_only",
            "excluded_classes": 6,
            "subset_size": 94,
            "present_actions_in_subset": "26",
            "subset_action_sparsity": 0.7234042553191489
          },
          "mAP_standard_with_null_verb": 0.8224666449043836,
          "mAP_present_only_with_null_verb": 0.44155548301461217,
          "mAP_freq_weighted_with_null_verb": 0.7553120875276521,
          "mAP_sample_wise_with_null_verb": 0.8339462257365049,
          "mAP_standard_all_actions": 0.8224666449043836,
          "mAP_present_only_all_actions": 0.44155548301461217,
          "mAP_freq_weighted_all_actions": 0.7553120875276521,
          "mAP_sample_wise_all_actions": 0.8339462257365049,
          "exact_match_with_null_verb": 0.37111007895959125,
          "hamming_accuracy_with_null_verb": 0.9909150023223409,
          "precision_with_null_verb": 0.8985888557905144,
          "recall_with_null_verb": 0.814884550997309,
          "f1_with_null_verb": 0.8516355261879811,
          "num_predictions": 2153,
          "num_actions_total_with_null_verb": 100,
          "num_actions_present_with_null_verb": "30",
          "action_sparsity_with_null_verb": 0.7,
          "task": "single_step_action_prediction",
          "method_name": "AutoregressiveIL_video_VID06_epoch_-1",
          "exclude_last_n": 6,
          "mAP_standard": 0.8443932349818549,
          "mAP_present_only": 0.47588323416516853,
          "mAP_freq_weighted": 0.7929126373802678,
          "exact_match": 0.4528564793311658,
          "hamming_accuracy": 0.9917581603106995,
          "precision": 0.9021879393902308,
          "recall": 0.8380396475885743,
          "f1": 0.8672264943158567,
          "num_actions_total": 94,
          "num_actions_present": "26",
          "action_sparsity": 0.7234042553191489
        },
        "VID111": {
          "mAP": 0.45781293178650684,
          "mAP_info": {
            "calculated_from": "subset_excluding_last_classes_present_actions_only",
            "excluded_classes": 6,
            "subset_size": 94,
            "present_actions_in_subset": "25",
            "subset_action_sparsity": 0.7340425531914894
          },
          "mAP_standard_with_null_verb": 0.8308396465588455,
          "mAP_present_only_with_null_verb": 0.41668843640981207,
          "mAP_freq_weighted_with_null_verb": 0.5926137980343666,
          "mAP_sample_wise_with_null_verb": 0.6821733927624652,
          "mAP_standard_all_actions": 0.8308396465588455,
          "mAP_present_only_all_actions": 0.41668843640981207,
          "mAP_freq_weighted_all_actions": 0.5926137980343666,
          "mAP_sample_wise_all_actions": 0.6821733927624652,
          "exact_match_with_null_verb": 0.4428904428904429,
          "hamming_accuracy_with_null_verb": 0.9893193473193473,
          "precision_with_null_verb": 0.7844406583094321,
          "recall_with_null_verb": 0.7429968917219942,
          "f1_with_null_verb": 0.7620352689454709,
          "num_predictions": 2145,
          "num_actions_total_with_null_verb": 100,
          "num_actions_present_with_null_verb": "29",
          "action_sparsity_with_null_verb": 0.71,
          "task": "single_step_action_prediction",
          "method_name": "AutoregressiveIL_video_VID111_epoch_-1",
          "exclude_last_n": 6,
          "mAP_standard": 0.8558013116453476,
          "mAP_present_only": 0.45781293178650684,
          "mAP_freq_weighted": 0.6408211024364647,
          "exact_match": 0.503030303030303,
          "hamming_accuracy": 0.9909140504885185,
          "precision": 0.7920189377869902,
          "recall": 0.7857652399236956,
          "f1": 0.788857206222932,
          "num_actions_total": 94,
          "num_actions_present": "25",
          "action_sparsity": 0.7340425531914894
        },
        "VID14": {
          "mAP": 0.3435142294323908,
          "mAP_info": {
            "calculated_from": "subset_excluding_last_classes_present_actions_only",
            "excluded_classes": 6,
            "subset_size": 94,
            "present_actions_in_subset": "36",
            "subset_action_sparsity": 0.6170212765957447
          },
          "mAP_standard_with_null_verb": 0.7198466604555149,
          "mAP_present_only_with_null_verb": 0.3166991718427196,
          "mAP_freq_weighted_with_null_verb": 0.6799636170457116,
          "mAP_sample_wise_with_null_verb": 0.7569577481447641,
          "mAP_standard_all_actions": 0.7198466604555149,
          "mAP_present_only_all_actions": 0.3166991718427196,
          "mAP_freq_weighted_all_actions": 0.6799636170457116,
          "mAP_sample_wise_all_actions": 0.7569577481447641,
          "exact_match_with_null_verb": 0.40339578454332553,
          "hamming_accuracy_with_null_verb": 0.9900468384074942,
          "precision_with_null_verb": 0.8671185885263628,
          "recall_with_null_verb": 0.7727011935714618,
          "f1_with_null_verb": 0.8126951361114695,
          "num_predictions": 1708,
          "num_actions_total_with_null_verb": 100,
          "num_actions_present_with_null_verb": "41",
          "action_sparsity_with_null_verb": 0.5900000000000001,
          "task": "single_step_action_prediction",
          "method_name": "AutoregressiveIL_video_VID14_epoch_-1",
          "exclude_last_n": 6,
          "mAP_standard": 0.7485799176549581,
          "mAP_present_only": 0.3435142294323908,
          "mAP_freq_weighted": 0.7114905684401631,
          "exact_match": 0.4596018735362998,
          "hamming_accuracy": 0.9905575763615526,
          "precision": 0.8714270356825753,
          "recall": 0.7906867579347421,
          "f1": 0.8259579263126988,
          "num_actions_total": 94,
          "num_actions_present": "36",
          "action_sparsity": 0.6170212765957447
        },
        "VID23": {
          "mAP": 0.4113451318324169,
          "mAP_info": {
            "calculated_from": "subset_excluding_last_classes_present_actions_only",
            "excluded_classes": 6,
            "subset_size": 94,
            "present_actions_in_subset": "26",
            "subset_action_sparsity": 0.7234042553191489
          },
          "mAP_standard_with_null_verb": 0.7838473411622151,
          "mAP_present_only_with_null_verb": 0.3672494876200486,
          "mAP_freq_weighted_with_null_verb": 0.6453329207365701,
          "mAP_sample_wise_with_null_verb": 0.7444988372597846,
          "mAP_standard_all_actions": 0.7838473411622151,
          "mAP_present_only_all_actions": 0.3672494876200486,
          "mAP_freq_weighted_all_actions": 0.6453329207365701,
          "mAP_sample_wise_all_actions": 0.7444988372597846,
          "exact_match_with_null_verb": 0.3712538226299694,
          "hamming_accuracy_with_null_verb": 0.9893761467889908,
          "precision_with_null_verb": 0.8580084100761067,
          "recall_with_null_verb": 0.764681490908302,
          "f1_with_null_verb": 0.8040923355147471,
          "num_predictions": 1635,
          "num_actions_total_with_null_verb": 100,
          "num_actions_present_with_null_verb": "31",
          "action_sparsity_with_null_verb": 0.69,
          "task": "single_step_action_prediction",
          "method_name": "AutoregressiveIL_video_VID23_epoch_-1",
          "exclude_last_n": 6,
          "mAP_standard": 0.8159039726344984,
          "mAP_present_only": 0.4113451318324169,
          "mAP_freq_weighted": 0.6746699930928695,
          "exact_match": 0.4452599388379205,
          "hamming_accuracy": 0.9902466002993038,
          "precision": 0.8639780138410276,
          "recall": 0.7854498858722594,
          "f1": 0.8197947470711515,
          "num_actions_total": 94,
          "num_actions_present": "26",
          "action_sparsity": 0.7234042553191489
        },
        "VID25": {
          "mAP": 0.6270298513795706,
          "mAP_info": {
            "calculated_from": "subset_excluding_last_classes_present_actions_only",
            "excluded_classes": 6,
            "subset_size": 94,
            "present_actions_in_subset": "21",
            "subset_action_sparsity": 0.7765957446808511
          },
          "mAP_standard_with_null_verb": 0.8680832456334104,
          "mAP_present_only_with_null_verb": 0.5310894062823484,
          "mAP_freq_weighted_with_null_verb": 0.7701782886345565,
          "mAP_sample_wise_with_null_verb": 0.8078397098118959,
          "mAP_standard_all_actions": 0.8680832456334104,
          "mAP_present_only_all_actions": 0.5310894062823484,
          "mAP_freq_weighted_all_actions": 0.7701782886345565,
          "mAP_sample_wise_all_actions": 0.8078397098118959,
          "exact_match_with_null_verb": 0.39971817754814465,
          "hamming_accuracy_with_null_verb": 0.9909112259276656,
          "precision_with_null_verb": 0.8914364367823191,
          "recall_with_null_verb": 0.8065797581347143,
          "f1_with_null_verb": 0.8436578058773103,
          "num_predictions": 2129,
          "num_actions_total_with_null_verb": 100,
          "num_actions_present_with_null_verb": "26",
          "action_sparsity_with_null_verb": 0.74,
          "task": "single_step_action_prediction",
          "method_name": "AutoregressiveIL_video_VID25_epoch_-1",
          "exclude_last_n": 6,
          "mAP_standard": 0.9060385838188402,
          "mAP_present_only": 0.6270298513795706,
          "mAP_freq_weighted": 0.8094899038173027,
          "exact_match": 0.43964302489431656,
          "hamming_accuracy": 0.9915103484804573,
          "precision": 0.895087140527289,
          "recall": 0.8242477788942115,
          "f1": 0.8560493085832575,
          "num_actions_total": 94,
          "num_actions_present": "21",
          "action_sparsity": 0.7765957446808511
        },
        "VID50": {
          "mAP": 0.5251583050708625,
          "mAP_info": {
            "calculated_from": "subset_excluding_last_classes_present_actions_only",
            "excluded_classes": 6,
            "subset_size": 94,
            "present_actions_in_subset": "16",
            "subset_action_sparsity": 0.8297872340425532
          },
          "mAP_standard_with_null_verb": 0.9066563837898856,
          "mAP_present_only_with_null_verb": 0.4814243543882531,
          "mAP_freq_weighted_with_null_verb": 0.7750689422571913,
          "mAP_sample_wise_with_null_verb": 0.8438306748272417,
          "mAP_standard_all_actions": 0.9066563837898856,
          "mAP_present_only_all_actions": 0.4814243543882531,
          "mAP_freq_weighted_all_actions": 0.7750689422571913,
          "mAP_sample_wise_all_actions": 0.8438306748272417,
          "exact_match_with_null_verb": 0.4954296160877514,
          "hamming_accuracy_with_null_verb": 0.99172760511883,
          "precision_with_null_verb": 0.8870263039355455,
          "recall_with_null_verb": 0.845299463031805,
          "f1_with_null_verb": 0.8649283199149176,
          "num_predictions": 1094,
          "num_actions_total_with_null_verb": 100,
          "num_actions_present_with_null_verb": "18",
          "action_sparsity_with_null_verb": 0.8200000000000001,
          "task": "single_step_action_prediction",
          "method_name": "AutoregressiveIL_video_VID50_epoch_-1",
          "exclude_last_n": 6,
          "mAP_standard": 0.9191758817141893,
          "mAP_present_only": 0.5251583050708625,
          "mAP_freq_weighted": 0.8091311159588115,
          "exact_match": 0.5319926873857403,
          "hamming_accuracy": 0.9923664864444358,
          "precision": 0.8931242436419204,
          "recall": 0.8647022262258097,
          "f1": 0.8783595752876605,
          "num_actions_total": 94,
          "num_actions_present": "16",
          "action_sparsity": 0.8297872340425532
        },
        "VID51": {
          "mAP": 0.44299372445926705,
          "mAP_info": {
            "calculated_from": "subset_excluding_last_classes_present_actions_only",
            "excluded_classes": 6,
            "subset_size": 94,
            "present_actions_in_subset": "24",
            "subset_action_sparsity": 0.7446808510638299
          },
          "mAP_standard_with_null_verb": 0.7982555965860771,
          "mAP_present_only_with_null_verb": 0.4077779192623343,
          "mAP_freq_weighted_with_null_verb": 0.7089857139537983,
          "mAP_sample_wise_with_null_verb": 0.7653944463732768,
          "mAP_standard_all_actions": 0.7982555965860771,
          "mAP_present_only_all_actions": 0.4077779192623343,
          "mAP_freq_weighted_all_actions": 0.7089857139537983,
          "mAP_sample_wise_all_actions": 0.7653944463732768,
          "exact_match_with_null_verb": 0.37907608695652173,
          "hamming_accuracy_with_null_verb": 0.9900169836956522,
          "precision_with_null_verb": 0.8516117464109587,
          "recall_with_null_verb": 0.7865913098873232,
          "f1_with_null_verb": 0.8156681961283128,
          "num_predictions": 2944,
          "num_actions_total_with_null_verb": 100,
          "num_actions_present_with_null_verb": "29",
          "action_sparsity_with_null_verb": 0.71,
          "task": "single_step_action_prediction",
          "method_name": "AutoregressiveIL_video_VID51_epoch_-1",
          "exclude_last_n": 6,
          "mAP_standard": 0.8258707381598129,
          "mAP_present_only": 0.44299372445926705,
          "mAP_freq_weighted": 0.7507830342312393,
          "exact_match": 0.4470108695652174,
          "hamming_accuracy": 0.9911901595744681,
          "precision": 0.8670636930336423,
          "recall": 0.8027889690831764,
          "f1": 0.8317368765038052,
          "num_actions_total": 94,
          "num_actions_present": "24",
          "action_sparsity": 0.7446808510638299
        },
        "VID66": {
          "mAP": 0.6292837609339351,
          "mAP_info": {
            "calculated_from": "subset_excluding_last_classes_present_actions_only",
            "excluded_classes": 6,
            "subset_size": 94,
            "present_actions_in_subset": "20",
            "subset_action_sparsity": 0.7872340425531915
          },
          "mAP_standard_with_null_verb": 0.870485043791753,
          "mAP_present_only_with_null_verb": 0.5673262773554473,
          "mAP_freq_weighted_with_null_verb": 0.8352604637847035,
          "mAP_sample_wise_with_null_verb": 0.8619663933363494,
          "mAP_standard_all_actions": 0.870485043791753,
          "mAP_present_only_all_actions": 0.5673262773554473,
          "mAP_freq_weighted_all_actions": 0.8352604637847035,
          "mAP_sample_wise_all_actions": 0.8619663933363494,
          "exact_match_with_null_verb": 0.5175438596491229,
          "hamming_accuracy_with_null_verb": 0.993141447368421,
          "precision_with_null_verb": 0.9166887417261083,
          "recall_with_null_verb": 0.8502407859570363,
          "f1_with_null_verb": 0.8804855997821326,
          "num_predictions": 1824,
          "num_actions_total_with_null_verb": 100,
          "num_actions_present_with_null_verb": "23",
          "action_sparsity_with_null_verb": 0.77,
          "task": "single_step_action_prediction",
          "method_name": "AutoregressiveIL_video_VID66_epoch_-1",
          "exclude_last_n": 6,
          "mAP_standard": 0.8892093108370073,
          "mAP_present_only": 0.6292837609339351,
          "mAP_freq_weighted": 0.8578468448446227,
          "exact_match": 0.5372807017543859,
          "hamming_accuracy": 0.9934560470324748,
          "precision": 0.9245015157442913,
          "recall": 0.8604795111722086,
          "f1": 0.8897863470557582,
          "num_actions_total": 94,
          "num_actions_present": "20",
          "action_sparsity": 0.7872340425531915
        },
        "VID79": {
          "mAP": 0.3922602182107021,
          "mAP_info": {
            "calculated_from": "subset_excluding_last_classes_present_actions_only",
            "excluded_classes": 6,
            "subset_size": 94,
            "present_actions_in_subset": "31",
            "subset_action_sparsity": 0.6702127659574468
          },
          "mAP_standard_with_null_verb": 0.7490853846956896,
          "mAP_present_only_with_null_verb": 0.35857051304358245,
          "mAP_freq_weighted_with_null_verb": 0.7707931597570288,
          "mAP_sample_wise_with_null_verb": 0.7791286540601141,
          "mAP_standard_all_actions": 0.7490853846956896,
          "mAP_present_only_all_actions": 0.35857051304358245,
          "mAP_freq_weighted_all_actions": 0.7707931597570288,
          "mAP_sample_wise_all_actions": 0.7791286540601141,
          "exact_match_with_null_verb": 0.4150556531927358,
          "hamming_accuracy_with_null_verb": 0.989900410076157,
          "precision_with_null_verb": 0.8627166830081497,
          "recall_with_null_verb": 0.8083538370719736,
          "f1_with_null_verb": 0.8332451924098511,
          "num_predictions": 3414,
          "num_actions_total_with_null_verb": 100,
          "num_actions_present_with_null_verb": "36",
          "action_sparsity_with_null_verb": 0.64,
          "task": "single_step_action_prediction",
          "method_name": "AutoregressiveIL_video_VID79_epoch_-1",
          "exclude_last_n": 6,
          "mAP_standard": 0.7782985826014017,
          "mAP_present_only": 0.3922602182107021,
          "mAP_freq_weighted": 0.8008125187524265,
          "exact_match": 0.44932630345635616,
          "hamming_accuracy": 0.9905053035685351,
          "precision": 0.8751187355417934,
          "recall": 0.8186388451647209,
          "f1": 0.8444887538182537,
          "num_actions_total": 94,
          "num_actions_present": "31",
          "action_sparsity": 0.6702127659574468
        }
      },
      "video_loss_metrics": {
        "VID02": {
          "action_rec_loss": 0.05184855924976597,
          "frame_loss": 0.16419313335268015,
          "action_loss": 0.03734822626117083,
          "phase_loss": 0.8497037428911379,
          "consistency_loss": 0.002253868370342879,
          "total_loss": 0.4409302039009132
        },
        "VID06": {
          "action_rec_loss": 0.039714678753861574,
          "frame_loss": 0.16294904108400698,
          "action_loss": 0.0324365786500965,
          "phase_loss": 0.5565860309490657,
          "consistency_loss": 0.0023413386352735366,
          "total_loss": 0.32811382639187353
        },
        "VID111": {
          "action_rec_loss": 0.046575147546914025,
          "frame_loss": 0.1558733430923894,
          "action_loss": 0.03443351378912296,
          "phase_loss": 1.9754856472299218,
          "consistency_loss": 0.0019531214955366993,
          "total_loss": 0.7639279899221879
        },
        "VID14": {
          "action_rec_loss": 0.0457730274353716,
          "frame_loss": 0.1730849125148363,
          "action_loss": 0.03841688538298759,
          "phase_loss": 2.2053597793088295,
          "consistency_loss": 0.0019073545215951952,
          "total_loss": 0.8398872037009101
        },
        "VID23": {
          "action_rec_loss": 0.05598451703886029,
          "frame_loss": 0.18419341833412067,
          "action_loss": 0.042732524745182125,
          "phase_loss": 1.3092356305118062,
          "consistency_loss": 0.0022855849119436757,
          "total_loss": 0.5970650030281938
        },
        "VID25": {
          "action_rec_loss": 0.037867544607672866,
          "frame_loss": 0.1614596925175457,
          "action_loss": 0.03110958637197071,
          "phase_loss": 0.8206137779191061,
          "consistency_loss": 0.002067704402315261,
          "total_loss": 0.4028558497414438
        },
        "VID50": {
          "action_rec_loss": 0.03364659076222502,
          "frame_loss": 0.15194890734510144,
          "action_loss": 0.02798107961881096,
          "phase_loss": 0.4418039405265557,
          "consistency_loss": 0.0019515160417633024,
          "total_loss": 0.2760039743953857
        },
        "VID51": {
          "action_rec_loss": 0.049707605152928845,
          "frame_loss": 0.14692665626416387,
          "action_loss": 0.035563941272931,
          "phase_loss": 1.276018982515087,
          "consistency_loss": 0.002341628447343579,
          "total_loss": 0.5559184139027543
        },
        "VID66": {
          "action_rec_loss": 0.027742921294383563,
          "frame_loss": 0.1650508349075129,
          "action_loss": 0.021853069600438813,
          "phase_loss": 0.2588632254274665,
          "consistency_loss": 0.0021854621865919285,
          "total_loss": 0.21588877831961503
        },
        "VID79": {
          "action_rec_loss": 0.04000461695164912,
          "frame_loss": 0.1751795721666835,
          "action_loss": 0.033992791543135344,
          "phase_loss": 0.4974799691099673,
          "consistency_loss": 0.0023957030572495765,
          "total_loss": 0.31708258592358257
        }
      },
      "generation_quality": {
        "frame_smoothness": 1.1234325567881267,
        "action_diversity": 0.0010189561289735138
      },
      "planning_evaluation": {
        "aggregated_results": {
          "num_videos": 10,
          "overall_success_rate": 15.931928166277917,
          "horizon_aggregated": {
            "1s": {
              "num_videos_evaluated": 10,
              "planning_horizon_frames": 1,
              "planning_horizon_seconds": 1.0,
              "mean_ivt_mAP": 0.22600061733111892,
              "std_ivt_mAP": 0.057039395841644636,
              "mean_exact_match_rate": 0.420429970013213,
              "std_exact_match_rate": 0.0492678909580661,
              "mean_hamming_accuracy": 0.9905533439347994,
              "std_hamming_accuracy": 0.0011175881953408232,
              "mean_action_consistency": 0.9964442760759209,
              "std_action_consistency": 0.0003589504399709997,
              "mean_temporal_smoothness": "0.9964506",
              "std_temporal_smoothness": "0.00035769463",
              "mean_sparsity_similarity": 0.9969587736827332,
              "std_sparsity_similarity": 0.0008007256343416531,
              "mean_ivt_i_mAP": 0.6378834570292418,
              "mean_ivt_v_mAP": 0.47256463511128166,
              "mean_ivt_t_mAP": 0.3262867174551062,
              "mean_ivt_iv_mAP": 0.2817059758347086,
              "mean_ivt_it_mAP": 0.2656672815345263
            },
            "2s": {
              "num_videos_evaluated": 10,
              "planning_horizon_frames": 2,
              "planning_horizon_seconds": 2.0,
              "mean_ivt_mAP": 0.2240916159214069,
              "std_ivt_mAP": 0.05717135122345078,
              "mean_exact_match_rate": 0.4214307796685266,
              "std_exact_match_rate": 0.04729280764753269,
              "mean_hamming_accuracy": 0.9901642642578308,
              "std_hamming_accuracy": 0.0012309486730129027,
              "mean_action_consistency": 0.9968061865790931,
              "std_action_consistency": 0.00022375067773428665,
              "mean_temporal_smoothness": "0.9968112",
              "std_temporal_smoothness": "0.00022303248",
              "mean_sparsity_similarity": 0.9979277228653191,
              "std_sparsity_similarity": 0.0008357238962606966,
              "mean_ivt_i_mAP": 0.6400788618952087,
              "mean_ivt_v_mAP": 0.4699411825795711,
              "mean_ivt_t_mAP": 0.3277164841595236,
              "mean_ivt_iv_mAP": 0.27907862039859155,
              "mean_ivt_it_mAP": 0.2639312392247944
            },
            "3s": {
              "num_videos_evaluated": 10,
              "planning_horizon_frames": 3,
              "planning_horizon_seconds": 3.0,
              "mean_ivt_mAP": 0.21197919675364713,
              "std_ivt_mAP": 0.05065557063306029,
              "mean_exact_match_rate": 0.40875792200135647,
              "std_exact_match_rate": 0.04687553541871006,
              "mean_hamming_accuracy": 0.9897674672991104,
              "std_hamming_accuracy": 0.0012410232461301644,
              "mean_action_consistency": 0.9970935582080187,
              "std_action_consistency": 0.00023556695699750762,
              "mean_temporal_smoothness": "0.9970978",
              "std_temporal_smoothness": "0.00023489523",
              "mean_sparsity_similarity": 0.9983295996205632,
              "std_sparsity_similarity": 0.0008462227474236422,
              "mean_ivt_i_mAP": 0.6238658608393512,
              "mean_ivt_v_mAP": 0.45588594268322036,
              "mean_ivt_t_mAP": 0.3192694374512993,
              "mean_ivt_iv_mAP": 0.26930131851389366,
              "mean_ivt_it_mAP": 0.2500151818532987
            },
            "5s": {
              "num_videos_evaluated": 10,
              "planning_horizon_frames": 5,
              "planning_horizon_seconds": 5.0,
              "mean_ivt_mAP": 0.19421194416102275,
              "std_ivt_mAP": 0.04741051886668061,
              "mean_exact_match_rate": 0.38268868065537187,
              "std_exact_match_rate": 0.04389888073830143,
              "mean_hamming_accuracy": 0.9890822079277939,
              "std_hamming_accuracy": 0.0012373955222284739,
              "mean_action_consistency": 0.9974193610119266,
              "std_action_consistency": 0.00016278923281882297,
              "mean_temporal_smoothness": "0.9974227",
              "std_temporal_smoothness": "0.00016237119",
              "mean_sparsity_similarity": 0.9987063783498232,
              "std_sparsity_similarity": 0.000717654155881313,
              "mean_ivt_i_mAP": 0.5935700313849633,
              "mean_ivt_v_mAP": 0.4303245601721116,
              "mean_ivt_t_mAP": 0.3060484127039277,
              "mean_ivt_iv_mAP": 0.2537331353653006,
              "mean_ivt_it_mAP": 0.22909039421222258
            }
          }
        },
        "detailed_video_results": {
          "VID02": {
            "video_id": "VID02",
            "total_sequences": 178,
            "successful_predictions": 2839,
            "success_rate": 15.94943820224719,
            "horizon_results": {
              "1s": {
                "num_sequences": 2839,
                "total_frames": 2839,
                "horizon_frames": 1,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.1921976218139536,
                "ivt_i_mAP": 0.60443164266119,
                "ivt_v_mAP": 0.420790024595832,
                "ivt_t_mAP": 0.2825536255126703,
                "ivt_iv_mAP": 0.2421908023164524,
                "ivt_it_mAP": 0.23100915758765597,
                "exact_match_rate": 0.402606551602677,
                "hamming_accuracy": 0.9901197604790419,
                "action_consistency": 0.9959055673009162,
                "temporal_smoothness": "0.9959139",
                "pred_sparsity": 0.011144769284959492,
                "gt_sparsity": 0.014346600915815428,
                "sparsity_similarity": 0.996798168369144
              },
              "2s": {
                "num_sequences": 2839,
                "total_frames": 2839,
                "horizon_frames": 2,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.1753953445351375,
                "ivt_i_mAP": 0.5915257178041968,
                "ivt_v_mAP": 0.3970806903163919,
                "ivt_t_mAP": 0.2600763246779079,
                "ivt_iv_mAP": 0.22677554712439107,
                "ivt_it_mAP": 0.2102260224239423,
                "exact_match_rate": 0.3902782669954209,
                "hamming_accuracy": 0.9897076435364565,
                "action_consistency": 0.9965398167723749,
                "temporal_smoothness": "0.9965458",
                "pred_sparsity": 0.011852765058119056,
                "gt_sparsity": 0.014346600915815428,
                "sparsity_similarity": 0.9975061641423036
              },
              "3s": {
                "num_sequences": 2839,
                "total_frames": 2839,
                "horizon_frames": 3,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.16717469121792733,
                "ivt_i_mAP": 0.5779460002168956,
                "ivt_v_mAP": 0.38375212344398246,
                "ivt_t_mAP": 0.24620699876253693,
                "ivt_iv_mAP": 0.21530647650004867,
                "ivt_it_mAP": 0.2000425104903513,
                "exact_match_rate": 0.3716097217330046,
                "hamming_accuracy": 0.9892884818598098,
                "action_consistency": 0.9967653276955603,
                "temporal_smoothness": "0.99677056",
                "pred_sparsity": 0.012159210989785136,
                "gt_sparsity": 0.014346600915815428,
                "sparsity_similarity": 0.9978126100739697
              },
              "5s": {
                "num_sequences": 2839,
                "total_frames": 2839,
                "horizon_frames": 5,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.1514500012275921,
                "ivt_i_mAP": 0.5580821792656455,
                "ivt_v_mAP": 0.34872201418557963,
                "ivt_t_mAP": 0.2272447019902586,
                "ivt_iv_mAP": 0.20013868822490988,
                "ivt_it_mAP": 0.18128938523265561,
                "exact_match_rate": 0.3480098626276858,
                "hamming_accuracy": 0.9887742162733357,
                "action_consistency": 0.9970824524312897,
                "temporal_smoothness": "0.9970867",
                "pred_sparsity": 0.012511447692849596,
                "gt_sparsity": 0.014346600915815428,
                "sparsity_similarity": 0.9981648467770342
              }
            }
          },
          "VID06": {
            "video_id": "VID06",
            "total_sequences": 135,
            "successful_predictions": 2153,
            "success_rate": 15.948148148148148,
            "horizon_results": {
              "1s": {
                "num_sequences": 2153,
                "total_frames": 2153,
                "horizon_frames": 1,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.19850960395036,
                "ivt_i_mAP": 0.6082536257868609,
                "ivt_v_mAP": 0.36667807649874146,
                "ivt_t_mAP": 0.31759899335376923,
                "ivt_iv_mAP": 0.2202950549841828,
                "ivt_it_mAP": 0.2506078690992945,
                "exact_match_rate": 0.37111007895959125,
                "hamming_accuracy": 0.9908871342313051,
                "action_consistency": 0.9969609665427509,
                "temporal_smoothness": "0.9969655",
                "pred_sparsity": 0.013687877380399442,
                "gt_sparsity": 0.01740362285183465,
                "sparsity_similarity": 0.9962842545285648
              },
              "2s": {
                "num_sequences": 2153,
                "total_frames": 2153,
                "horizon_frames": 2,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.200908237313635,
                "ivt_i_mAP": 0.630590333670025,
                "ivt_v_mAP": 0.37305115546537804,
                "ivt_t_mAP": 0.3231660048077343,
                "ivt_iv_mAP": 0.22389152675716195,
                "ivt_it_mAP": 0.25254041623285417,
                "exact_match_rate": 0.37807710171853226,
                "hamming_accuracy": 0.9905898745935904,
                "action_consistency": 0.9971096654275093,
                "temporal_smoothness": "0.99711376",
                "pred_sparsity": 0.01458894565722248,
                "gt_sparsity": 0.01740362285183465,
                "sparsity_similarity": 0.9971853228053879
              },
              "3s": {
                "num_sequences": 2153,
                "total_frames": 2153,
                "horizon_frames": 3,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.1979698204361827,
                "ivt_i_mAP": 0.6406361805000157,
                "ivt_v_mAP": 0.37474137088016185,
                "ivt_t_mAP": 0.3198758563771463,
                "ivt_iv_mAP": 0.2252802774885029,
                "ivt_it_mAP": 0.24761935948928102,
                "exact_match_rate": 0.3683232698560149,
                "hamming_accuracy": 0.9902740362285184,
                "action_consistency": 0.9973791821561339,
                "temporal_smoothness": "0.9973827",
                "pred_sparsity": 0.015025545750116116,
                "gt_sparsity": 0.01740362285183465,
                "sparsity_similarity": 0.9976219228982814
              },
              "5s": {
                "num_sequences": 2153,
                "total_frames": 2153,
                "horizon_frames": 5,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.18940705074687036,
                "ivt_i_mAP": 0.6567478443842045,
                "ivt_v_mAP": 0.3795171357175783,
                "ivt_t_mAP": 0.30967331377725305,
                "ivt_iv_mAP": 0.22706712293234851,
                "ivt_it_mAP": 0.23540177861035805,
                "exact_match_rate": 0.346493265211333,
                "hamming_accuracy": 0.9895169530887135,
                "action_consistency": 0.9975557620817844,
                "temporal_smoothness": "0.9975587",
                "pred_sparsity": 0.015615420343706455,
                "gt_sparsity": 0.01740362285183465,
                "sparsity_similarity": 0.9982117974918718
              }
            }
          },
          "VID111": {
            "video_id": "VID111",
            "total_sequences": 135,
            "successful_predictions": 2145,
            "success_rate": 15.88888888888889,
            "horizon_results": {
              "1s": {
                "num_sequences": 2145,
                "total_frames": 2145,
                "horizon_frames": 1,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.21789938449151075,
                "ivt_i_mAP": 0.5608353002483782,
                "ivt_v_mAP": 0.432309152664733,
                "ivt_t_mAP": 0.2804936930472422,
                "ivt_iv_mAP": 0.26297104909884944,
                "ivt_it_mAP": 0.25292962684997694,
                "exact_match_rate": 0.4405594405594406,
                "hamming_accuracy": 0.9892820512820513,
                "action_consistency": 0.9967723880597015,
                "temporal_smoothness": "0.9967776",
                "pred_sparsity": 0.01041958041958042,
                "gt_sparsity": 0.012251748251748252,
                "sparsity_similarity": 0.9981678321678321
              },
              "2s": {
                "num_sequences": 2145,
                "total_frames": 2145,
                "horizon_frames": 2,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.22116128453747722,
                "ivt_i_mAP": 0.5815268164680176,
                "ivt_v_mAP": 0.45100629850384066,
                "ivt_t_mAP": 0.27960266589536864,
                "ivt_iv_mAP": 0.27339750925830797,
                "ivt_it_mAP": 0.2550934601682738,
                "exact_match_rate": 0.427972027972028,
                "hamming_accuracy": 0.9887785547785548,
                "action_consistency": 0.9968563432835821,
                "temporal_smoothness": "0.9968612",
                "pred_sparsity": 0.010923076923076923,
                "gt_sparsity": 0.012251748251748252,
                "sparsity_similarity": 0.9986713286713287
              },
              "3s": {
                "num_sequences": 2145,
                "total_frames": 2145,
                "horizon_frames": 3,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.20416893443142156,
                "ivt_i_mAP": 0.5670545882506005,
                "ivt_v_mAP": 0.44033657192072495,
                "ivt_t_mAP": 0.27989620356746797,
                "ivt_iv_mAP": 0.26643859598706454,
                "ivt_it_mAP": 0.23434772779970436,
                "exact_match_rate": 0.4144522144522145,
                "hamming_accuracy": 0.9884289044289044,
                "action_consistency": 0.9969029850746268,
                "temporal_smoothness": "0.9969078",
                "pred_sparsity": 0.011403263403263404,
                "gt_sparsity": 0.012251748251748252,
                "sparsity_similarity": 0.9991515151515151
              },
              "5s": {
                "num_sequences": 2145,
                "total_frames": 2145,
                "horizon_frames": 5,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.18075618261153933,
                "ivt_i_mAP": 0.5495901792810837,
                "ivt_v_mAP": 0.43785374589000736,
                "ivt_t_mAP": 0.2577172337382951,
                "ivt_iv_mAP": 0.2645443401635695,
                "ivt_it_mAP": 0.20102307767319408,
                "exact_match_rate": 0.39533799533799535,
                "hamming_accuracy": 0.988027972027972,
                "action_consistency": 0.9976119402985074,
                "temporal_smoothness": "0.99761474",
                "pred_sparsity": 0.011785547785547785,
                "gt_sparsity": 0.012251748251748252,
                "sparsity_similarity": 0.9995337995337995
              }
            }
          },
          "VID14": {
            "video_id": "VID14",
            "total_sequences": 107,
            "successful_predictions": 1708,
            "success_rate": 15.962616822429906,
            "horizon_results": {
              "1s": {
                "num_sequences": 1708,
                "total_frames": 1708,
                "horizon_frames": 1,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.13998464309751701,
                "ivt_i_mAP": 0.5559173681239944,
                "ivt_v_mAP": 0.4098019905828647,
                "ivt_t_mAP": 0.267968711141788,
                "ivt_iv_mAP": 0.21261868478638546,
                "ivt_it_mAP": 0.1894286448084465,
                "exact_match_rate": 0.40339578454332553,
                "hamming_accuracy": 0.9900644028103045,
                "action_consistency": 0.9969185705916813,
                "temporal_smoothness": "0.9969234",
                "pred_sparsity": 0.01145784543325527,
                "gt_sparsity": 0.015480093676814988,
                "sparsity_similarity": 0.9959777517564403
              },
              "2s": {
                "num_sequences": 1708,
                "total_frames": 1708,
                "horizon_frames": 2,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.13492367845102957,
                "ivt_i_mAP": 0.5563264997978276,
                "ivt_v_mAP": 0.3959796941512691,
                "ivt_t_mAP": 0.2688271325410128,
                "ivt_iv_mAP": 0.20650203711549586,
                "ivt_it_mAP": 0.18256869895385586,
                "exact_match_rate": 0.40866510538641687,
                "hamming_accuracy": 0.9898185011709602,
                "action_consistency": 0.9971997656707674,
                "temporal_smoothness": "0.9972037",
                "pred_sparsity": 0.012523419203747072,
                "gt_sparsity": 0.015480093676814988,
                "sparsity_similarity": 0.9970433255269321
              },
              "3s": {
                "num_sequences": 1708,
                "total_frames": 1708,
                "horizon_frames": 3,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.13114280203286321,
                "ivt_i_mAP": 0.5528635399916657,
                "ivt_v_mAP": 0.39582718330708205,
                "ivt_t_mAP": 0.2608774300069339,
                "ivt_iv_mAP": 0.2059569852965709,
                "ivt_it_mAP": 0.17695801987162746,
                "exact_match_rate": 0.3911007025761124,
                "hamming_accuracy": 0.9893384074941451,
                "action_consistency": 0.9974692442882249,
                "temporal_smoothness": "0.9974724",
                "pred_sparsity": 0.012991803278688525,
                "gt_sparsity": 0.015480093676814988,
                "sparsity_similarity": 0.9975117096018735
              },
              "5s": {
                "num_sequences": 1708,
                "total_frames": 1708,
                "horizon_frames": 5,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.11953093956607154,
                "ivt_i_mAP": 0.5074500782376872,
                "ivt_v_mAP": 0.35442171014399276,
                "ivt_t_mAP": 0.25766512262436214,
                "ivt_iv_mAP": 0.1850606588188427,
                "ivt_it_mAP": 0.16092188694530146,
                "exact_match_rate": 0.3553864168618267,
                "hamming_accuracy": 0.988284543325527,
                "action_consistency": 0.9975395430579965,
                "temporal_smoothness": "0.9975426",
                "pred_sparsity": 0.013682669789227166,
                "gt_sparsity": 0.015480093676814988,
                "sparsity_similarity": 0.9982025761124121
              }
            }
          },
          "VID23": {
            "video_id": "VID23",
            "total_sequences": 103,
            "successful_predictions": 1635,
            "success_rate": 15.87378640776699,
            "horizon_results": {
              "1s": {
                "num_sequences": 1635,
                "total_frames": 1635,
                "horizon_frames": 1,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.19525318347066337,
                "ivt_i_mAP": 0.5174323786770818,
                "ivt_v_mAP": 0.3908515430527959,
                "ivt_t_mAP": 0.2802405397389211,
                "ivt_iv_mAP": 0.24201697672180822,
                "ivt_it_mAP": 0.21632147839276403,
                "exact_match_rate": 0.37186544342507644,
                "hamming_accuracy": 0.9893822629969419,
                "action_consistency": 0.9963157894736843,
                "temporal_smoothness": "0.9963225",
                "pred_sparsity": 0.01163914373088685,
                "gt_sparsity": 0.0158348623853211,
                "sparsity_similarity": 0.9958042813455658
              },
              "2s": {
                "num_sequences": 1635,
                "total_frames": 1635,
                "horizon_frames": 2,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.19393863680580586,
                "ivt_i_mAP": 0.5159453115407227,
                "ivt_v_mAP": 0.38500740641566206,
                "ivt_t_mAP": 0.2789446812204135,
                "ivt_iv_mAP": 0.23674748137722534,
                "ivt_it_mAP": 0.21646010332106777,
                "exact_match_rate": 0.3712538226299694,
                "hamming_accuracy": 0.9889908256880734,
                "action_consistency": 0.9970012239902081,
                "temporal_smoothness": "0.9970057",
                "pred_sparsity": 0.012581039755351683,
                "gt_sparsity": 0.01582262996941896,
                "sparsity_similarity": 0.9967584097859328
              },
              "3s": {
                "num_sequences": 1635,
                "total_frames": 1635,
                "horizon_frames": 3,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.1782288223145085,
                "ivt_i_mAP": 0.5093513392567178,
                "ivt_v_mAP": 0.37413181972061227,
                "ivt_t_mAP": 0.26871573297409,
                "ivt_iv_mAP": 0.22871615027161413,
                "ivt_it_mAP": 0.1990546528601291,
                "exact_match_rate": 0.363302752293578,
                "hamming_accuracy": 0.9884709480122325,
                "action_consistency": 0.9972215422276621,
                "temporal_smoothness": "0.9972254",
                "pred_sparsity": 0.012966360856269113,
                "gt_sparsity": 0.01581039755351682,
                "sparsity_similarity": 0.9971559633027522
              },
              "5s": {
                "num_sequences": 1635,
                "total_frames": 1635,
                "horizon_frames": 5,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.15684161399640276,
                "ivt_i_mAP": 0.46964404577338464,
                "ivt_v_mAP": 0.35046885135235173,
                "ivt_t_mAP": 0.2499007882889973,
                "ivt_iv_mAP": 0.21518593945755043,
                "ivt_it_mAP": 0.1751215126586542,
                "exact_match_rate": 0.3474006116207951,
                "hamming_accuracy": 0.9877125382262997,
                "action_consistency": 0.99734394124847,
                "temporal_smoothness": "0.9973475",
                "pred_sparsity": 0.013382262996941896,
                "gt_sparsity": 0.01578593272171254,
                "sparsity_similarity": 0.9975963302752293
              }
            }
          },
          "VID25": {
            "video_id": "VID25",
            "total_sequences": 134,
            "successful_predictions": 2129,
            "success_rate": 15.888059701492537,
            "horizon_results": {
              "1s": {
                "num_sequences": 2129,
                "total_frames": 2129,
                "horizon_frames": 1,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.29508692608921583,
                "ivt_i_mAP": 0.7268400185069203,
                "ivt_v_mAP": 0.45692428281575215,
                "ivt_t_mAP": 0.40606752908047117,
                "ivt_iv_mAP": 0.2906329825592021,
                "ivt_it_mAP": 0.3296901136440196,
                "exact_match_rate": 0.40206669798027245,
                "hamming_accuracy": 0.9909300140911226,
                "action_consistency": 0.9962593984962406,
                "temporal_smoothness": "0.9962663",
                "pred_sparsity": 0.012968529826209487,
                "gt_sparsity": 0.01657116016909347,
                "sparsity_similarity": 0.996397369657116
              },
              "2s": {
                "num_sequences": 2129,
                "total_frames": 2129,
                "horizon_frames": 2,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.2924690476230156,
                "ivt_i_mAP": 0.7123742229596655,
                "ivt_v_mAP": 0.44817522295818374,
                "ivt_t_mAP": 0.42186530894007285,
                "ivt_iv_mAP": 0.28501880665040114,
                "ivt_it_mAP": 0.327308329267227,
                "exact_match_rate": 0.4405824330671677,
                "hamming_accuracy": 0.9909253170502583,
                "action_consistency": 0.9967105263157895,
                "temporal_smoothness": "0.99671596",
                "pred_sparsity": 0.013931423203381869,
                "gt_sparsity": 0.01657116016909347,
                "sparsity_similarity": 0.9973602630342884
              },
              "3s": {
                "num_sequences": 2129,
                "total_frames": 2129,
                "horizon_frames": 3,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.27604490113722135,
                "ivt_i_mAP": 0.6987333283333254,
                "ivt_v_mAP": 0.43879228686730903,
                "ivt_t_mAP": 0.41042706267812734,
                "ivt_iv_mAP": 0.27925791023029906,
                "ivt_it_mAP": 0.3088357204430499,
                "exact_match_rate": 0.4485674025364021,
                "hamming_accuracy": 0.9906951620479099,
                "action_consistency": 0.996936090225564,
                "temporal_smoothness": "0.9969408",
                "pred_sparsity": 0.014302489431658055,
                "gt_sparsity": 0.01657116016909347,
                "sparsity_similarity": 0.9977313292625646
              },
              "5s": {
                "num_sequences": 2129,
                "total_frames": 2129,
                "horizon_frames": 5,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.2508356221937599,
                "ivt_i_mAP": 0.6825773835167569,
                "ivt_v_mAP": 0.4359544455713474,
                "ivt_t_mAP": 0.39284717684154663,
                "ivt_iv_mAP": 0.27463304937008076,
                "ivt_it_mAP": 0.28099042526094153,
                "exact_match_rate": 0.4316580554250822,
                "hamming_accuracy": 0.9900939408172851,
                "action_consistency": 0.9976315789473684,
                "temporal_smoothness": "0.9976345",
                "pred_sparsity": 0.01462188821042743,
                "gt_sparsity": 0.01657116016909347,
                "sparsity_similarity": 0.998050728041334
              }
            }
          },
          "VID50": {
            "video_id": "VID50",
            "total_sequences": 69,
            "successful_predictions": 1094,
            "success_rate": 15.855072463768115,
            "horizon_results": {
              "1s": {
                "num_sequences": 1094,
                "total_frames": 1094,
                "horizon_frames": 1,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.30699817256552225,
                "ivt_i_mAP": 0.8336001705392572,
                "ivt_v_mAP": 0.6588175451194878,
                "ivt_t_mAP": 0.3127156373342457,
                "ivt_iv_mAP": 0.44146109710406867,
                "ivt_it_mAP": 0.3392922700681223,
                "exact_match_rate": 0.5036563071297989,
                "hamming_accuracy": 0.991782449725777,
                "action_consistency": 0.9966422689844465,
                "temporal_smoothness": "0.99664795",
                "pred_sparsity": 0.014579524680073126,
                "gt_sparsity": 0.016453382084095063,
                "sparsity_similarity": 0.9981261425959781
              },
              "2s": {
                "num_sequences": 1094,
                "total_frames": 1094,
                "horizon_frames": 2,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.2844580643715084,
                "ivt_i_mAP": 0.7621702238857793,
                "ivt_v_mAP": 0.5989207011235346,
                "ivt_t_mAP": 0.30729323314801005,
                "ivt_iv_mAP": 0.4005333017317928,
                "ivt_it_mAP": 0.31683662459880985,
                "exact_match_rate": 0.46983546617915906,
                "hamming_accuracy": 0.9909597806215722,
                "action_consistency": 0.9968252516010979,
                "temporal_smoothness": "0.9968303",
                "pred_sparsity": 0.01585923217550274,
                "gt_sparsity": 0.01643510054844607,
                "sparsity_similarity": 0.9994241316270567
              },
              "3s": {
                "num_sequences": 1094,
                "total_frames": 1094,
                "horizon_frames": 3,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.2636982803443699,
                "ivt_i_mAP": 0.6922917570270755,
                "ivt_v_mAP": 0.5526852423768426,
                "ivt_t_mAP": 0.3008791076809773,
                "ivt_iv_mAP": 0.3696111807353007,
                "ivt_it_mAP": 0.2934973298659121,
                "exact_match_rate": 0.4460694698354662,
                "hamming_accuracy": 0.9905210237659964,
                "action_consistency": 0.9973924977127173,
                "temporal_smoothness": "0.9973958",
                "pred_sparsity": 0.016261425959780623,
                "gt_sparsity": 0.016416819012797075,
                "sparsity_similarity": 0.9998446069469835
              },
              "5s": {
                "num_sequences": 1094,
                "total_frames": 1094,
                "horizon_frames": 5,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.23298418017724754,
                "ivt_i_mAP": 0.5806082825488788,
                "ivt_v_mAP": 0.47478185277392043,
                "ivt_t_mAP": 0.28593715110089046,
                "ivt_iv_mAP": 0.3184257631375052,
                "ivt_it_mAP": 0.25893988154021036,
                "exact_match_rate": 0.41224862888482633,
                "hamming_accuracy": 0.989908592321755,
                "action_consistency": 0.9974473924977127,
                "temporal_smoothness": "0.9974507",
                "pred_sparsity": 0.01670018281535649,
                "gt_sparsity": 0.01640767824497258,
                "sparsity_similarity": 0.9997074954296161
              }
            }
          },
          "VID51": {
            "video_id": "VID51",
            "total_sequences": 184,
            "successful_predictions": 2944,
            "success_rate": 16.0,
            "horizon_results": {
              "1s": {
                "num_sequences": 2944,
                "total_frames": 2944,
                "horizon_frames": 1,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.21926110275192048,
                "ivt_i_mAP": 0.6376313303222231,
                "ivt_v_mAP": 0.49260939127392744,
                "ivt_t_mAP": 0.38584516270225533,
                "ivt_iv_mAP": 0.28122201273284175,
                "ivt_it_mAP": 0.26163160661278556,
                "exact_match_rate": 0.37907608695652173,
                "hamming_accuracy": 0.9900339673913043,
                "action_consistency": 0.9964899762147469,
                "temporal_smoothness": "0.99649614",
                "pred_sparsity": 0.012306385869565218,
                "gt_sparsity": 0.015146059782608697,
                "sparsity_similarity": 0.9971603260869565
              },
              "2s": {
                "num_sequences": 2944,
                "total_frames": 2944,
                "horizon_frames": 2,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.23249838321422753,
                "ivt_i_mAP": 0.6792156754708705,
                "ivt_v_mAP": 0.5250134280885977,
                "ivt_t_mAP": 0.40274880223262954,
                "ivt_iv_mAP": 0.29821264674724546,
                "ivt_it_mAP": 0.27915436212114536,
                "exact_match_rate": 0.38383152173913043,
                "hamming_accuracy": 0.989500679347826,
                "action_consistency": 0.9966326877336051,
                "temporal_smoothness": "0.99663836",
                "pred_sparsity": 0.013325407608695652,
                "gt_sparsity": 0.015142663043478262,
                "sparsity_similarity": 0.9981827445652174
              },
              "3s": {
                "num_sequences": 2944,
                "total_frames": 2944,
                "horizon_frames": 3,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.22173527394181383,
                "ivt_i_mAP": 0.665651333009773,
                "ivt_v_mAP": 0.514661690598653,
                "ivt_t_mAP": 0.3882226851250473,
                "ivt_iv_mAP": 0.2911032234618343,
                "ivt_it_mAP": 0.2654877674354464,
                "exact_match_rate": 0.37092391304347827,
                "hamming_accuracy": 0.9890353260869565,
                "action_consistency": 0.9969588854909955,
                "temporal_smoothness": "0.99696344",
                "pred_sparsity": 0.013563179347826087,
                "gt_sparsity": 0.015139266304347827,
                "sparsity_similarity": 0.9984239130434782
              },
              "5s": {
                "num_sequences": 2944,
                "total_frames": 2944,
                "horizon_frames": 5,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.2069447178690065,
                "ivt_i_mAP": 0.653033910565277,
                "ivt_v_mAP": 0.49667152191634006,
                "ivt_t_mAP": 0.3665613319983287,
                "ivt_iv_mAP": 0.2755717761155823,
                "ivt_it_mAP": 0.2491788637965692,
                "exact_match_rate": 0.343070652173913,
                "hamming_accuracy": 0.98828125,
                "action_consistency": 0.997353041114509,
                "temporal_smoothness": "0.9973566",
                "pred_sparsity": 0.013902853260869565,
                "gt_sparsity": 0.015132472826086957,
                "sparsity_similarity": 0.9987703804347826
              }
            }
          },
          "VID66": {
            "video_id": "VID66",
            "total_sequences": 114,
            "successful_predictions": 1824,
            "success_rate": 16.0,
            "horizon_results": {
              "1s": {
                "num_sequences": 1824,
                "total_frames": 1824,
                "horizon_frames": 1,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.3178750320770574,
                "ivt_i_mAP": 0.6177036302834685,
                "ivt_v_mAP": 0.5293376406582287,
                "ivt_t_mAP": 0.3890696369939487,
                "ivt_iv_mAP": 0.3599115059367619,
                "ivt_it_mAP": 0.3424661949713255,
                "exact_match_rate": 0.5175438596491229,
                "hamming_accuracy": 0.9931304824561403,
                "action_consistency": 0.996253428414701,
                "temporal_smoothness": "0.99626046",
                "pred_sparsity": 0.013267543859649122,
                "gt_sparsity": 0.015838815789473683,
                "sparsity_similarity": 0.9974287280701755
              },
              "2s": {
                "num_sequences": 1824,
                "total_frames": 1824,
                "horizon_frames": 2,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.3263872239609819,
                "ivt_i_mAP": 0.6503646802750971,
                "ivt_v_mAP": 0.5479701794826233,
                "ivt_t_mAP": 0.3846225223963149,
                "ivt_iv_mAP": 0.37273105184459077,
                "ivt_it_mAP": 0.35317368793098913,
                "exact_match_rate": 0.5334429824561403,
                "hamming_accuracy": 0.9931359649122807,
                "action_consistency": 0.9966703236423478,
                "temporal_smoothness": "0.99667585",
                "pred_sparsity": 0.01419407894736842,
                "gt_sparsity": 0.015838815789473683,
                "sparsity_similarity": 0.9983552631578947
              },
              "3s": {
                "num_sequences": 1824,
                "total_frames": 1824,
                "horizon_frames": 3,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.30021916714919,
                "ivt_i_mAP": 0.616911305718914,
                "ivt_v_mAP": 0.5119051998286193,
                "ivt_t_mAP": 0.3549916744116641,
                "ivt_iv_mAP": 0.347433939473798,
                "ivt_it_mAP": 0.32666436235439944,
                "exact_match_rate": 0.5180921052631579,
                "hamming_accuracy": 0.9926973684210526,
                "action_consistency": 0.9969775095995612,
                "temporal_smoothness": "0.99698204",
                "pred_sparsity": 0.014698464912280702,
                "gt_sparsity": 0.015838815789473683,
                "sparsity_similarity": 0.998859649122807
              },
              "5s": {
                "num_sequences": 1824,
                "total_frames": 1824,
                "horizon_frames": 5,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.2836514760479399,
                "ivt_i_mAP": 0.599411535598826,
                "ivt_v_mAP": 0.4839663837831469,
                "ivt_t_mAP": 0.35017780164835655,
                "ivt_iv_mAP": 0.327918012825884,
                "ivt_it_mAP": 0.30942202776490835,
                "exact_match_rate": 0.48026315789473684,
                "hamming_accuracy": 0.9919736842105263,
                "action_consistency": 0.9972737246297312,
                "temporal_smoothness": "0.99727744",
                "pred_sparsity": 0.01518092105263158,
                "gt_sparsity": 0.015827850877192982,
                "sparsity_similarity": 0.9993530701754386
              }
            }
          },
          "VID79": {
            "video_id": "VID79",
            "total_sequences": 214,
            "successful_predictions": 3414,
            "success_rate": 15.953271028037383,
            "horizon_results": {
              "1s": {
                "num_sequences": 3414,
                "total_frames": 3414,
                "horizon_frames": 1,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.1769405030034684,
                "ivt_i_mAP": 0.7161891051430427,
                "ivt_v_mAP": 0.5675267038504537,
                "ivt_t_mAP": 0.34031364564574984,
                "ivt_iv_mAP": 0.2637395921065325,
                "ivt_it_mAP": 0.2432958533108719,
                "exact_match_rate": 0.4124194493263035,
                "hamming_accuracy": 0.989920913884007,
                "action_consistency": 0.9959244066803399,
                "temporal_smoothness": "0.99593264",
                "pred_sparsity": 0.014086115992970123,
                "gt_sparsity": 0.01664323374340949,
                "sparsity_similarity": 0.9974428822495607
              },
              "2s": {
                "num_sequences": 3414,
                "total_frames": 3414,
                "horizon_frames": 2,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.17877625840125036,
                "ivt_i_mAP": 0.7207491370798835,
                "ivt_v_mAP": 0.5772070492902305,
                "ivt_t_mAP": 0.3500181657357716,
                "ivt_iv_mAP": 0.2669762953793032,
                "ivt_it_mAP": 0.24595068722977872,
                "exact_match_rate": 0.4103690685413005,
                "hamming_accuracy": 0.9892355008787346,
                "action_consistency": 0.9965162613536478,
                "temporal_smoothness": "0.99652237",
                "pred_sparsity": 0.015430579964850616,
                "gt_sparsity": 0.016640304628002343,
                "sparsity_similarity": 0.9987902753368483
              },
              "3s": {
                "num_sequences": 3414,
                "total_frames": 3414,
                "horizon_frames": 3,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.17940927453097266,
                "ivt_i_mAP": 0.7172192360885293,
                "ivt_v_mAP": 0.5720259378882163,
                "ivt_t_mAP": 0.36260162292900217,
                "ivt_iv_mAP": 0.2639084456939039,
                "ivt_it_mAP": 0.24764436792308586,
                "exact_match_rate": 0.3951376684241359,
                "hamming_accuracy": 0.988925014645577,
                "action_consistency": 0.9969323176091415,
                "temporal_smoothness": "0.996937",
                "pred_sparsity": 0.015820152314001173,
                "gt_sparsity": 0.016637375512595195,
                "sparsity_similarity": 0.999182776801406
              },
              "5s": {
                "num_sequences": 3414,
                "total_frames": 3414,
                "horizon_frames": 5,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.16971765717379764,
                "ivt_i_mAP": 0.6785548746778893,
                "ivt_v_mAP": 0.5408879403868514,
                "ivt_t_mAP": 0.3627595050309889,
                "ivt_iv_mAP": 0.24878600260673236,
                "ivt_it_mAP": 0.23861510263943292,
                "exact_match_rate": 0.3670181605155243,
                "hamming_accuracy": 0.9882483889865261,
                "action_consistency": 0.9973542338118957,
                "temporal_smoothness": "0.99735767",
                "pred_sparsity": 0.016104276508494435,
                "gt_sparsity": 0.016631517281780903,
                "sparsity_similarity": 0.9994727592267135
              }
            }
          }
        },
        "evaluation_settings": {
          "context_length": 20,
          "temperature": 0.1,
          "planning_horizons": {
            "1s": 1,
            "2s": 2,
            "3s": 3,
            "5s": 5
          },
          "num_videos": 10
        }
      },
      "model_type": "AutoregressiveIL",
      "evaluation_approach": "comprehensive_with_planning",
      "num_videos_evaluated": 10,
      "publication_metrics": {
        "single_step_mAP": 0.47378119168447325,
        "single_step_ivt_mAP": 0.0,
        "planning_1s_mAP": 0.22600061733111892,
        "planning_2s_mAP": 0.2240916159214069,
        "planning_3s_mAP": 0.21197919675364713,
        "planning_5s_mAP": 0.19421194416102275,
        "evaluation_types": [
          "single_step_recognition",
          "multi_step_planning"
        ],
        "planning_consistency": 0.9968061865790931
      },
      "evaluation_summary": {
        "single_step_performance": 0.47378119168447325,
        "short_term_planning": 0.2240916159214069,
        "medium_term_planning": 0.19421194416102275,
        "planning_degradation": 0.1406574616719822,
        "strength": "Autoregressive planning with causal generation",
        "architecture": "GPT-2 based autoregressive model",
        "planning_horizon_capability": "up_to_5_seconds",
        "target_prediction_type": "next_action_anticipation"
      },
      "performance_analysis": {
        "summary_stats": {
          "num_videos": 10,
          "mAP_stats": {
            "mean": 0.47378119168447325,
            "std": 0.08984882293678319,
            "min": 0.3435142294323908,
            "max": 0.6292837609339351,
            "median": 0.45040332812288697,
            "q25": 0.41664148126779066,
            "q75": 0.512839537344439
          },
          "sparsity_stats": {
            "mean": 0.7308510638297873,
            "std": 0.05729886387019247,
            "correlation_with_mAP": 0.8117349421805653
          }
        },
        "performance_categories": {
          "high_performers": [
            "VID25",
            "VID66"
          ],
          "low_performers": [
            "VID14"
          ],
          "consistent_performers": [
            "VID02",
            "VID06",
            "VID111",
            "VID23",
            "VID50",
            "VID51",
            "VID79"
          ]
        },
        "detailed_rankings": [
          [
            "VID66",
            0.6292837609339351
          ],
          [
            "VID25",
            0.6270298513795706
          ],
          [
            "VID50",
            0.5251583050708625
          ],
          [
            "VID06",
            0.47588323416516853
          ],
          [
            "VID111",
            0.45781293178650684
          ],
          [
            "VID51",
            0.44299372445926705
          ],
          [
            "VID02",
            0.43253052957391186
          ],
          [
            "VID23",
            0.4113451318324169
          ],
          [
            "VID79",
            0.3922602182107021
          ],
          [
            "VID14",
            0.3435142294323908
          ]
        ]
      }
    },
    "method_description": "Autoregressive IL with multi-step planning capabilities",
    "capabilities": {
      "single_step_recognition": 0.47378119168447325,
      "short_term_planning_2s": 0.2240916159214069,
      "planning_degradation": 0.1406574616719822,
      "planning_horizon": "up_to_5_seconds"
    },
    "target_type": "next_action_prediction",
    "planning_ready": true,
    "pretrained": null
  },
  "comprehensive_evaluation": {
    "evaluator": "<evaluation.integrated_evaluation.IntegratedEvaluationFramework object at 0x7f7a728aeaa0>",
    "results": {
      "status": "success",
      "evaluation_type": "comprehensive_evaluation_with_proper_batches",
      "num_models": 1,
      "num_videos": 10,
      "horizon": 15,
      "video_results": {
        "VID02": {
          "video_id": "VID02",
          "evaluation_type": "comprehensive_fair_evaluation_with_proper_batches",
          "single_step_evaluation": {
            "AutoregressiveIL": {
              "metrics": {
                "mAP": 0.3518758401264917,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "28",
                  "subset_action_sparsity": 0.7021276595744681
                },
                "mAP_standard_with_null_verb": 0.7352974195808882,
                "mAP_present_only_with_null_verb": 0.30969829288496514,
                "mAP_freq_weighted_with_null_verb": 0.6595148311768453,
                "mAP_sample_wise_with_null_verb": 0.7081582004214262,
                "mAP_standard_all_actions": 0.7352974195808882,
                "mAP_present_only_all_actions": 0.30969829288496514,
                "mAP_freq_weighted_all_actions": 0.6595148311768453,
                "mAP_sample_wise_all_actions": 0.7081582004214262,
                "exact_match_with_null_verb": 0.3705530116238112,
                "hamming_accuracy_with_null_verb": 0.9899436421275097,
                "precision_with_null_verb": 0.8519134492555747,
                "recall_with_null_verb": 0.7504125679188033,
                "f1_with_null_verb": 0.7923246679086937,
                "num_predictions": 2839,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "34",
                "action_sparsity_with_null_verb": 0.6599999999999999,
                "task": "single_step_action_prediction",
                "method_name": "AutoregressiveIL",
                "exclude_last_n": 6,
                "mAP_standard": 0.775026845995125,
                "mAP_present_only": 0.3518758401264917,
                "mAP_freq_weighted": 0.6861911924380035,
                "exact_match": 0.40894681225783724,
                "hamming_accuracy": 0.9902910074719148,
                "precision": 0.8571262120969281,
                "recall": 0.7628550182810169,
                "f1": 0.8025835359850522,
                "num_actions_total": 94,
                "num_actions_present": "28",
                "action_sparsity": 0.7021276595744681
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": true
            }
          },
          "planning_evaluation": {
            "AutoregressiveIL": {}
          },
          "summary": {
            "primary_comparison": {
              "AutoregressiveIL": {
                "mAP": 0.3518758401264917,
                "exact_match": 0.40894681225783724,
                "task": "single_step_action_prediction"
              }
            },
            "secondary_analysis": {},
            "overall_ranking": {},
            "paradigm_insights": {
              "fair_comparison_task": "single_step_action_prediction",
              "planning_analysis": "shows_method_specific_strengths",
              "evaluation_approach": "respects_training_paradigms"
            }
          },
          "fairness_report": {
            "evaluation_design": {
              "primary_evaluation": "single_step_fair_comparison",
              "secondary_evaluation": "method_specific_planning_analysis",
              "data_handling": "uses_dataloader_batches_like_training",
              "temporal_structure": "maintained_for_il_model",
              "ground_truth_leakage": "eliminated"
            },
            "method_fairness": {
              "AutoregressiveIL": "evaluated_with_proper_temporal_sequences",
              "WorldModelRL": "evaluated_with_consistent_batch_approach",
              "DirectVideoRL": "evaluated_with_consistent_batch_approach"
            },
            "data_integrity": {
              "temporal_context": "preserved_for_models_that_need_it",
              "batch_structure": "mirrors_training_approach",
              "evaluation_consistency": "matches_model_training_interface"
            },
            "comparison_validity": {
              "single_step_comparison": "valid_and_fair_with_proper_data_handling",
              "planning_comparison": "method_specific_respecting_capabilities",
              "overall_approach": "methodologically_sound_and_consistent_with_training"
            }
          }
        },
        "VID06": {
          "video_id": "VID06",
          "evaluation_type": "comprehensive_fair_evaluation_with_proper_batches",
          "single_step_evaluation": {
            "AutoregressiveIL": {
              "metrics": {
                "mAP": 0.415404270186463,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "26",
                  "subset_action_sparsity": 0.7234042553191489
                },
                "mAP_standard_with_null_verb": 0.8046596560254896,
                "mAP_present_only_with_null_verb": 0.38219885341829857,
                "mAP_freq_weighted_with_null_verb": 0.7493482936119285,
                "mAP_sample_wise_with_null_verb": 0.8168507953710554,
                "mAP_standard_all_actions": 0.8046596560254896,
                "mAP_present_only_all_actions": 0.38219885341829857,
                "mAP_freq_weighted_all_actions": 0.7493482936119285,
                "mAP_sample_wise_all_actions": 0.8168507953710554,
                "exact_match_with_null_verb": 0.35624709707385044,
                "hamming_accuracy_with_null_verb": 0.9904830469112865,
                "precision_with_null_verb": 0.8917001317804419,
                "recall_with_null_verb": 0.8070623044565148,
                "f1_with_null_verb": 0.844054163024035,
                "num_predictions": 2153,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "30",
                "action_sparsity_with_null_verb": 0.7,
                "task": "single_step_action_prediction",
                "method_name": "AutoregressiveIL",
                "exclude_last_n": 6,
                "mAP_standard": 0.8276650109026387,
                "mAP_present_only": 0.415404270186463,
                "mAP_freq_weighted": 0.7875777129840148,
                "exact_match": 0.4324198792382722,
                "hamming_accuracy": 0.9913085155794488,
                "precision": 0.8971256357091086,
                "recall": 0.8273402326666508,
                "f1": 0.8587412523618481,
                "num_actions_total": 94,
                "num_actions_present": "26",
                "action_sparsity": 0.7234042553191489
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": true
            }
          },
          "planning_evaluation": {
            "AutoregressiveIL": {}
          },
          "summary": {
            "primary_comparison": {
              "AutoregressiveIL": {
                "mAP": 0.415404270186463,
                "exact_match": 0.4324198792382722,
                "task": "single_step_action_prediction"
              }
            },
            "secondary_analysis": {},
            "overall_ranking": {},
            "paradigm_insights": {
              "fair_comparison_task": "single_step_action_prediction",
              "planning_analysis": "shows_method_specific_strengths",
              "evaluation_approach": "respects_training_paradigms"
            }
          },
          "fairness_report": {
            "evaluation_design": {
              "primary_evaluation": "single_step_fair_comparison",
              "secondary_evaluation": "method_specific_planning_analysis",
              "data_handling": "uses_dataloader_batches_like_training",
              "temporal_structure": "maintained_for_il_model",
              "ground_truth_leakage": "eliminated"
            },
            "method_fairness": {
              "AutoregressiveIL": "evaluated_with_proper_temporal_sequences",
              "WorldModelRL": "evaluated_with_consistent_batch_approach",
              "DirectVideoRL": "evaluated_with_consistent_batch_approach"
            },
            "data_integrity": {
              "temporal_context": "preserved_for_models_that_need_it",
              "batch_structure": "mirrors_training_approach",
              "evaluation_consistency": "matches_model_training_interface"
            },
            "comparison_validity": {
              "single_step_comparison": "valid_and_fair_with_proper_data_handling",
              "planning_comparison": "method_specific_respecting_capabilities",
              "overall_approach": "methodologically_sound_and_consistent_with_training"
            }
          }
        },
        "VID111": {
          "video_id": "VID111",
          "evaluation_type": "comprehensive_fair_evaluation_with_proper_batches",
          "single_step_evaluation": {
            "AutoregressiveIL": {
              "metrics": {
                "mAP": 0.4125697572282243,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "25",
                  "subset_action_sparsity": 0.7340425531914894
                },
                "mAP_standard_with_null_verb": 0.8203023208110691,
                "mAP_present_only_with_null_verb": 0.38035283038299744,
                "mAP_freq_weighted_with_null_verb": 0.6011744798871116,
                "mAP_sample_wise_with_null_verb": 0.6804188118881529,
                "mAP_standard_all_actions": 0.8203023208110691,
                "mAP_present_only_all_actions": 0.38035283038299744,
                "mAP_freq_weighted_all_actions": 0.6011744798871116,
                "mAP_sample_wise_all_actions": 0.6804188118881529,
                "exact_match_with_null_verb": 0.4400932400932401,
                "hamming_accuracy_with_null_verb": 0.9891888111888112,
                "precision_with_null_verb": 0.7825907399974248,
                "recall_with_null_verb": 0.7320326815742632,
                "f1_with_null_verb": 0.7547442571064431,
                "num_predictions": 2145,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "29",
                "action_sparsity_with_null_verb": 0.71,
                "task": "single_step_action_prediction",
                "method_name": "AutoregressiveIL",
                "exclude_last_n": 6,
                "mAP_standard": 0.843768552454315,
                "mAP_present_only": 0.4125697572282243,
                "mAP_freq_weighted": 0.6408787831807463,
                "exact_match": 0.5006993006993007,
                "hamming_accuracy": 0.9907355056291226,
                "precision": 0.7895300899924018,
                "recall": 0.7711785036307544,
                "f1": 0.7800447942270742,
                "num_actions_total": 94,
                "num_actions_present": "25",
                "action_sparsity": 0.7340425531914894
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": true
            }
          },
          "planning_evaluation": {
            "AutoregressiveIL": {}
          },
          "summary": {
            "primary_comparison": {
              "AutoregressiveIL": {
                "mAP": 0.4125697572282243,
                "exact_match": 0.5006993006993007,
                "task": "single_step_action_prediction"
              }
            },
            "secondary_analysis": {},
            "overall_ranking": {},
            "paradigm_insights": {
              "fair_comparison_task": "single_step_action_prediction",
              "planning_analysis": "shows_method_specific_strengths",
              "evaluation_approach": "respects_training_paradigms"
            }
          },
          "fairness_report": {
            "evaluation_design": {
              "primary_evaluation": "single_step_fair_comparison",
              "secondary_evaluation": "method_specific_planning_analysis",
              "data_handling": "uses_dataloader_batches_like_training",
              "temporal_structure": "maintained_for_il_model",
              "ground_truth_leakage": "eliminated"
            },
            "method_fairness": {
              "AutoregressiveIL": "evaluated_with_proper_temporal_sequences",
              "WorldModelRL": "evaluated_with_consistent_batch_approach",
              "DirectVideoRL": "evaluated_with_consistent_batch_approach"
            },
            "data_integrity": {
              "temporal_context": "preserved_for_models_that_need_it",
              "batch_structure": "mirrors_training_approach",
              "evaluation_consistency": "matches_model_training_interface"
            },
            "comparison_validity": {
              "single_step_comparison": "valid_and_fair_with_proper_data_handling",
              "planning_comparison": "method_specific_respecting_capabilities",
              "overall_approach": "methodologically_sound_and_consistent_with_training"
            }
          }
        },
        "VID14": {
          "video_id": "VID14",
          "evaluation_type": "comprehensive_fair_evaluation_with_proper_batches",
          "single_step_evaluation": {
            "AutoregressiveIL": {
              "metrics": {
                "mAP": 0.3202598039995326,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "36",
                  "subset_action_sparsity": 0.6170212765957447
                },
                "mAP_standard_with_null_verb": 0.7109555542746453,
                "mAP_present_only_with_null_verb": 0.2950135470113306,
                "mAP_freq_weighted_with_null_verb": 0.6827553686642769,
                "mAP_sample_wise_with_null_verb": 0.7489211058953402,
                "mAP_standard_all_actions": 0.7109555542746453,
                "mAP_present_only_all_actions": 0.2950135470113306,
                "mAP_freq_weighted_all_actions": 0.6827553686642769,
                "mAP_sample_wise_all_actions": 0.7489211058953402,
                "exact_match_with_null_verb": 0.3881733021077283,
                "hamming_accuracy_with_null_verb": 0.9901580796252928,
                "precision_with_null_verb": 0.8751775789849443,
                "recall_with_null_verb": 0.766429133289134,
                "f1_with_null_verb": 0.8112668265923555,
                "num_predictions": 1708,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "41",
                "action_sparsity_with_null_verb": 0.5900000000000001,
                "task": "single_step_action_prediction",
                "method_name": "AutoregressiveIL",
                "exclude_last_n": 6,
                "mAP_standard": 0.739673967489183,
                "mAP_present_only": 0.3202598039995326,
                "mAP_freq_weighted": 0.7135958135396354,
                "exact_match": 0.44320843091334894,
                "hamming_accuracy": 0.9906634610593452,
                "precision": 0.8796286875577523,
                "recall": 0.7835992650622198,
                "f1": 0.8244192838597648,
                "num_actions_total": 94,
                "num_actions_present": "36",
                "action_sparsity": 0.6170212765957447
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": true
            }
          },
          "planning_evaluation": {
            "AutoregressiveIL": {}
          },
          "summary": {
            "primary_comparison": {
              "AutoregressiveIL": {
                "mAP": 0.3202598039995326,
                "exact_match": 0.44320843091334894,
                "task": "single_step_action_prediction"
              }
            },
            "secondary_analysis": {},
            "overall_ranking": {},
            "paradigm_insights": {
              "fair_comparison_task": "single_step_action_prediction",
              "planning_analysis": "shows_method_specific_strengths",
              "evaluation_approach": "respects_training_paradigms"
            }
          },
          "fairness_report": {
            "evaluation_design": {
              "primary_evaluation": "single_step_fair_comparison",
              "secondary_evaluation": "method_specific_planning_analysis",
              "data_handling": "uses_dataloader_batches_like_training",
              "temporal_structure": "maintained_for_il_model",
              "ground_truth_leakage": "eliminated"
            },
            "method_fairness": {
              "AutoregressiveIL": "evaluated_with_proper_temporal_sequences",
              "WorldModelRL": "evaluated_with_consistent_batch_approach",
              "DirectVideoRL": "evaluated_with_consistent_batch_approach"
            },
            "data_integrity": {
              "temporal_context": "preserved_for_models_that_need_it",
              "batch_structure": "mirrors_training_approach",
              "evaluation_consistency": "matches_model_training_interface"
            },
            "comparison_validity": {
              "single_step_comparison": "valid_and_fair_with_proper_data_handling",
              "planning_comparison": "method_specific_respecting_capabilities",
              "overall_approach": "methodologically_sound_and_consistent_with_training"
            }
          }
        },
        "VID23": {
          "video_id": "VID23",
          "evaluation_type": "comprehensive_fair_evaluation_with_proper_batches",
          "single_step_evaluation": {
            "AutoregressiveIL": {
              "metrics": {
                "mAP": 0.39956490156350494,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "26",
                  "subset_action_sparsity": 0.7234042553191489
                },
                "mAP_standard_with_null_verb": 0.791215368173169,
                "mAP_present_only_with_null_verb": 0.3587592521715127,
                "mAP_freq_weighted_with_null_verb": 0.6441159456912308,
                "mAP_sample_wise_with_null_verb": 0.7546516258558877,
                "mAP_standard_all_actions": 0.791215368173169,
                "mAP_present_only_all_actions": 0.3587592521715127,
                "mAP_freq_weighted_all_actions": 0.6441159456912308,
                "mAP_sample_wise_all_actions": 0.7546516258558877,
                "exact_match_with_null_verb": 0.3712538226299694,
                "hamming_accuracy_with_null_verb": 0.9893761467889908,
                "precision_with_null_verb": 0.8583521690984888,
                "recall_with_null_verb": 0.764111438555819,
                "f1_with_null_verb": 0.8038341347578386,
                "num_predictions": 1635,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "31",
                "action_sparsity_with_null_verb": 0.69,
                "task": "single_step_action_prediction",
                "method_name": "AutoregressiveIL",
                "exclude_last_n": 6,
                "mAP_standard": 0.8232839089430971,
                "mAP_present_only": 0.39956490156350494,
                "mAP_freq_weighted": 0.6687514727371261,
                "exact_match": 0.4434250764525994,
                "hamming_accuracy": 0.9901359880278483,
                "precision": 0.8619562578121089,
                "recall": 0.7831064443379565,
                "f1": 0.8175377228245605,
                "num_actions_total": 94,
                "num_actions_present": "26",
                "action_sparsity": 0.7234042553191489
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": true
            }
          },
          "planning_evaluation": {
            "AutoregressiveIL": {}
          },
          "summary": {
            "primary_comparison": {
              "AutoregressiveIL": {
                "mAP": 0.39956490156350494,
                "exact_match": 0.4434250764525994,
                "task": "single_step_action_prediction"
              }
            },
            "secondary_analysis": {},
            "overall_ranking": {},
            "paradigm_insights": {
              "fair_comparison_task": "single_step_action_prediction",
              "planning_analysis": "shows_method_specific_strengths",
              "evaluation_approach": "respects_training_paradigms"
            }
          },
          "fairness_report": {
            "evaluation_design": {
              "primary_evaluation": "single_step_fair_comparison",
              "secondary_evaluation": "method_specific_planning_analysis",
              "data_handling": "uses_dataloader_batches_like_training",
              "temporal_structure": "maintained_for_il_model",
              "ground_truth_leakage": "eliminated"
            },
            "method_fairness": {
              "AutoregressiveIL": "evaluated_with_proper_temporal_sequences",
              "WorldModelRL": "evaluated_with_consistent_batch_approach",
              "DirectVideoRL": "evaluated_with_consistent_batch_approach"
            },
            "data_integrity": {
              "temporal_context": "preserved_for_models_that_need_it",
              "batch_structure": "mirrors_training_approach",
              "evaluation_consistency": "matches_model_training_interface"
            },
            "comparison_validity": {
              "single_step_comparison": "valid_and_fair_with_proper_data_handling",
              "planning_comparison": "method_specific_respecting_capabilities",
              "overall_approach": "methodologically_sound_and_consistent_with_training"
            }
          }
        },
        "VID25": {
          "video_id": "VID25",
          "evaluation_type": "comprehensive_fair_evaluation_with_proper_batches",
          "single_step_evaluation": {
            "AutoregressiveIL": {
              "metrics": {
                "mAP": 0.5863562351696298,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "21",
                  "subset_action_sparsity": 0.7765957446808511
                },
                "mAP_standard_with_null_verb": 0.8681051210351738,
                "mAP_present_only_with_null_verb": 0.49271200398143805,
                "mAP_freq_weighted_with_null_verb": 0.7491075578278882,
                "mAP_sample_wise_with_null_verb": 0.7993292425248262,
                "mAP_standard_all_actions": 0.8681051210351738,
                "mAP_present_only_all_actions": 0.49271200398143805,
                "mAP_freq_weighted_all_actions": 0.7491075578278882,
                "mAP_sample_wise_all_actions": 0.7993292425248262,
                "exact_match_with_null_verb": 0.40676373884452793,
                "hamming_accuracy_with_null_verb": 0.9908125880695162,
                "precision_with_null_verb": 0.8905770872390841,
                "recall_with_null_verb": 0.8036035676585238,
                "f1_with_null_verb": 0.8414388434861184,
                "num_predictions": 2129,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "26",
                "action_sparsity_with_null_verb": 0.74,
                "task": "single_step_action_prediction",
                "method_name": "AutoregressiveIL",
                "exclude_last_n": 6,
                "mAP_standard": 0.9075902227506619,
                "mAP_present_only": 0.5863562351696298,
                "mAP_freq_weighted": 0.7874914750817867,
                "exact_match": 0.44668858619069984,
                "hamming_accuracy": 0.9914104114407923,
                "precision": 0.893313207659097,
                "recall": 0.8225557208906844,
                "f1": 0.8543068757442227,
                "num_actions_total": 94,
                "num_actions_present": "21",
                "action_sparsity": 0.7765957446808511
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": true
            }
          },
          "planning_evaluation": {
            "AutoregressiveIL": {}
          },
          "summary": {
            "primary_comparison": {
              "AutoregressiveIL": {
                "mAP": 0.5863562351696298,
                "exact_match": 0.44668858619069984,
                "task": "single_step_action_prediction"
              }
            },
            "secondary_analysis": {},
            "overall_ranking": {},
            "paradigm_insights": {
              "fair_comparison_task": "single_step_action_prediction",
              "planning_analysis": "shows_method_specific_strengths",
              "evaluation_approach": "respects_training_paradigms"
            }
          },
          "fairness_report": {
            "evaluation_design": {
              "primary_evaluation": "single_step_fair_comparison",
              "secondary_evaluation": "method_specific_planning_analysis",
              "data_handling": "uses_dataloader_batches_like_training",
              "temporal_structure": "maintained_for_il_model",
              "ground_truth_leakage": "eliminated"
            },
            "method_fairness": {
              "AutoregressiveIL": "evaluated_with_proper_temporal_sequences",
              "WorldModelRL": "evaluated_with_consistent_batch_approach",
              "DirectVideoRL": "evaluated_with_consistent_batch_approach"
            },
            "data_integrity": {
              "temporal_context": "preserved_for_models_that_need_it",
              "batch_structure": "mirrors_training_approach",
              "evaluation_consistency": "matches_model_training_interface"
            },
            "comparison_validity": {
              "single_step_comparison": "valid_and_fair_with_proper_data_handling",
              "planning_comparison": "method_specific_respecting_capabilities",
              "overall_approach": "methodologically_sound_and_consistent_with_training"
            }
          }
        },
        "VID50": {
          "video_id": "VID50",
          "evaluation_type": "comprehensive_fair_evaluation_with_proper_batches",
          "single_step_evaluation": {
            "AutoregressiveIL": {
              "metrics": {
                "mAP": 0.43914752433865195,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "16",
                  "subset_action_sparsity": 0.8297872340425532
                },
                "mAP_standard_with_null_verb": 0.8829385323240395,
                "mAP_present_only_with_null_verb": 0.4052140684668861,
                "mAP_freq_weighted_with_null_verb": 0.7258719903542814,
                "mAP_sample_wise_with_null_verb": 0.7973441711228105,
                "mAP_standard_all_actions": 0.8829385323240395,
                "mAP_present_only_all_actions": 0.4052140684668861,
                "mAP_freq_weighted_all_actions": 0.7258719903542814,
                "mAP_sample_wise_all_actions": 0.7973441711228105,
                "exact_match_with_null_verb": 0.4680073126142596,
                "hamming_accuracy_with_null_verb": 0.9909597806215722,
                "precision_with_null_verb": 0.8759154126137665,
                "recall_with_null_verb": 0.829613795952086,
                "f1_with_null_verb": 0.8511860190235495,
                "num_predictions": 1094,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "18",
                "action_sparsity_with_null_verb": 0.8200000000000001,
                "task": "single_step_action_prediction",
                "method_name": "AutoregressiveIL",
                "exclude_last_n": 6,
                "mAP_standard": 0.8938974509512598,
                "mAP_present_only": 0.43914752433865195,
                "mAP_freq_weighted": 0.7564581014614924,
                "exact_match": 0.5027422303473492,
                "hamming_accuracy": 0.9915107549885254,
                "precision": 0.8812635895074931,
                "recall": 0.8475151302444149,
                "f1": 0.8635772236079489,
                "num_actions_total": 94,
                "num_actions_present": "16",
                "action_sparsity": 0.8297872340425532
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": true
            }
          },
          "planning_evaluation": {
            "AutoregressiveIL": {}
          },
          "summary": {
            "primary_comparison": {
              "AutoregressiveIL": {
                "mAP": 0.43914752433865195,
                "exact_match": 0.5027422303473492,
                "task": "single_step_action_prediction"
              }
            },
            "secondary_analysis": {},
            "overall_ranking": {},
            "paradigm_insights": {
              "fair_comparison_task": "single_step_action_prediction",
              "planning_analysis": "shows_method_specific_strengths",
              "evaluation_approach": "respects_training_paradigms"
            }
          },
          "fairness_report": {
            "evaluation_design": {
              "primary_evaluation": "single_step_fair_comparison",
              "secondary_evaluation": "method_specific_planning_analysis",
              "data_handling": "uses_dataloader_batches_like_training",
              "temporal_structure": "maintained_for_il_model",
              "ground_truth_leakage": "eliminated"
            },
            "method_fairness": {
              "AutoregressiveIL": "evaluated_with_proper_temporal_sequences",
              "WorldModelRL": "evaluated_with_consistent_batch_approach",
              "DirectVideoRL": "evaluated_with_consistent_batch_approach"
            },
            "data_integrity": {
              "temporal_context": "preserved_for_models_that_need_it",
              "batch_structure": "mirrors_training_approach",
              "evaluation_consistency": "matches_model_training_interface"
            },
            "comparison_validity": {
              "single_step_comparison": "valid_and_fair_with_proper_data_handling",
              "planning_comparison": "method_specific_respecting_capabilities",
              "overall_approach": "methodologically_sound_and_consistent_with_training"
            }
          }
        },
        "VID51": {
          "video_id": "VID51",
          "evaluation_type": "comprehensive_fair_evaluation_with_proper_batches",
          "single_step_evaluation": {
            "AutoregressiveIL": {
              "metrics": {
                "mAP": 0.43395100216387256,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "24",
                  "subset_action_sparsity": 0.7446808510638299
                },
                "mAP_standard_with_null_verb": 0.8240899895066259,
                "mAP_present_only_with_null_verb": 0.3934137569193998,
                "mAP_freq_weighted_with_null_verb": 0.7098619104382696,
                "mAP_sample_wise_with_null_verb": 0.7453932659988656,
                "mAP_standard_all_actions": 0.8240899895066259,
                "mAP_present_only_all_actions": 0.3934137569193998,
                "mAP_freq_weighted_all_actions": 0.7098619104382696,
                "mAP_sample_wise_all_actions": 0.7453932659988656,
                "exact_match_with_null_verb": 0.3648097826086957,
                "hamming_accuracy_with_null_verb": 0.9899422554347826,
                "precision_with_null_verb": 0.859279836123386,
                "recall_with_null_verb": 0.7685568220780206,
                "f1_with_null_verb": 0.807131806772056,
                "num_predictions": 2944,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "29",
                "action_sparsity_with_null_verb": 0.71,
                "task": "single_step_action_prediction",
                "method_name": "AutoregressiveIL",
                "exclude_last_n": 6,
                "mAP_standard": 0.8554768516163078,
                "mAP_present_only": 0.43395100216387256,
                "mAP_freq_weighted": 0.754174470799223,
                "exact_match": 0.4279891304347826,
                "hamming_accuracy": 0.9908830076318224,
                "precision": 0.8679509254213824,
                "recall": 0.7847776722861934,
                "f1": 0.820886500667036,
                "num_actions_total": 94,
                "num_actions_present": "24",
                "action_sparsity": 0.7446808510638299
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": true
            }
          },
          "planning_evaluation": {
            "AutoregressiveIL": {}
          },
          "summary": {
            "primary_comparison": {
              "AutoregressiveIL": {
                "mAP": 0.43395100216387256,
                "exact_match": 0.4279891304347826,
                "task": "single_step_action_prediction"
              }
            },
            "secondary_analysis": {},
            "overall_ranking": {},
            "paradigm_insights": {
              "fair_comparison_task": "single_step_action_prediction",
              "planning_analysis": "shows_method_specific_strengths",
              "evaluation_approach": "respects_training_paradigms"
            }
          },
          "fairness_report": {
            "evaluation_design": {
              "primary_evaluation": "single_step_fair_comparison",
              "secondary_evaluation": "method_specific_planning_analysis",
              "data_handling": "uses_dataloader_batches_like_training",
              "temporal_structure": "maintained_for_il_model",
              "ground_truth_leakage": "eliminated"
            },
            "method_fairness": {
              "AutoregressiveIL": "evaluated_with_proper_temporal_sequences",
              "WorldModelRL": "evaluated_with_consistent_batch_approach",
              "DirectVideoRL": "evaluated_with_consistent_batch_approach"
            },
            "data_integrity": {
              "temporal_context": "preserved_for_models_that_need_it",
              "batch_structure": "mirrors_training_approach",
              "evaluation_consistency": "matches_model_training_interface"
            },
            "comparison_validity": {
              "single_step_comparison": "valid_and_fair_with_proper_data_handling",
              "planning_comparison": "method_specific_respecting_capabilities",
              "overall_approach": "methodologically_sound_and_consistent_with_training"
            }
          }
        },
        "VID66": {
          "video_id": "VID66",
          "evaluation_type": "comprehensive_fair_evaluation_with_proper_batches",
          "single_step_evaluation": {
            "AutoregressiveIL": {
              "metrics": {
                "mAP": 0.6050073104729583,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "20",
                  "subset_action_sparsity": 0.7872340425531915
                },
                "mAP_standard_with_null_verb": 0.8834849757133708,
                "mAP_present_only_with_null_verb": 0.5368911987537858,
                "mAP_freq_weighted_with_null_verb": 0.8351676242412274,
                "mAP_sample_wise_with_null_verb": 0.8589606780388269,
                "mAP_standard_all_actions": 0.8834849757133708,
                "mAP_present_only_all_actions": 0.5368911987537858,
                "mAP_freq_weighted_all_actions": 0.8351676242412274,
                "mAP_sample_wise_all_actions": 0.8589606780388269,
                "exact_match_with_null_verb": 0.5356359649122807,
                "hamming_accuracy_with_null_verb": 0.9934100877192983,
                "precision_with_null_verb": 0.9209028381117454,
                "recall_with_null_verb": 0.8556561004227632,
                "f1_with_null_verb": 0.8854430732088469,
                "num_predictions": 1824,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "23",
                "action_sparsity_with_null_verb": 0.77,
                "task": "single_step_action_prediction",
                "method_name": "AutoregressiveIL",
                "exclude_last_n": 6,
                "mAP_standard": 0.9053207043559486,
                "mAP_present_only": 0.6050073104729583,
                "mAP_freq_weighted": 0.8593414943992266,
                "exact_match": 0.5526315789473685,
                "hamming_accuracy": 0.993631019036954,
                "precision": 0.9253598860414678,
                "recall": 0.8660162177867108,
                "f1": 0.8933832377884114,
                "num_actions_total": 94,
                "num_actions_present": "20",
                "action_sparsity": 0.7872340425531915
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": true
            }
          },
          "planning_evaluation": {
            "AutoregressiveIL": {}
          },
          "summary": {
            "primary_comparison": {
              "AutoregressiveIL": {
                "mAP": 0.6050073104729583,
                "exact_match": 0.5526315789473685,
                "task": "single_step_action_prediction"
              }
            },
            "secondary_analysis": {},
            "overall_ranking": {},
            "paradigm_insights": {
              "fair_comparison_task": "single_step_action_prediction",
              "planning_analysis": "shows_method_specific_strengths",
              "evaluation_approach": "respects_training_paradigms"
            }
          },
          "fairness_report": {
            "evaluation_design": {
              "primary_evaluation": "single_step_fair_comparison",
              "secondary_evaluation": "method_specific_planning_analysis",
              "data_handling": "uses_dataloader_batches_like_training",
              "temporal_structure": "maintained_for_il_model",
              "ground_truth_leakage": "eliminated"
            },
            "method_fairness": {
              "AutoregressiveIL": "evaluated_with_proper_temporal_sequences",
              "WorldModelRL": "evaluated_with_consistent_batch_approach",
              "DirectVideoRL": "evaluated_with_consistent_batch_approach"
            },
            "data_integrity": {
              "temporal_context": "preserved_for_models_that_need_it",
              "batch_structure": "mirrors_training_approach",
              "evaluation_consistency": "matches_model_training_interface"
            },
            "comparison_validity": {
              "single_step_comparison": "valid_and_fair_with_proper_data_handling",
              "planning_comparison": "method_specific_respecting_capabilities",
              "overall_approach": "methodologically_sound_and_consistent_with_training"
            }
          }
        },
        "VID79": {
          "video_id": "VID79",
          "evaluation_type": "comprehensive_fair_evaluation_with_proper_batches",
          "single_step_evaluation": {
            "AutoregressiveIL": {
              "metrics": {
                "mAP": 0.33735297261153774,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "31",
                  "subset_action_sparsity": 0.6702127659574468
                },
                "mAP_standard_with_null_verb": 0.7405011789519732,
                "mAP_present_only_with_null_verb": 0.30694771931103665,
                "mAP_freq_weighted_with_null_verb": 0.7608181309831564,
                "mAP_sample_wise_with_null_verb": 0.7793234639505056,
                "mAP_standard_all_actions": 0.7405011789519732,
                "mAP_present_only_all_actions": 0.30694771931103665,
                "mAP_freq_weighted_all_actions": 0.7608181309831564,
                "mAP_sample_wise_all_actions": 0.7793234639505056,
                "exact_match_with_null_verb": 0.4179847685998828,
                "hamming_accuracy_with_null_verb": 0.9901523140011717,
                "precision_with_null_verb": 0.8741918070107878,
                "recall_with_null_verb": 0.8005231995856028,
                "f1_with_null_verb": 0.8331800062935376,
                "num_predictions": 3414,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "36",
                "action_sparsity_with_null_verb": 0.64,
                "task": "single_step_action_prediction",
                "method_name": "AutoregressiveIL",
                "exclude_last_n": 6,
                "mAP_standard": 0.7708291718186986,
                "mAP_present_only": 0.33735297261153774,
                "mAP_freq_weighted": 0.7907170741346765,
                "exact_match": 0.44932630345635616,
                "hamming_accuracy": 0.9906299467773498,
                "precision": 0.8834654203153003,
                "recall": 0.81094756193244,
                "f1": 0.8432737838784783,
                "num_actions_total": 94,
                "num_actions_present": "31",
                "action_sparsity": 0.6702127659574468
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": true
            }
          },
          "planning_evaluation": {
            "AutoregressiveIL": {}
          },
          "summary": {
            "primary_comparison": {
              "AutoregressiveIL": {
                "mAP": 0.33735297261153774,
                "exact_match": 0.44932630345635616,
                "task": "single_step_action_prediction"
              }
            },
            "secondary_analysis": {},
            "overall_ranking": {},
            "paradigm_insights": {
              "fair_comparison_task": "single_step_action_prediction",
              "planning_analysis": "shows_method_specific_strengths",
              "evaluation_approach": "respects_training_paradigms"
            }
          },
          "fairness_report": {
            "evaluation_design": {
              "primary_evaluation": "single_step_fair_comparison",
              "secondary_evaluation": "method_specific_planning_analysis",
              "data_handling": "uses_dataloader_batches_like_training",
              "temporal_structure": "maintained_for_il_model",
              "ground_truth_leakage": "eliminated"
            },
            "method_fairness": {
              "AutoregressiveIL": "evaluated_with_proper_temporal_sequences",
              "WorldModelRL": "evaluated_with_consistent_batch_approach",
              "DirectVideoRL": "evaluated_with_consistent_batch_approach"
            },
            "data_integrity": {
              "temporal_context": "preserved_for_models_that_need_it",
              "batch_structure": "mirrors_training_approach",
              "evaluation_consistency": "matches_model_training_interface"
            },
            "comparison_validity": {
              "single_step_comparison": "valid_and_fair_with_proper_data_handling",
              "planning_comparison": "method_specific_respecting_capabilities",
              "overall_approach": "methodologically_sound_and_consistent_with_training"
            }
          }
        }
      },
      "aggregate_results": {
        "single_step_comparison": {
          "AutoregressiveIL": {
            "mean_mAP": 0.43014896178608675,
            "std_mAP": 0.09129447260687798,
            "mean_exact_match": 0.4608077328937915,
            "std_exact_match": 0.04158967378469676,
            "num_videos": 10,
            "evaluation_type": "single_step_fair_comparison"
          }
        },
        "planning_analysis": {},
        "method_rankings": {
          "single_step_ranking": [
            [
              "AutoregressiveIL",
              0.43014896178608675
            ]
          ],
          "planning_ranking": []
        }
      },
      "statistical_tests": {},
      "evaluation_design": {
        "data_handling": "uses_dataloader_batches_like_training",
        "temporal_structure": "maintained_properly",
        "model_interfaces": "consistent_with_training",
        "primary_evaluation": "single_step_action_prediction_with_proper_context",
        "secondary_evaluation": "multi_step_planning_analysis",
        "fairness_approach": "respects_training_paradigms_and_data_structure"
      },
      "timestamp": "2025-06-26 12:39:05.582053"
    },
    "file_paths": {
      "evaluation": "results/2025-06-26_11-35-49/fold0/integrated_evaluation/evaluation_results.json",
      "fair_comparison": "results/2025-06-26_11-35-49/fold0/integrated_evaluation/fair_single_step_comparison.csv",
      "planning_analysis": "results/2025-06-26_11-35-49/fold0/integrated_evaluation/planning_capability_analysis.csv"
    }
  },
  "generated_plots": {
    "per_video_performance": "results/2025-06-26_11-35-49/fold0/publication_plots/per_video_performance_analysis.png",
    "performance_dashboard": "results/2025-06-26_11-35-49/fold0/publication_plots/performance_dashboard.png"
  }
}