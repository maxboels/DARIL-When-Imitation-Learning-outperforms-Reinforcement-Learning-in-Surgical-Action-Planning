{
  "experiment_name": "2025-06-26_16-08-06",
  "config": {
    "debug": false,
    "experiment": {
      "train": {
        "max_videos": 40
      },
      "test": {
        "max_videos": 10,
        "test_on_train": false
      },
      "autoregressive_il": {
        "enabled": true,
        "train": true,
        "evaluate": true,
        "il_model_path": null,
        "recognition": {
          "enabled": false,
          "ivt_map": 36.1
        }
      },
      "world_model": {
        "enabled": false,
        "wm_model_path": "results/fixed_rl_2025-06-13_19-22-25/logs/checkpoints/world_model_best_epoch_1.pt"
      },
      "rl_experiments": {
        "enabled": false,
        "eval_episodes": 10
      }
    },
    "training": {
      "epochs": 15,
      "batch_size": 8,
      "learning_rate": "5e-5",
      "log_every_n_steps": 20,
      "optimizer_type": "adamw",
      "weight_decay": 0.02,
      "gradient_clip_val": 0.5,
      "scheduler": {
        "type": "cosine_with_warmup",
        "warmup_epochs": 2,
        "eta_min": "1e-6"
      },
      "parameter_groups": {
        "bilstm_recognition": {
          "lr_multiplier": 1.0,
          "weight_decay_multiplier": 0.3
        },
        "gpt2_backbone": {
          "lr_multiplier": 0.3,
          "weight_decay_multiplier": 0.8
        },
        "frame_processing": {
          "lr_multiplier": 0.5,
          "weight_decay_multiplier": 1.5
        },
        "action_prediction": {
          "lr_multiplier": 1.5,
          "weight_decay_multiplier": 0.2
        },
        "auxiliary_heads": {
          "lr_multiplier": 0.8,
          "weight_decay_multiplier": 1.0
        }
      },
      "lr_monitoring": {
        "track_gradients": true,
        "track_parameters": true,
        "log_frequency": 50,
        "save_plots": true,
        "generate_recommendations": true
      },
      "augmentation": {
        "temporal_crop_ratio": 0.85,
        "temporal_jitter_std": 0.02,
        "sequence_shuffle_prob": 0.1,
        "frame_dropout_prob": 0.05
      },
      "early_stopping": {
        "patience": 8,
        "min_delta": 0.001,
        "monitor": "val_action_mAP"
      },
      "num_workers": 2,
      "pin_memory": true,
      "log_dir": "logs",
      "checkpoint_dir": "checkpoints",
      "eval_epoch_interval": 1,
      "save_model": true,
      "checkpointing": {
        "save_best_only": false,
        "save_top_k": 5,
        "monitor": "val_action_mAP",
        "mode": "max",
        "save_every_n_epochs": 5
      }
    },
    "evaluation": {
      "prediction_horizon": 8,
      "comprehensive_evaluation": {
        "per_video_analysis": true,
        "statistical_significance": true,
        "confidence_intervals": true,
        "baseline_comparison": 36.1
      },
      "supervised": {
        "action_prediction": true
      },
      "rl": {
        "rollout_horizon": 15,
        "use_best_actions": true
      },
      "comparison": {
        "statistical_tests": true,
        "effect_size_threshold": 0.15
      },
      "world_model": {
        "use_memory": false,
        "overall_horizon": 1
      }
    },
    "rl_training": {
      "action_space_type": "continuous",
      "outcome_based_rewards": true,
      "rl_horizon": 30,
      "reward_mode": "dense",
      "normalize_rewards": true,
      "early_termination": true,
      "timesteps": 50000,
      "reward_weights": {
        "expert_matching": 10.0,
        "action_sparsity": 1.0,
        "world_model_rewards": 0.5,
        "completion_bonus": 5.0,
        "consistency_bonus": 1.0,
        "phase_completion": 1.0,
        "risk_penalty": -0.5
      },
      "ppo": {
        "learning_rate": "5e-5",
        "n_steps": 512,
        "batch_size": 64,
        "n_epochs": 10,
        "gamma": 0.95,
        "gae_lambda": 0.9,
        "clip_range": 0.1,
        "ent_coef": 0.05,
        "vf_coef": 0.5,
        "max_grad_norm": 0.5
      },
      "a2c": {
        "learning_rate": "1e-4",
        "n_steps": 32,
        "gamma": 0.95,
        "gae_lambda": 0.9,
        "ent_coef": 0.05,
        "vf_coef": 0.25,
        "max_grad_norm": 0.5
      }
    },
    "data": {
      "context_length": 12,
      "train_shift": 1,
      "padding_value": 0.0,
      "max_horizon": 8,
      "normalize_embeddings": true,
      "embedding_noise": 0.01,
      "paths": {
        "data_dir": "/home/maxboels/datasets/CholecT50",
        "class_labels_file_path": "./data/labels.json",
        "fold": 0,
        "metadata_file": "embeddings_f0_swin_bas_129_phase_complet_phase_transit_prog_prob_action_risk_glob_outcome.csv",
        "video_global_outcome_file": "embeddings_f1_swin_bas_129_with_enhanced_global_metrics.csv"
      },
      "frame_risk_agg": "max"
    },
    "training_mode": "rl",
    "preprocess": {
      "extract_rewards": false,
      "analyze_rewards": false,
      "rewards": {
        "grounded": {
          "phase_completion": true,
          "phase_transition": true,
          "phase_progression": true,
          "global_progression": true
        },
        "imitation": {
          "action_distribution": true
        },
        "expert_knowledge": {
          "risk_score": true,
          "frame_risk_agg": "max"
        }
      }
    },
    "models": {
      "autoregressive_il": {
        "hidden_dim": 384,
        "embedding_dim": 1024,
        "n_layer": 3,
        "num_action_classes": 100,
        "num_phase_classes": 7,
        "dropout": 0.3,
        "max_length": 256,
        "layer_dropout": 0.15,
        "attention_dropout": 0.2,
        "frame_projection_dropout": 0.2,
        "bilstm_layers": 1,
        "bilstm_dropout": 0.25,
        "bilstm_bidirectional": true
      },
      "conditional_world_model": {
        "hidden_dim": 512,
        "embedding_dim": 1024,
        "action_embedding_dim": 128,
        "n_layer": 4,
        "num_action_classes": 100,
        "num_phase_classes": 7,
        "dropout": 0.1,
        "max_sequence_length": 512
      }
    },
    "loss_weights": {
      "recognition": 1.0,
      "generation": 2.0,
      "frame_reconstruction": 0.2,
      "phase_prediction": 0.5
    },
    "fair_evaluation": {
      "enabled": true,
      "include_traditional_metrics": true,
      "include_clinical_metrics": true,
      "per_video_analysis": {
        "enabled": true,
        "save_individual_results": true,
        "statistical_aggregation": true,
        "baseline_comparison": 36.1
      },
      "clinical_outcome_weights": {
        "phase_progression": 2.0,
        "innovation": 0.5
      }
    },
    "supervised_learning": {
      "data_augmentation": true
    },
    "research_comparison": {
      "methods": [
        "autoregressive_il",
        "conditional_world_model",
        "direct_video_rl"
      ]
    },
    "advanced": {
      "mixed_precision": false
    },
    "hardware": {
      "persistent_workers": false,
      "mixed_precision": false
    },
    "rl_debugging": {
      "enabled": true,
      "save_training_curves": true,
      "monitor_expert_matching": true,
      "log_action_distributions": true,
      "convergence_analysis": true,
      "episode_log_frequency": 10,
      "eval_frequency": 1000,
      "reward_improvement_threshold": 0.1,
      "expert_matching_threshold": 0.5,
      "debug_dir": "rl_debug",
      "plot_dir": "rl_plots"
    },
    "il_debugging": {
      "enabled": true,
      "convergence_tracking": {
        "early_plateau_detection": true,
        "overfitting_detection": true,
        "feature_utilization_analysis": true
      },
      "baseline_comparison": {
        "swin_recognition_mAP": 36.1,
        "improvement_threshold": 1.0
      },
      "temporal_evaluation": {
        "short_term_prediction": true,
        "medium_term_prediction": true,
        "temporal_consistency": true,
        "sequence_modeling_analysis": true
      }
    },
    "il_performance_targets": {
      "recognition_mAP_target": 38.0,
      "generation_mAP_target": 35.0,
      "convergence_epoch": 5,
      "minimum_improvement": 1.0,
      "maximum_overfitting": 5.0
    }
  },
  "timestamp": "2025-06-26_16-08-06",
  "results_dir": "results/2025-06-26_16-08-06/fold0",
  "method_1_autoregressive_il": {
    "status": "success",
    "model_path": "results/2025-06-26_16-08-06/fold0/logs/checkpoints/autoregressive_il_best_epoch_1.pt",
    "model_type": "AutoregressiveIL",
    "approach": "Causal frame generation \u2192 action anticipation",
    "evaluation": {
      "overall_metrics": {
        "ivt_current_mAP": 0.3408039070164103,
        "ivt_rec_i_mAP": 0.9159243975250062,
        "ivt_rec_v_mAP": 0.6955406625158344,
        "ivt_rec_t_mAP": 0.5299918360396106,
        "ivt_rec_iv_mAP": 0.42447486628345527,
        "ivt_rec_it_mAP": 0.43211868889253563,
        "ivt_next_mAP": 0.3363409941885953,
        "ivt_i_mAP": 0.8887098609907187,
        "ivt_v_mAP": 0.6993035104123201,
        "ivt_t_mAP": 0.5408391853348132,
        "ivt_iv_mAP": 0.39968544051674965,
        "ivt_it_mAP": 0.43649162778628414,
        "phase_loss": 1.2928618271613683,
        "action_rec_loss": 0.04118569810059245,
        "total_loss": 0.5654126802197609,
        "action_loss": 0.03606322803837225,
        "frame_loss": 0.18995623402341957,
        "consistency_loss": 0.002046031191518233,
        "action_mAP": 0.5057570338845174,
        "action_mAP_standard": 0.8403347423992011,
        "action_mAP_freq_weighted": 0.7678081681740514,
        "action_exact_match": 0.48176293338755183,
        "action_hamming_accuracy": 0.9913163860731509,
        "action_precision": 0.8705791522910765,
        "action_recall": 0.8205420793036649,
        "action_f1": 0.8433994054016603,
        "action_sparsity": 0.7308510638297873,
        "num_actions_present": 25.3,
        "action_mAP_with_null_verb": 0.46234936245660474,
        "action_exact_match_with_null_verb": 0.4355311386634141,
        "action_sparsity_with_null_verb": 0.7030000000000001,
        "num_actions_total": 94.0,
        "num_actions_total_with_null_verb": 100.0,
        "action_mAP_std": 0.09745888585577783,
        "action_exact_match_std": 0.037817938941554385,
        "action_sparsity_std": 0.05729886387019247,
        "planning_1s_mAP": 0.23367564789839707,
        "planning_2s_mAP": 0.22392161630888782,
        "planning_3s_mAP": 0.21039478006797477,
        "planning_5s_mAP": 0.19131999992543716,
        "planning_available": true
      },
      "detailed_video_metrics": {
        "VID02": {
          "mAP": 0.4745481434041167,
          "mAP_info": {
            "calculated_from": "subset_excluding_last_classes_present_actions_only",
            "excluded_classes": 6,
            "subset_size": 94,
            "present_actions_in_subset": "28",
            "subset_action_sparsity": 0.7021276595744681
          },
          "mAP_standard_with_null_verb": 0.7451442918049562,
          "mAP_present_only_with_null_verb": 0.4268949758969306,
          "mAP_freq_weighted_with_null_verb": 0.7046278440530059,
          "mAP_sample_wise_with_null_verb": 0.7215540054403436,
          "mAP_standard_all_actions": 0.7451442918049562,
          "mAP_present_only_all_actions": 0.4268949758969306,
          "mAP_freq_weighted_all_actions": 0.7046278440530059,
          "mAP_sample_wise_all_actions": 0.7215540054403436,
          "exact_match_with_null_verb": 0.39415287072912997,
          "hamming_accuracy_with_null_verb": 0.9899189855582952,
          "precision_with_null_verb": 0.8413115657294281,
          "recall_with_null_verb": 0.7689089013979544,
          "f1_with_null_verb": 0.8006648717065352,
          "num_predictions": 2839,
          "num_actions_total_with_null_verb": 100,
          "num_actions_present_with_null_verb": "34",
          "action_sparsity_with_null_verb": 0.6599999999999999,
          "task": "single_step_action_prediction",
          "method_name": "AutoregressiveIL_video_VID02_epoch_-1",
          "exclude_last_n": 6,
          "mAP_standard": 0.7796526384608008,
          "mAP_present_only": 0.4745481434041167,
          "mAP_freq_weighted": 0.7277235814382942,
          "exact_match": 0.4258541740049313,
          "hamming_accuracy": 0.9903921818440715,
          "precision": 0.8502007837930197,
          "recall": 0.7814119546048002,
          "f1": 0.8119308798581208,
          "num_actions_total": 94,
          "num_actions_present": "28",
          "action_sparsity": 0.7021276595744681
        },
        "VID06": {
          "mAP": 0.5629868533825343,
          "mAP_info": {
            "calculated_from": "subset_excluding_last_classes_present_actions_only",
            "excluded_classes": 6,
            "subset_size": 94,
            "present_actions_in_subset": "26",
            "subset_action_sparsity": 0.7234042553191489
          },
          "mAP_standard_with_null_verb": 0.8410778296415026,
          "mAP_present_only_with_null_verb": 0.5369260988050083,
          "mAP_freq_weighted_with_null_verb": 0.7679851701652056,
          "mAP_sample_wise_with_null_verb": 0.8457812095573194,
          "mAP_standard_all_actions": 0.8410778296415026,
          "mAP_present_only_all_actions": 0.5369260988050083,
          "mAP_freq_weighted_all_actions": 0.7679851701652056,
          "mAP_sample_wise_all_actions": 0.8457812095573194,
          "exact_match_with_null_verb": 0.41012540640966094,
          "hamming_accuracy_with_null_verb": 0.9909893172317696,
          "precision_with_null_verb": 0.8946777327499968,
          "recall_with_null_verb": 0.8230491164914997,
          "f1_with_null_verb": 0.855147964799254,
          "num_predictions": 2153,
          "num_actions_total_with_null_verb": 100,
          "num_actions_present_with_null_verb": "30",
          "action_sparsity_with_null_verb": 0.7,
          "task": "single_step_action_prediction",
          "method_name": "AutoregressiveIL_video_VID06_epoch_-1",
          "exclude_last_n": 6,
          "mAP_standard": 0.8578474275313392,
          "mAP_present_only": 0.5629868533825343,
          "mAP_freq_weighted": 0.8003820112308359,
          "exact_match": 0.4737575476079888,
          "hamming_accuracy": 0.9917581603106995,
          "precision": 0.8971630004593161,
          "recall": 0.8451144234349092,
          "f1": 0.8692420137021677,
          "num_actions_total": 94,
          "num_actions_present": "26",
          "action_sparsity": 0.7234042553191489
        },
        "VID111": {
          "mAP": 0.46984197570875447,
          "mAP_info": {
            "calculated_from": "subset_excluding_last_classes_present_actions_only",
            "excluded_classes": 6,
            "subset_size": 94,
            "present_actions_in_subset": "25",
            "subset_action_sparsity": 0.7340425531914894
          },
          "mAP_standard_with_null_verb": 0.8338916521320888,
          "mAP_present_only_with_null_verb": 0.4272125935589272,
          "mAP_freq_weighted_with_null_verb": 0.5991827385640303,
          "mAP_sample_wise_with_null_verb": 0.7104556190146875,
          "mAP_standard_all_actions": 0.8338916521320888,
          "mAP_present_only_all_actions": 0.4272125935589272,
          "mAP_freq_weighted_all_actions": 0.5991827385640303,
          "mAP_sample_wise_all_actions": 0.7104556190146875,
          "exact_match_with_null_verb": 0.4568764568764569,
          "hamming_accuracy_with_null_verb": 0.9894172494172494,
          "precision_with_null_verb": 0.7882476586702085,
          "recall_with_null_verb": 0.737221586014887,
          "f1_with_null_verb": 0.7601744427019288,
          "num_predictions": 2145,
          "num_actions_total_with_null_verb": 100,
          "num_actions_present_with_null_verb": "29",
          "action_sparsity_with_null_verb": 0.71,
          "task": "single_step_action_prediction",
          "method_name": "AutoregressiveIL_video_VID111_epoch_-1",
          "exclude_last_n": 6,
          "mAP_standard": 0.8590005254544559,
          "mAP_present_only": 0.46984197570875447,
          "mAP_freq_weighted": 0.6472584970612919,
          "exact_match": 0.5174825174825175,
          "hamming_accuracy": 0.9908644546942419,
          "precision": 0.7916162238594593,
          "recall": 0.780164600422945,
          "f1": 0.7857722257115367,
          "num_actions_total": 94,
          "num_actions_present": "25",
          "action_sparsity": 0.7340425531914894
        },
        "VID14": {
          "mAP": 0.35076594976142184,
          "mAP_info": {
            "calculated_from": "subset_excluding_last_classes_present_actions_only",
            "excluded_classes": 6,
            "subset_size": 94,
            "present_actions_in_subset": "36",
            "subset_action_sparsity": 0.6170212765957447
          },
          "mAP_standard_with_null_verb": 0.7129706003935502,
          "mAP_present_only_with_null_verb": 0.3243185375452442,
          "mAP_freq_weighted_with_null_verb": 0.6878323382644134,
          "mAP_sample_wise_with_null_verb": 0.7631174729752386,
          "mAP_standard_all_actions": 0.7129706003935502,
          "mAP_present_only_all_actions": 0.3243185375452442,
          "mAP_freq_weighted_all_actions": 0.6878323382644134,
          "mAP_sample_wise_all_actions": 0.7631174729752386,
          "exact_match_with_null_verb": 0.4332552693208431,
          "hamming_accuracy_with_null_verb": 0.9904391100702576,
          "precision_with_null_verb": 0.8699347721580228,
          "recall_with_null_verb": 0.7879772660132356,
          "f1_with_null_verb": 0.823668054938301,
          "num_predictions": 1708,
          "num_actions_total_with_null_verb": 100,
          "num_actions_present_with_null_verb": "41",
          "action_sparsity_with_null_verb": 0.5900000000000001,
          "task": "single_step_action_prediction",
          "method_name": "AutoregressiveIL_video_VID14_epoch_-1",
          "exclude_last_n": 6,
          "mAP_standard": 0.7407188743767146,
          "mAP_present_only": 0.35076594976142184,
          "mAP_freq_weighted": 0.7198325709247779,
          "exact_match": 0.4847775175644028,
          "hamming_accuracy": 0.9909188300363745,
          "precision": 0.8726728431719064,
          "recall": 0.8065413316850656,
          "f1": 0.8362712819593029,
          "num_actions_total": 94,
          "num_actions_present": "36",
          "action_sparsity": 0.6170212765957447
        },
        "VID23": {
          "mAP": 0.4666372981812242,
          "mAP_info": {
            "calculated_from": "subset_excluding_last_classes_present_actions_only",
            "excluded_classes": 6,
            "subset_size": 94,
            "present_actions_in_subset": "26",
            "subset_action_sparsity": 0.7234042553191489
          },
          "mAP_standard_with_null_verb": 0.7995438180838942,
          "mAP_present_only_with_null_verb": 0.41788328414159404,
          "mAP_freq_weighted_with_null_verb": 0.6842719068297112,
          "mAP_sample_wise_with_null_verb": 0.744354603265612,
          "mAP_standard_all_actions": 0.7995438180838942,
          "mAP_present_only_all_actions": 0.41788328414159404,
          "mAP_freq_weighted_all_actions": 0.6842719068297112,
          "mAP_sample_wise_all_actions": 0.744354603265612,
          "exact_match_with_null_verb": 0.38776758409785933,
          "hamming_accuracy_with_null_verb": 0.9895290519877676,
          "precision_with_null_verb": 0.859305321899571,
          "recall_with_null_verb": 0.7704596971272915,
          "f1_with_null_verb": 0.8083830170967184,
          "num_predictions": 1635,
          "num_actions_total_with_null_verb": 100,
          "num_actions_present_with_null_verb": "31",
          "action_sparsity_with_null_verb": 0.69,
          "task": "single_step_action_prediction",
          "method_name": "AutoregressiveIL_video_VID23_epoch_-1",
          "exclude_last_n": 6,
          "mAP_standard": 0.8418358484331048,
          "mAP_present_only": 0.4666372981812242,
          "mAP_freq_weighted": 0.7155047184328776,
          "exact_match": 0.46238532110091746,
          "hamming_accuracy": 0.9904157720085888,
          "precision": 0.8657786147807331,
          "recall": 0.7911500037351171,
          "f1": 0.824072156214904,
          "num_actions_total": 94,
          "num_actions_present": "26",
          "action_sparsity": 0.7234042553191489
        },
        "VID25": {
          "mAP": 0.6604027110289054,
          "mAP_info": {
            "calculated_from": "subset_excluding_last_classes_present_actions_only",
            "excluded_classes": 6,
            "subset_size": 94,
            "present_actions_in_subset": "21",
            "subset_action_sparsity": 0.7765957446808511
          },
          "mAP_standard_with_null_verb": 0.8876659823208315,
          "mAP_present_only_with_null_verb": 0.5679460858493524,
          "mAP_freq_weighted_with_null_verb": 0.7757416540060482,
          "mAP_sample_wise_with_null_verb": 0.8125599111447142,
          "mAP_standard_all_actions": 0.8876659823208315,
          "mAP_present_only_all_actions": 0.5679460858493524,
          "mAP_freq_weighted_all_actions": 0.7757416540060482,
          "mAP_sample_wise_all_actions": 0.8125599111447142,
          "exact_match_with_null_verb": 0.41944574917801786,
          "hamming_accuracy_with_null_verb": 0.991211836542978,
          "precision_with_null_verb": 0.8956330659481977,
          "recall_with_null_verb": 0.813420688725853,
          "f1_with_null_verb": 0.849583612859147,
          "num_predictions": 2129,
          "num_actions_total_with_null_verb": 100,
          "num_actions_present_with_null_verb": "26",
          "action_sparsity_with_null_verb": 0.74,
          "task": "single_step_action_prediction",
          "method_name": "AutoregressiveIL_video_VID25_epoch_-1",
          "exclude_last_n": 6,
          "mAP_standard": 0.9241325205490107,
          "mAP_present_only": 0.6604027110289054,
          "mAP_freq_weighted": 0.8143629016439277,
          "exact_match": 0.4635979333020197,
          "hamming_accuracy": 0.9917751816355695,
          "precision": 0.896550462337677,
          "recall": 0.8331854964214505,
          "f1": 0.8620139234158177,
          "num_actions_total": 94,
          "num_actions_present": "21",
          "action_sparsity": 0.7765957446808511
        },
        "VID50": {
          "mAP": 0.528028115550844,
          "mAP_info": {
            "calculated_from": "subset_excluding_last_classes_present_actions_only",
            "excluded_classes": 6,
            "subset_size": 94,
            "present_actions_in_subset": "16",
            "subset_action_sparsity": 0.8297872340425532
          },
          "mAP_standard_with_null_verb": 0.8973622824520422,
          "mAP_present_only_with_null_verb": 0.48534601362245716,
          "mAP_freq_weighted_with_null_verb": 0.768207821171426,
          "mAP_sample_wise_with_null_verb": 0.8389554187739919,
          "mAP_standard_all_actions": 0.8973622824520422,
          "mAP_present_only_all_actions": 0.48534601362245716,
          "mAP_freq_weighted_all_actions": 0.768207821171426,
          "mAP_sample_wise_all_actions": 0.8389554187739919,
          "exact_match_with_null_verb": 0.4844606946983547,
          "hamming_accuracy_with_null_verb": 0.9914533820840951,
          "precision_with_null_verb": 0.8816264503565283,
          "recall_with_null_verb": 0.8421556175134242,
          "f1_with_null_verb": 0.8607729268231097,
          "num_predictions": 1094,
          "num_actions_total_with_null_verb": 100,
          "num_actions_present_with_null_verb": "18",
          "action_sparsity_with_null_verb": 0.8200000000000001,
          "task": "single_step_action_prediction",
          "method_name": "AutoregressiveIL_video_VID50_epoch_-1",
          "exclude_last_n": 6,
          "mAP_standard": 0.9090260622214204,
          "mAP_present_only": 0.528028115550844,
          "mAP_freq_weighted": 0.8012168207408872,
          "exact_match": 0.5164533820840951,
          "hamming_accuracy": 0.9920553113695593,
          "precision": 0.8871127313614766,
          "recall": 0.8613669112127464,
          "f1": 0.8737796647622809,
          "num_actions_total": 94,
          "num_actions_present": "16",
          "action_sparsity": 0.8297872340425532
        },
        "VID51": {
          "mAP": 0.47728284533602644,
          "mAP_info": {
            "calculated_from": "subset_excluding_last_classes_present_actions_only",
            "excluded_classes": 6,
            "subset_size": 94,
            "present_actions_in_subset": "24",
            "subset_action_sparsity": 0.7446808510638299
          },
          "mAP_standard_with_null_verb": 0.8002585295754208,
          "mAP_present_only_with_null_verb": 0.4491673433635195,
          "mAP_freq_weighted_with_null_verb": 0.7228104354124603,
          "mAP_sample_wise_with_null_verb": 0.7677938734412747,
          "mAP_standard_all_actions": 0.8002585295754208,
          "mAP_present_only_all_actions": 0.4491673433635195,
          "mAP_freq_weighted_all_actions": 0.7228104354124603,
          "mAP_sample_wise_all_actions": 0.7677938734412747,
          "exact_match_with_null_verb": 0.39402173913043476,
          "hamming_accuracy_with_null_verb": 0.9898403532608696,
          "precision_with_null_verb": 0.8445329034583829,
          "recall_with_null_verb": 0.7909179675277549,
          "f1_with_null_verb": 0.815379110218186,
          "num_predictions": 2944,
          "num_actions_total_with_null_verb": 100,
          "num_actions_present_with_null_verb": "29",
          "action_sparsity_with_null_verb": 0.71,
          "task": "single_step_action_prediction",
          "method_name": "AutoregressiveIL_video_VID51_epoch_-1",
          "exclude_last_n": 6,
          "mAP_standard": 0.8239871094474961,
          "mAP_present_only": 0.47728284533602644,
          "mAP_freq_weighted": 0.7576469142041825,
          "exact_match": 0.4476902173913043,
          "hamming_accuracy": 0.9909046889454209,
          "precision": 0.8563234220296678,
          "recall": 0.8068022445780807,
          "f1": 0.8296485150238404,
          "num_actions_total": 94,
          "num_actions_present": "24",
          "action_sparsity": 0.7446808510638299
        },
        "VID66": {
          "mAP": 0.6697824176882541,
          "mAP_info": {
            "calculated_from": "subset_excluding_last_classes_present_actions_only",
            "excluded_classes": 6,
            "subset_size": 94,
            "present_actions_in_subset": "20",
            "subset_action_sparsity": 0.7872340425531915
          },
          "mAP_standard_with_null_verb": 0.8712970568701686,
          "mAP_present_only_with_null_verb": 0.6143350298702975,
          "mAP_freq_weighted_with_null_verb": 0.8600429597163703,
          "mAP_sample_wise_with_null_verb": 0.8650185533283351,
          "mAP_standard_all_actions": 0.8712970568701686,
          "mAP_present_only_all_actions": 0.6143350298702975,
          "mAP_freq_weighted_all_actions": 0.8600429597163703,
          "mAP_sample_wise_all_actions": 0.8650185533283351,
          "exact_match_with_null_verb": 0.5455043859649122,
          "hamming_accuracy_with_null_verb": 0.9932565789473684,
          "precision_with_null_verb": 0.9106535158404492,
          "recall_with_null_verb": 0.8627300774927997,
          "f1_with_null_verb": 0.8851539854331321,
          "num_predictions": 1824,
          "num_actions_total_with_null_verb": 100,
          "num_actions_present_with_null_verb": "23",
          "action_sparsity_with_null_verb": 0.77,
          "task": "single_step_action_prediction",
          "method_name": "AutoregressiveIL_video_VID66_epoch_-1",
          "exclude_last_n": 6,
          "mAP_standard": 0.8871877484443094,
          "mAP_present_only": 0.6697824176882541,
          "mAP_freq_weighted": 0.8809465402828897,
          "exact_match": 0.5619517543859649,
          "hamming_accuracy": 0.9935085386338186,
          "precision": 0.9162146226999295,
          "recall": 0.8729833412856387,
          "f1": 0.8933714608175223,
          "num_actions_total": 94,
          "num_actions_present": "20",
          "action_sparsity": 0.7872340425531915
        },
        "VID79": {
          "mAP": 0.39729402880309317,
          "mAP_info": {
            "calculated_from": "subset_excluding_last_classes_present_actions_only",
            "excluded_classes": 6,
            "subset_size": 94,
            "present_actions_in_subset": "31",
            "subset_action_sparsity": 0.6702127659574468
          },
          "mAP_standard_with_null_verb": 0.7544469182885778,
          "mAP_present_only_with_null_verb": 0.37346366191271674,
          "mAP_freq_weighted_with_null_verb": 0.7851181061701882,
          "mAP_sample_wise_with_null_verb": 0.7814124413493658,
          "mAP_standard_all_actions": 0.7544469182885778,
          "mAP_present_only_all_actions": 0.37346366191271674,
          "mAP_freq_weighted_all_actions": 0.7851181061701882,
          "mAP_sample_wise_all_actions": 0.7814124413493658,
          "exact_match_with_null_verb": 0.429701230228471,
          "hamming_accuracy_with_null_verb": 0.9901113063854716,
          "precision_with_null_verb": 0.864610481929865,
          "recall_with_null_verb": 0.8150356656819249,
          "f1_with_null_verb": 0.8379426035191131,
          "num_predictions": 3414,
          "num_actions_total_with_null_verb": 100,
          "num_actions_present_with_null_verb": "36",
          "action_sparsity_with_null_verb": 0.64,
          "task": "single_step_action_prediction",
          "method_name": "AutoregressiveIL_video_VID79_epoch_-1",
          "exclude_last_n": 6,
          "mAP_standard": 0.7799586690733604,
          "mAP_present_only": 0.39729402880309317,
          "mAP_freq_weighted": 0.8132071257805487,
          "exact_match": 0.46367896895137667,
          "hamming_accuracy": 0.9905707412531628,
          "precision": 0.8721588184175806,
          "recall": 0.8267004856558943,
          "f1": 0.84789193255111,
          "num_actions_total": 94,
          "num_actions_present": "31",
          "action_sparsity": 0.6702127659574468
        }
      },
      "video_loss_metrics": {
        "VID02": {
          "action_rec_loss": 0.04589632453326488,
          "frame_loss": 0.18794180604983385,
          "action_loss": 0.04074232483013782,
          "phase_loss": 1.0563393248591781,
          "consistency_loss": 0.0019006894109064836,
          "total_loss": 0.5028554299557713
        },
        "VID06": {
          "action_rec_loss": 0.04400788905735916,
          "frame_loss": 0.18777679113878143,
          "action_loss": 0.03168950054230798,
          "phase_loss": 0.63396229280444,
          "consistency_loss": 0.0022463826831249714,
          "total_loss": 0.37231750813899217
        },
        "VID111": {
          "action_rec_loss": 0.04510410123202408,
          "frame_loss": 0.18532305975880847,
          "action_loss": 0.03368662949767787,
          "phase_loss": 2.705618247676498,
          "consistency_loss": 0.0018855708389457345,
          "total_loss": 0.9947438024843049
        },
        "VID14": {
          "action_rec_loss": 0.04637582099648145,
          "frame_loss": 0.2075666927071027,
          "action_loss": 0.04277211389500021,
          "phase_loss": 3.3561789451954636,
          "consistency_loss": 0.0019752773800910204,
          "total_loss": 1.2035862369306176
        },
        "VID23": {
          "action_rec_loss": 0.050719696014032416,
          "frame_loss": 0.21083102615141286,
          "action_loss": 0.05152190410943415,
          "phase_loss": 1.5246896671350914,
          "consistency_loss": 0.0022340279117608265,
          "total_loss": 0.6644852256629525
        },
        "VID25": {
          "action_rec_loss": 0.035769216387045624,
          "frame_loss": 0.18700117257873664,
          "action_loss": 0.03369979251591203,
          "phase_loss": 0.8504165854768608,
          "consistency_loss": 0.0020738591113471667,
          "total_loss": 0.4203713928185375
        },
        "VID50": {
          "action_rec_loss": 0.03283616778355321,
          "frame_loss": 0.1758367202251497,
          "action_loss": 0.031881194847659715,
          "phase_loss": 0.6070329450542147,
          "consistency_loss": 0.0021129950757153727,
          "total_loss": 0.33591188408815076
        },
        "VID51": {
          "action_rec_loss": 0.047004345577823126,
          "frame_loss": 0.16962508033232196,
          "action_loss": 0.03765326723833309,
          "phase_loss": 1.0576534748880633,
          "consistency_loss": 0.002269670665781306,
          "total_loss": 0.49634425320824527
        },
        "VID66": {
          "action_rec_loss": 0.025695806101738158,
          "frame_loss": 0.18753047561959216,
          "action_loss": 0.020342700640787626,
          "phase_loss": 0.3728009239099955,
          "consistency_loss": 0.0017330932642783395,
          "total_loss": 0.2571704417401761
        },
        "VID79": {
          "action_rec_loss": 0.03844761332260238,
          "frame_loss": 0.2001295156724559,
          "action_loss": 0.03664285226647204,
          "phase_loss": 0.763925864613878,
          "consistency_loss": 0.002028745573231108,
          "total_loss": 0.40634062716986036
        }
      },
      "generation_quality": {
        "frame_smoothness": 0.7925564845403036,
        "action_diversity": 0.0006588078394997865
      },
      "planning_evaluation": {
        "aggregated_results": {
          "num_videos": 10,
          "overall_success_rate": 7.985665342578561,
          "horizon_aggregated": {
            "1s": {
              "num_videos_evaluated": 10,
              "planning_horizon_frames": 1,
              "planning_horizon_seconds": 1.0,
              "mean_ivt_mAP": 0.23367564789839707,
              "std_ivt_mAP": 0.059785393901850135,
              "mean_exact_match_rate": 0.4346501656514773,
              "std_exact_match_rate": 0.04569387263468713,
              "mean_hamming_accuracy": 0.9905984759972393,
              "std_hamming_accuracy": 0.001088379748922423,
              "mean_action_consistency": 0.9968186975417789,
              "std_action_consistency": 0.00025576368293984514,
              "mean_temporal_smoothness": "0.9968238",
              "std_temporal_smoothness": "0.00025495407",
              "mean_sparsity_similarity": 0.9972486424307515,
              "std_sparsity_similarity": 0.0007183922651501156,
              "mean_ivt_i_mAP": 0.6690010763028603,
              "mean_ivt_v_mAP": 0.491742348722899,
              "mean_ivt_t_mAP": 0.3373483983227349,
              "mean_ivt_iv_mAP": 0.2919385164096303,
              "mean_ivt_it_mAP": 0.27633010611618947
            },
            "2s": {
              "num_videos_evaluated": 10,
              "planning_horizon_frames": 2,
              "planning_horizon_seconds": 2.0,
              "mean_ivt_mAP": 0.22392161630888782,
              "std_ivt_mAP": 0.054568252526481766,
              "mean_exact_match_rate": 0.4282616721037072,
              "std_exact_match_rate": 0.04282423878342449,
              "mean_hamming_accuracy": 0.9903410088518141,
              "std_hamming_accuracy": 0.0010372566481527147,
              "mean_action_consistency": 0.9974336187940438,
              "std_action_consistency": 0.0001733914265412172,
              "mean_temporal_smoothness": "0.997437",
              "std_temporal_smoothness": "0.00017295097",
              "mean_sparsity_similarity": 0.997856611010169,
              "std_sparsity_similarity": 0.0008344741524646829,
              "mean_ivt_i_mAP": 0.6487827675982845,
              "mean_ivt_v_mAP": 0.47778228406778106,
              "mean_ivt_t_mAP": 0.33517679879644596,
              "mean_ivt_iv_mAP": 0.28279029188879606,
              "mean_ivt_it_mAP": 0.26615361107857505
            },
            "3s": {
              "num_videos_evaluated": 10,
              "planning_horizon_frames": 3,
              "planning_horizon_seconds": 3.0,
              "mean_ivt_mAP": 0.21039478006797477,
              "std_ivt_mAP": 0.04985226611687177,
              "mean_exact_match_rate": 0.41477293647645014,
              "std_exact_match_rate": 0.04488162190114302,
              "mean_hamming_accuracy": 0.9899934582974096,
              "std_hamming_accuracy": 0.0010726339026737957,
              "mean_action_consistency": 0.9978661364996043,
              "std_action_consistency": 0.0002468061417130837,
              "mean_temporal_smoothness": "0.9978684",
              "std_temporal_smoothness": "0.00024626157",
              "mean_sparsity_similarity": 0.9981328108405707,
              "std_sparsity_similarity": 0.0009075417075100148,
              "mean_ivt_i_mAP": 0.6180451255050192,
              "mean_ivt_v_mAP": 0.4546224201314448,
              "mean_ivt_t_mAP": 0.32561609546317194,
              "mean_ivt_iv_mAP": 0.2678656722449416,
              "mean_ivt_it_mAP": 0.2521897803931514
            },
            "5s": {
              "num_videos_evaluated": 10,
              "planning_horizon_frames": 5,
              "planning_horizon_seconds": 5.0,
              "mean_ivt_mAP": 0.19131999992543716,
              "std_ivt_mAP": 0.04267290913984412,
              "mean_exact_match_rate": 0.3877983459432007,
              "std_exact_match_rate": 0.04221155379461945,
              "mean_hamming_accuracy": 0.989339311579478,
              "std_hamming_accuracy": 0.0010757161747088195,
              "mean_action_consistency": 0.9982115839362807,
              "std_action_consistency": 0.000194752680090167,
              "mean_temporal_smoothness": "0.9982132",
              "std_temporal_smoothness": "0.0001944005",
              "mean_sparsity_similarity": 0.9984615905521081,
              "std_sparsity_similarity": 0.0008756496352505395,
              "mean_ivt_i_mAP": 0.5688927011731638,
              "mean_ivt_v_mAP": 0.4154058770400111,
              "mean_ivt_t_mAP": 0.3104280376136221,
              "mean_ivt_iv_mAP": 0.24355214809953063,
              "mean_ivt_it_mAP": 0.23072640093278368
            }
          }
        },
        "detailed_video_results": {
          "VID02": {
            "video_id": "VID02",
            "total_sequences": 355,
            "successful_predictions": 2839,
            "success_rate": 7.997183098591549,
            "horizon_results": {
              "1s": {
                "num_sequences": 2839,
                "total_frames": 2839,
                "horizon_frames": 1,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.18761738000419617,
                "ivt_i_mAP": 0.6104081380024585,
                "ivt_v_mAP": 0.4214242620247006,
                "ivt_t_mAP": 0.257350877510049,
                "ivt_iv_mAP": 0.23268211911092412,
                "ivt_it_mAP": 0.2249646797231046,
                "exact_match_rate": 0.3906305036984854,
                "hamming_accuracy": 0.9898872842550194,
                "action_consistency": 0.9963706835799859,
                "temporal_smoothness": "0.99637735",
                "pred_sparsity": 0.011285663966185277,
                "gt_sparsity": 0.014346600915815428,
                "sparsity_similarity": 0.9969390630503698
              },
              "2s": {
                "num_sequences": 2839,
                "total_frames": 2839,
                "horizon_frames": 2,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.18464873395980202,
                "ivt_i_mAP": 0.5884304206821891,
                "ivt_v_mAP": 0.40935363005057374,
                "ivt_t_mAP": 0.2571932641970927,
                "ivt_iv_mAP": 0.22117275875456818,
                "ivt_it_mAP": 0.2217045423020041,
                "exact_match_rate": 0.38288129623106726,
                "hamming_accuracy": 0.989732300105671,
                "action_consistency": 0.9970331219168429,
                "temporal_smoothness": "0.9970375",
                "pred_sparsity": 0.01169425854174005,
                "gt_sparsity": 0.014346600915815428,
                "sparsity_similarity": 0.9973476576259246
              },
              "3s": {
                "num_sequences": 2839,
                "total_frames": 2839,
                "horizon_frames": 3,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.1734735689651875,
                "ivt_i_mAP": 0.5481879140905821,
                "ivt_v_mAP": 0.38535559658969626,
                "ivt_t_mAP": 0.242493490524045,
                "ivt_iv_mAP": 0.20940968936645293,
                "ivt_it_mAP": 0.20855124847476972,
                "exact_match_rate": 0.36597393448397325,
                "hamming_accuracy": 0.9893800634026065,
                "action_consistency": 0.9973643410852713,
                "temporal_smoothness": "0.99736786",
                "pred_sparsity": 0.012011271574498062,
                "gt_sparsity": 0.014346600915815428,
                "sparsity_similarity": 0.9976646706586826
              },
              "5s": {
                "num_sequences": 2839,
                "total_frames": 2839,
                "horizon_frames": 5,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.1572443007513097,
                "ivt_i_mAP": 0.5210849759116597,
                "ivt_v_mAP": 0.3488919815846328,
                "ivt_t_mAP": 0.22765271362342554,
                "ivt_iv_mAP": 0.18826534017398744,
                "ivt_it_mAP": 0.18907884630742713,
                "exact_match_rate": 0.34202183867559,
                "hamming_accuracy": 0.9888340965128566,
                "action_consistency": 0.9977660324171952,
                "temporal_smoothness": "0.9977685",
                "pred_sparsity": 0.012296583303980275,
                "gt_sparsity": 0.014346600915815428,
                "sparsity_similarity": 0.9979499823881648
              }
            }
          },
          "VID06": {
            "video_id": "VID06",
            "total_sequences": 270,
            "successful_predictions": 2153,
            "success_rate": 7.974074074074074,
            "horizon_results": {
              "1s": {
                "num_sequences": 2153,
                "total_frames": 2153,
                "horizon_frames": 1,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.19247476789900878,
                "ivt_i_mAP": 0.6574512783753309,
                "ivt_v_mAP": 0.39004724966334153,
                "ivt_t_mAP": 0.3245135331739238,
                "ivt_iv_mAP": 0.23628427323920634,
                "ivt_it_mAP": 0.24415389479496308,
                "exact_match_rate": 0.41151881096144916,
                "hamming_accuracy": 0.9909428704133767,
                "action_consistency": 0.9969423791821561,
                "temporal_smoothness": "0.996947",
                "pred_sparsity": 0.014273107292150488,
                "gt_sparsity": 0.01740362285183465,
                "sparsity_similarity": 0.9968694844403159
              },
              "2s": {
                "num_sequences": 2153,
                "total_frames": 2153,
                "horizon_frames": 2,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.19038645803848758,
                "ivt_i_mAP": 0.6543133778050638,
                "ivt_v_mAP": 0.39514004639253164,
                "ivt_t_mAP": 0.3277823996771679,
                "ivt_iv_mAP": 0.23953984819617619,
                "ivt_it_mAP": 0.23937610278152202,
                "exact_match_rate": 0.4017649790989317,
                "hamming_accuracy": 0.9906502554575012,
                "action_consistency": 0.9974860594795539,
                "temporal_smoothness": "0.9974893",
                "pred_sparsity": 0.014918718067812356,
                "gt_sparsity": 0.01740362285183465,
                "sparsity_similarity": 0.9975150952159777
              },
              "3s": {
                "num_sequences": 2153,
                "total_frames": 2153,
                "horizon_frames": 3,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.18715231433359064,
                "ivt_i_mAP": 0.6414497214830498,
                "ivt_v_mAP": 0.3903128975052404,
                "ivt_t_mAP": 0.3248797921982318,
                "ivt_iv_mAP": 0.2347368218008224,
                "ivt_it_mAP": 0.2356847874411159,
                "exact_match_rate": 0.3892243381328379,
                "hamming_accuracy": 0.99039479795634,
                "action_consistency": 0.9978578066914499,
                "temporal_smoothness": "0.9978601",
                "pred_sparsity": 0.015090571295866233,
                "gt_sparsity": 0.01740362285183465,
                "sparsity_similarity": 0.9976869484440316
              },
              "5s": {
                "num_sequences": 2153,
                "total_frames": 2153,
                "horizon_frames": 5,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.182002004975411,
                "ivt_i_mAP": 0.609193652031509,
                "ivt_v_mAP": 0.37052964151046275,
                "ivt_t_mAP": 0.30775228592856246,
                "ivt_iv_mAP": 0.22251781645300792,
                "ivt_it_mAP": 0.22805531294768397,
                "exact_match_rate": 0.3729679516953089,
                "hamming_accuracy": 0.9898792382721784,
                "action_consistency": 0.9983131970260223,
                "temporal_smoothness": "0.9983146",
                "pred_sparsity": 0.015485369252206223,
                "gt_sparsity": 0.01740362285183465,
                "sparsity_similarity": 0.9980817464003716
              }
            }
          },
          "VID111": {
            "video_id": "VID111",
            "total_sequences": 269,
            "successful_predictions": 2145,
            "success_rate": 7.973977695167286,
            "horizon_results": {
              "1s": {
                "num_sequences": 2145,
                "total_frames": 2145,
                "horizon_frames": 1,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.24612269135568024,
                "ivt_i_mAP": 0.6741849676202188,
                "ivt_v_mAP": 0.5139477365441558,
                "ivt_t_mAP": 0.3287826209635384,
                "ivt_iv_mAP": 0.3114209083306748,
                "ivt_it_mAP": 0.2893425337606284,
                "exact_match_rate": 0.4578088578088578,
                "hamming_accuracy": 0.9894498834498835,
                "action_consistency": 0.9973227611940298,
                "temporal_smoothness": "0.9973264",
                "pred_sparsity": 0.010018648018648019,
                "gt_sparsity": 0.012251748251748252,
                "sparsity_similarity": 0.9977668997668998
              },
              "2s": {
                "num_sequences": 2145,
                "total_frames": 2145,
                "horizon_frames": 2,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.23540169569963043,
                "ivt_i_mAP": 0.6737410565611732,
                "ivt_v_mAP": 0.4917445965487713,
                "ivt_t_mAP": 0.3308759315936139,
                "ivt_iv_mAP": 0.29814562891240726,
                "ivt_it_mAP": 0.2837296167706133,
                "exact_match_rate": 0.43916083916083914,
                "hamming_accuracy": 0.9892634032634032,
                "action_consistency": 0.9975186567164179,
                "temporal_smoothness": "0.99752176",
                "pred_sparsity": 0.010941724941724941,
                "gt_sparsity": 0.012251748251748252,
                "sparsity_similarity": 0.9986899766899767
              },
              "3s": {
                "num_sequences": 2145,
                "total_frames": 2145,
                "horizon_frames": 3,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.19738625932394763,
                "ivt_i_mAP": 0.6207118879535097,
                "ivt_v_mAP": 0.4435621027529796,
                "ivt_t_mAP": 0.29777043221039806,
                "ivt_iv_mAP": 0.2689046838883551,
                "ivt_it_mAP": 0.24067211441344447,
                "exact_match_rate": 0.41864801864801865,
                "hamming_accuracy": 0.9888997668997669,
                "action_consistency": 0.9979570895522388,
                "temporal_smoothness": "0.9979592",
                "pred_sparsity": 0.011268065268065269,
                "gt_sparsity": 0.012251748251748252,
                "sparsity_similarity": 0.999016317016317
              },
              "5s": {
                "num_sequences": 2145,
                "total_frames": 2145,
                "horizon_frames": 5,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.1675208927832402,
                "ivt_i_mAP": 0.5448456511129672,
                "ivt_v_mAP": 0.39039553463100657,
                "ivt_t_mAP": 0.27915173871263355,
                "ivt_iv_mAP": 0.23658648055544473,
                "ivt_it_mAP": 0.20396489653270267,
                "exact_match_rate": 0.3911421911421911,
                "hamming_accuracy": 0.9882284382284382,
                "action_consistency": 0.9983488805970149,
                "temporal_smoothness": "0.99835026",
                "pred_sparsity": 0.011668997668997668,
                "gt_sparsity": 0.012251748251748252,
                "sparsity_similarity": 0.9994172494172494
              }
            }
          },
          "VID14": {
            "video_id": "VID14",
            "total_sequences": 214,
            "successful_predictions": 1708,
            "success_rate": 7.981308411214953,
            "horizon_results": {
              "1s": {
                "num_sequences": 1708,
                "total_frames": 1708,
                "horizon_frames": 1,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.14482568659504297,
                "ivt_i_mAP": 0.5920107316049005,
                "ivt_v_mAP": 0.43102339810037993,
                "ivt_t_mAP": 0.27739849098967606,
                "ivt_iv_mAP": 0.22344608571697544,
                "ivt_it_mAP": 0.19543334103583743,
                "exact_match_rate": 0.4338407494145199,
                "hamming_accuracy": 0.9904449648711944,
                "action_consistency": 0.997152899824253,
                "temporal_smoothness": "0.9971569",
                "pred_sparsity": 0.012037470725995316,
                "gt_sparsity": 0.015480093676814988,
                "sparsity_similarity": 0.9965573770491803
              },
              "2s": {
                "num_sequences": 1708,
                "total_frames": 1708,
                "horizon_frames": 2,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.13570761989205338,
                "ivt_i_mAP": 0.5337745888391177,
                "ivt_v_mAP": 0.3916367057649646,
                "ivt_t_mAP": 0.2769224898387962,
                "ivt_iv_mAP": 0.20375690101215146,
                "ivt_it_mAP": 0.18226753977702012,
                "exact_match_rate": 0.40866510538641687,
                "hamming_accuracy": 0.9901112412177986,
                "action_consistency": 0.9977035735207967,
                "temporal_smoothness": "0.9977062",
                "pred_sparsity": 0.012605386416861826,
                "gt_sparsity": 0.015480093676814988,
                "sparsity_similarity": 0.9971252927400468
              },
              "3s": {
                "num_sequences": 1708,
                "total_frames": 1708,
                "horizon_frames": 3,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.13245176905744804,
                "ivt_i_mAP": 0.5223281268466674,
                "ivt_v_mAP": 0.3883886483550032,
                "ivt_t_mAP": 0.27533421557847404,
                "ivt_iv_mAP": 0.20105240287828352,
                "ivt_it_mAP": 0.1773039812716604,
                "exact_match_rate": 0.3940281030444965,
                "hamming_accuracy": 0.9897072599531616,
                "action_consistency": 0.9981839484475689,
                "temporal_smoothness": "0.99818563",
                "pred_sparsity": 0.012786885245901639,
                "gt_sparsity": 0.015480093676814988,
                "sparsity_similarity": 0.9973067915690866
              },
              "5s": {
                "num_sequences": 1708,
                "total_frames": 1708,
                "horizon_frames": 5,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.12332777993967887,
                "ivt_i_mAP": 0.4760928786194683,
                "ivt_v_mAP": 0.34561306807973063,
                "ivt_t_mAP": 0.2619391603929918,
                "ivt_iv_mAP": 0.17736997042479652,
                "ivt_it_mAP": 0.16502720843412005,
                "exact_match_rate": 0.3518735362997658,
                "hamming_accuracy": 0.9887704918032787,
                "action_consistency": 0.9983714118336262,
                "temporal_smoothness": "0.99837273",
                "pred_sparsity": 0.013430913348946135,
                "gt_sparsity": 0.015480093676814988,
                "sparsity_similarity": 0.9979508196721312
              }
            }
          },
          "VID23": {
            "video_id": "VID23",
            "total_sequences": 205,
            "successful_predictions": 1635,
            "success_rate": 7.975609756097561,
            "horizon_results": {
              "1s": {
                "num_sequences": 1635,
                "total_frames": 1635,
                "horizon_frames": 1,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.19964755513699942,
                "ivt_i_mAP": 0.5486156771348266,
                "ivt_v_mAP": 0.3939062099690936,
                "ivt_t_mAP": 0.2830437150904362,
                "ivt_iv_mAP": 0.24694547450102278,
                "ivt_it_mAP": 0.2229699461275578,
                "exact_match_rate": 0.3871559633027523,
                "hamming_accuracy": 0.9895045871559633,
                "action_consistency": 0.996609547123623,
                "temporal_smoothness": "0.99661523",
                "pred_sparsity": 0.011896024464831805,
                "gt_sparsity": 0.0158348623853211,
                "sparsity_similarity": 0.9960611620795107
              },
              "2s": {
                "num_sequences": 1635,
                "total_frames": 1635,
                "horizon_frames": 2,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.18848058740639848,
                "ivt_i_mAP": 0.5089457683569099,
                "ivt_v_mAP": 0.38426944456742546,
                "ivt_t_mAP": 0.27112450326815507,
                "ivt_iv_mAP": 0.2414197193293638,
                "ivt_it_mAP": 0.21167520830256203,
                "exact_match_rate": 0.3889908256880734,
                "hamming_accuracy": 0.9892905198776758,
                "action_consistency": 0.9976376988984088,
                "temporal_smoothness": "0.99764055",
                "pred_sparsity": 0.012452599388379205,
                "gt_sparsity": 0.01582262996941896,
                "sparsity_similarity": 0.9966299694189602
              },
              "3s": {
                "num_sequences": 1635,
                "total_frames": 1635,
                "horizon_frames": 3,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.1710763079945061,
                "ivt_i_mAP": 0.4684468726255193,
                "ivt_v_mAP": 0.35198739539860596,
                "ivt_t_mAP": 0.25951712842424196,
                "ivt_iv_mAP": 0.22307506607105576,
                "ivt_it_mAP": 0.192321164979316,
                "exact_match_rate": 0.3712538226299694,
                "hamming_accuracy": 0.9888195718654434,
                "action_consistency": 0.9980048959608323,
                "temporal_smoothness": "0.9980069",
                "pred_sparsity": 0.012617737003058105,
                "gt_sparsity": 0.01581039755351682,
                "sparsity_similarity": 0.9968073394495413
              },
              "5s": {
                "num_sequences": 1635,
                "total_frames": 1635,
                "horizon_frames": 5,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.16464090808972032,
                "ivt_i_mAP": 0.4532080190921198,
                "ivt_v_mAP": 0.34495443378540014,
                "ivt_t_mAP": 0.25636052330827114,
                "ivt_iv_mAP": 0.21624595766886395,
                "ivt_it_mAP": 0.1853279123723034,
                "exact_match_rate": 0.3498470948012232,
                "hamming_accuracy": 0.9882262996941896,
                "action_consistency": 0.998139534883721,
                "temporal_smoothness": "0.9981412",
                "pred_sparsity": 0.013015290519877676,
                "gt_sparsity": 0.01578593272171254,
                "sparsity_similarity": 0.9972293577981651
              }
            }
          },
          "VID25": {
            "video_id": "VID25",
            "total_sequences": 267,
            "successful_predictions": 2129,
            "success_rate": 7.97378277153558,
            "horizon_results": {
              "1s": {
                "num_sequences": 2129,
                "total_frames": 2129,
                "horizon_frames": 1,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.31259700315494915,
                "ivt_i_mAP": 0.7544662995404682,
                "ivt_v_mAP": 0.47320177593283097,
                "ivt_t_mAP": 0.42109022964305315,
                "ivt_iv_mAP": 0.2990945315110689,
                "ivt_it_mAP": 0.35156770951329486,
                "exact_match_rate": 0.42226397369657115,
                "hamming_accuracy": 0.9912212306247065,
                "action_consistency": 0.9967575187969925,
                "temporal_smoothness": "0.99676275",
                "pred_sparsity": 0.013100046970408643,
                "gt_sparsity": 0.01657116016909347,
                "sparsity_similarity": 0.9965288868013151
              },
              "2s": {
                "num_sequences": 2129,
                "total_frames": 2129,
                "horizon_frames": 2,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.2892454652621734,
                "ivt_i_mAP": 0.7320824511599802,
                "ivt_v_mAP": 0.4649864537185427,
                "ivt_t_mAP": 0.4192845116861738,
                "ivt_iv_mAP": 0.2942935753413659,
                "ivt_it_mAP": 0.32532847455889496,
                "exact_match_rate": 0.44387036167214655,
                "hamming_accuracy": 0.9911789572569282,
                "action_consistency": 0.9974248120300752,
                "temporal_smoothness": "0.9974281",
                "pred_sparsity": 0.013499295443870362,
                "gt_sparsity": 0.01657116016909347,
                "sparsity_similarity": 0.9969281352747769
              },
              "3s": {
                "num_sequences": 2129,
                "total_frames": 2129,
                "horizon_frames": 3,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.28170744253003394,
                "ivt_i_mAP": 0.7275491325525101,
                "ivt_v_mAP": 0.45809816890781485,
                "ivt_t_mAP": 0.41740448271893804,
                "ivt_iv_mAP": 0.28885894630318737,
                "ivt_it_mAP": 0.31704596342530833,
                "exact_match_rate": 0.4556129638327853,
                "hamming_accuracy": 0.9910333489901362,
                "action_consistency": 0.9981766917293233,
                "temporal_smoothness": "0.99817836",
                "pred_sparsity": 0.013757632691404415,
                "gt_sparsity": 0.01657116016909347,
                "sparsity_similarity": 0.997186472522311
              },
              "5s": {
                "num_sequences": 2129,
                "total_frames": 2129,
                "horizon_frames": 5,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.25776311874670904,
                "ivt_i_mAP": 0.6766909218008741,
                "ivt_v_mAP": 0.43862769221783154,
                "ivt_t_mAP": 0.40254951181168064,
                "ivt_iv_mAP": 0.2755700467436351,
                "ivt_it_mAP": 0.29019674535269085,
                "exact_match_rate": 0.4405824330671677,
                "hamming_accuracy": 0.9905025833724753,
                "action_consistency": 0.9984398496240602,
                "temporal_smoothness": "0.9984411",
                "pred_sparsity": 0.013884452794739315,
                "gt_sparsity": 0.01657116016909347,
                "sparsity_similarity": 0.9973132926256458
              }
            }
          },
          "VID50": {
            "video_id": "VID50",
            "total_sequences": 137,
            "successful_predictions": 1094,
            "success_rate": 7.985401459854015,
            "horizon_results": {
              "1s": {
                "num_sequences": 1094,
                "total_frames": 1094,
                "horizon_frames": 1,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.31555799457422473,
                "ivt_i_mAP": 0.8310817771135214,
                "ivt_v_mAP": 0.6540253945262028,
                "ivt_t_mAP": 0.3303718868468243,
                "ivt_iv_mAP": 0.4373474499233424,
                "ivt_it_mAP": 0.35562562020690947,
                "exact_match_rate": 0.4826325411334552,
                "hamming_accuracy": 0.991471663619744,
                "action_consistency": 0.9967337602927722,
                "temporal_smoothness": "0.99673903",
                "pred_sparsity": 0.01479890310786106,
                "gt_sparsity": 0.016453382084095063,
                "sparsity_similarity": 0.998345521023766
              },
              "2s": {
                "num_sequences": 1094,
                "total_frames": 1094,
                "horizon_frames": 2,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.30189321175335987,
                "ivt_i_mAP": 0.7695390313850333,
                "ivt_v_mAP": 0.6105605985379677,
                "ivt_t_mAP": 0.34090745701342545,
                "ivt_iv_mAP": 0.4082640868157152,
                "ivt_it_mAP": 0.3352047772111676,
                "exact_match_rate": 0.4789762340036563,
                "hamming_accuracy": 0.9911700182815356,
                "action_consistency": 0.9973193046660567,
                "temporal_smoothness": "0.9973229",
                "pred_sparsity": 0.015557586837294333,
                "gt_sparsity": 0.01643510054844607,
                "sparsity_similarity": 0.9991224862888483
              },
              "3s": {
                "num_sequences": 1094,
                "total_frames": 1094,
                "horizon_frames": 3,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.2704937692691383,
                "ivt_i_mAP": 0.6699286018571514,
                "ivt_v_mAP": 0.5393503437394138,
                "ivt_t_mAP": 0.31906004417771056,
                "ivt_iv_mAP": 0.36070348463566326,
                "ivt_it_mAP": 0.3051794083562786,
                "exact_match_rate": 0.46617915904936014,
                "hamming_accuracy": 0.9907586837294333,
                "action_consistency": 0.9975388838060384,
                "temporal_smoothness": "0.9975419",
                "pred_sparsity": 0.016060329067641682,
                "gt_sparsity": 0.016416819012797075,
                "sparsity_similarity": 0.9996435100548446
              },
              "5s": {
                "num_sequences": 1094,
                "total_frames": 1094,
                "horizon_frames": 5,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.21898991449791738,
                "ivt_i_mAP": 0.5290248913847388,
                "ivt_v_mAP": 0.43929740481795393,
                "ivt_t_mAP": 0.305099851606448,
                "ivt_iv_mAP": 0.2939959533806577,
                "ivt_it_mAP": 0.25455405715099727,
                "exact_match_rate": 0.4323583180987203,
                "hamming_accuracy": 0.989890310786106,
                "action_consistency": 0.9981061299176578,
                "temporal_smoothness": "0.9981079",
                "pred_sparsity": 0.016279707495429615,
                "gt_sparsity": 0.01640767824497258,
                "sparsity_similarity": 0.999872029250457
              }
            }
          },
          "VID51": {
            "video_id": "VID51",
            "total_sequences": 368,
            "successful_predictions": 2944,
            "success_rate": 8.0,
            "horizon_results": {
              "1s": {
                "num_sequences": 2944,
                "total_frames": 2944,
                "horizon_frames": 1,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.2299505917759331,
                "ivt_i_mAP": 0.6690645789970229,
                "ivt_v_mAP": 0.5208781654473923,
                "ivt_t_mAP": 0.40811980629142947,
                "ivt_iv_mAP": 0.2980448618246607,
                "ivt_it_mAP": 0.2787136536741878,
                "exact_match_rate": 0.39096467391304346,
                "hamming_accuracy": 0.9898029891304347,
                "action_consistency": 0.9967278287461774,
                "temporal_smoothness": "0.9967332",
                "pred_sparsity": 0.012781929347826087,
                "gt_sparsity": 0.015146059782608697,
                "sparsity_similarity": 0.9976358695652174
              },
              "2s": {
                "num_sequences": 2944,
                "total_frames": 2944,
                "horizon_frames": 2,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.2263571270725347,
                "ivt_i_mAP": 0.6748841082437892,
                "ivt_v_mAP": 0.5120403338265606,
                "ivt_t_mAP": 0.398430019124409,
                "ivt_iv_mAP": 0.2895045488645481,
                "ivt_it_mAP": 0.2790563341302798,
                "exact_match_rate": 0.39096467391304346,
                "hamming_accuracy": 0.9896569293478261,
                "action_consistency": 0.9974006116207951,
                "temporal_smoothness": "0.997404",
                "pred_sparsity": 0.013026494565217392,
                "gt_sparsity": 0.015142663043478262,
                "sparsity_similarity": 0.9978838315217391
              },
              "3s": {
                "num_sequences": 2944,
                "total_frames": 2944,
                "horizon_frames": 3,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.218874094715824,
                "ivt_i_mAP": 0.6742852923646278,
                "ivt_v_mAP": 0.5058449278645153,
                "ivt_t_mAP": 0.387215781962596,
                "ivt_iv_mAP": 0.2804030834905629,
                "ivt_it_mAP": 0.2744203892550505,
                "exact_match_rate": 0.37466032608695654,
                "hamming_accuracy": 0.9893342391304348,
                "action_consistency": 0.997849133537207,
                "temporal_smoothness": "0.99785143",
                "pred_sparsity": 0.013291440217391304,
                "gt_sparsity": 0.015139266304347827,
                "sparsity_similarity": 0.9981521739130435
              },
              "5s": {
                "num_sequences": 2944,
                "total_frames": 2944,
                "horizon_frames": 5,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.20374877697120544,
                "ivt_i_mAP": 0.64457749604642,
                "ivt_v_mAP": 0.4791820875240179,
                "ivt_t_mAP": 0.3663264102361303,
                "ivt_iv_mAP": 0.2640548380841788,
                "ivt_it_mAP": 0.25840694704588807,
                "exact_match_rate": 0.34816576086956524,
                "hamming_accuracy": 0.988804347826087,
                "action_consistency": 0.9980326197757391,
                "temporal_smoothness": "0.99803454",
                "pred_sparsity": 0.013495244565217392,
                "gt_sparsity": 0.015132472826086957,
                "sparsity_similarity": 0.9983627717391305
              }
            }
          },
          "VID66": {
            "video_id": "VID66",
            "total_sequences": 228,
            "successful_predictions": 1824,
            "success_rate": 8.0,
            "horizon_results": {
              "1s": {
                "num_sequences": 1824,
                "total_frames": 1824,
                "horizon_frames": 1,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.32085845014584785,
                "ivt_i_mAP": 0.6287382827777656,
                "ivt_v_mAP": 0.5306910929880588,
                "ivt_t_mAP": 0.38027014027809114,
                "ivt_iv_mAP": 0.36109830556460293,
                "ivt_it_mAP": 0.34348773114001446,
                "exact_match_rate": 0.5405701754385965,
                "hamming_accuracy": 0.9931743421052631,
                "action_consistency": 0.9967251782775645,
                "temporal_smoothness": "0.99673057",
                "pred_sparsity": 0.013914473684210527,
                "gt_sparsity": 0.015838815789473683,
                "sparsity_similarity": 0.9980756578947368
              },
              "2s": {
                "num_sequences": 1824,
                "total_frames": 1824,
                "horizon_frames": 2,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.3019314489316607,
                "ivt_i_mAP": 0.6200796066759371,
                "ivt_v_mAP": 0.544142961941898,
                "ivt_t_mAP": 0.3562571123667568,
                "ivt_iv_mAP": 0.3677366054522138,
                "ivt_it_mAP": 0.3258314021459799,
                "exact_match_rate": 0.524671052631579,
                "hamming_accuracy": 0.9927138157894737,
                "action_consistency": 0.9974053757542513,
                "temporal_smoothness": "0.99740875",
                "pred_sparsity": 0.014714912280701754,
                "gt_sparsity": 0.015838815789473683,
                "sparsity_similarity": 0.9988760964912281
              },
              "3s": {
                "num_sequences": 1824,
                "total_frames": 1824,
                "horizon_frames": 3,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.28622428895753826,
                "ivt_i_mAP": 0.595943449332165,
                "ivt_v_mAP": 0.5251626247748444,
                "ivt_t_mAP": 0.34777805594511574,
                "ivt_iv_mAP": 0.3549084936079339,
                "ivt_it_mAP": 0.31205267888126087,
                "exact_match_rate": 0.5082236842105263,
                "hamming_accuracy": 0.9923684210526316,
                "action_consistency": 0.9979758639605046,
                "temporal_smoothness": "0.9979779",
                "pred_sparsity": 0.015038377192982457,
                "gt_sparsity": 0.015838815789473683,
                "sparsity_similarity": 0.9991995614035087
              },
              "5s": {
                "num_sequences": 1824,
                "total_frames": 1824,
                "horizon_frames": 5,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.26478297831352177,
                "ivt_i_mAP": 0.5614188116187565,
                "ivt_v_mAP": 0.4812770250105212,
                "ivt_t_mAP": 0.3240688595457576,
                "ivt_iv_mAP": 0.325418178541028,
                "ivt_it_mAP": 0.29019634687631257,
                "exact_match_rate": 0.46765350877192985,
                "hamming_accuracy": 0.9917160087719298,
                "action_consistency": 0.9983708173340647,
                "temporal_smoothness": "0.9983722",
                "pred_sparsity": 0.015274122807017544,
                "gt_sparsity": 0.015827850877192982,
                "sparsity_similarity": 0.9994462719298246
              }
            }
          },
          "VID79": {
            "video_id": "VID79",
            "total_sequences": 427,
            "successful_predictions": 3414,
            "success_rate": 7.995316159250586,
            "horizon_results": {
              "1s": {
                "num_sequences": 3414,
                "total_frames": 3414,
                "horizon_frames": 1,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.187104358342088,
                "ivt_i_mAP": 0.7239890318620895,
                "ivt_v_mAP": 0.5882782020328337,
                "ivt_t_mAP": 0.3625426824403278,
                "ivt_iv_mAP": 0.2730211543738248,
                "ivt_it_mAP": 0.25704195118539613,
                "exact_match_rate": 0.4291154071470416,
                "hamming_accuracy": 0.9900849443468073,
                "action_consistency": 0.9968444184002344,
                "temporal_smoothness": "0.9968494",
                "pred_sparsity": 0.014349736379613356,
                "gt_sparsity": 0.01664323374340949,
                "sparsity_similarity": 0.9977065026362039
              },
              "2s": {
                "num_sequences": 3414,
                "total_frames": 3414,
                "horizon_frames": 2,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.18516381507277754,
                "ivt_i_mAP": 0.7320372662736506,
                "ivt_v_mAP": 0.5739480693285747,
                "ivt_t_mAP": 0.37299029919886884,
                "ivt_iv_mAP": 0.26406924620945066,
                "ivt_it_mAP": 0.25736211280570603,
                "exact_match_rate": 0.4226713532513181,
                "hamming_accuracy": 0.9896426479203281,
                "action_consistency": 0.9974069733372399,
                "temporal_smoothness": "0.99741036",
                "pred_sparsity": 0.01508787346221441,
                "gt_sparsity": 0.016640304628002343,
                "sparsity_similarity": 0.998447568834212
              },
              "3s": {
                "num_sequences": 3414,
                "total_frames": 3414,
                "horizon_frames": 3,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.18510798553253346,
                "ivt_i_mAP": 0.7116202559444091,
                "ivt_v_mAP": 0.5581614954263349,
                "ivt_t_mAP": 0.3847075308919684,
                "ivt_iv_mAP": 0.25660405040709927,
                "ivt_it_mAP": 0.25866606743330883,
                "exact_match_rate": 0.40392501464557706,
                "hamming_accuracy": 0.9892384299941418,
                "action_consistency": 0.997752710225608,
                "temporal_smoothness": "0.99775517",
                "pred_sparsity": 0.015301698886936145,
                "gt_sparsity": 0.016637375512595195,
                "sparsity_similarity": 0.998664323374341
              },
              "5s": {
                "num_sequences": 3414,
                "total_frames": 3414,
                "horizon_frames": 5,
                "avg_frames_per_sequence": 1.0,
                "ivt_mAP": 0.17317932418565762,
                "ivt_i_mAP": 0.6727897141131246,
                "ivt_v_mAP": 0.5152899012385532,
                "ivt_t_mAP": 0.37337932097031945,
                "ivt_iv_mAP": 0.23549689896970627,
                "ivt_it_mAP": 0.24245573630771092,
                "exact_match_rate": 0.38137082601054484,
                "hamming_accuracy": 0.9885413005272408,
                "action_consistency": 0.9982273659537064,
                "temporal_smoothness": "0.99822897",
                "pred_sparsity": 0.01562390158172232,
                "gt_sparsity": 0.016631517281780903,
                "sparsity_similarity": 0.9989923842999414
              }
            }
          }
        },
        "evaluation_settings": {
          "context_length": 20,
          "temperature": 0.1,
          "planning_horizons": {
            "1s": 1,
            "2s": 2,
            "3s": 3,
            "5s": 5
          },
          "num_videos": 10
        }
      },
      "model_type": "AutoregressiveIL",
      "evaluation_approach": "comprehensive_with_planning",
      "num_videos_evaluated": 10,
      "publication_metrics": {
        "single_step_mAP": 0.5057570338845174,
        "single_step_ivt_mAP": 0.0,
        "planning_1s_mAP": 0.23367564789839707,
        "planning_2s_mAP": 0.22392161630888782,
        "planning_3s_mAP": 0.21039478006797477,
        "planning_5s_mAP": 0.19131999992543716,
        "evaluation_types": [
          "single_step_recognition",
          "multi_step_planning"
        ],
        "planning_consistency": 0.9974336187940438
      },
      "evaluation_summary": {
        "single_step_performance": 0.5057570338845174,
        "short_term_planning": 0.22392161630888782,
        "medium_term_planning": 0.19131999992543716,
        "planning_degradation": 0.1812582883749028,
        "strength": "Autoregressive planning with causal generation",
        "architecture": "GPT-2 based autoregressive model",
        "planning_horizon_capability": "up_to_5_seconds",
        "target_prediction_type": "next_action_anticipation"
      },
      "performance_analysis": {
        "summary_stats": {
          "num_videos": 10,
          "mAP_stats": {
            "mean": 0.5057570338845174,
            "std": 0.09745888585577783,
            "min": 0.35076594976142184,
            "max": 0.6697824176882541,
            "median": 0.4759154943700716,
            "q25": 0.46743846756310675,
            "q75": 0.5542471689246117
          },
          "sparsity_stats": {
            "mean": 0.7308510638297873,
            "std": 0.05729886387019247,
            "correlation_with_mAP": 0.7699937835222498
          }
        },
        "performance_categories": {
          "high_performers": [
            "VID25",
            "VID66"
          ],
          "low_performers": [
            "VID14",
            "VID79"
          ],
          "consistent_performers": [
            "VID02",
            "VID06",
            "VID111",
            "VID23",
            "VID50",
            "VID51"
          ]
        },
        "detailed_rankings": [
          [
            "VID66",
            0.6697824176882541
          ],
          [
            "VID25",
            0.6604027110289054
          ],
          [
            "VID06",
            0.5629868533825343
          ],
          [
            "VID50",
            0.528028115550844
          ],
          [
            "VID51",
            0.47728284533602644
          ],
          [
            "VID02",
            0.4745481434041167
          ],
          [
            "VID111",
            0.46984197570875447
          ],
          [
            "VID23",
            0.4666372981812242
          ],
          [
            "VID79",
            0.39729402880309317
          ],
          [
            "VID14",
            0.35076594976142184
          ]
        ]
      }
    },
    "method_description": "Autoregressive IL with multi-step planning capabilities",
    "capabilities": {
      "single_step_recognition": 0.5057570338845174,
      "short_term_planning_2s": 0.22392161630888782,
      "planning_degradation": 0.1812582883749028,
      "planning_horizon": "up_to_5_seconds"
    },
    "target_type": "next_action_prediction",
    "planning_ready": true,
    "pretrained": null
  },
  "comprehensive_evaluation": {
    "evaluator": "<evaluation.integrated_evaluation.IntegratedEvaluationFramework object at 0x7f7e678e5930>",
    "results": {
      "status": "success",
      "evaluation_type": "comprehensive_evaluation_with_proper_batches",
      "num_models": 1,
      "num_videos": 10,
      "horizon": 8,
      "video_results": {
        "VID02": {
          "video_id": "VID02",
          "evaluation_type": "comprehensive_fair_evaluation_with_proper_batches",
          "single_step_evaluation": {
            "AutoregressiveIL": {
              "metrics": {
                "mAP": 0.2218668389583626,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "28",
                  "subset_action_sparsity": 0.7021276595744681
                },
                "mAP_standard_with_null_verb": 0.7243482783799204,
                "mAP_present_only_with_null_verb": 0.1892596422938835,
                "mAP_freq_weighted_with_null_verb": 0.5860793670071548,
                "mAP_sample_wise_with_null_verb": 0.6535222621518072,
                "mAP_standard_all_actions": 0.7243482783799204,
                "mAP_present_only_all_actions": 0.1892596422938835,
                "mAP_freq_weighted_all_actions": 0.5860793670071548,
                "mAP_sample_wise_all_actions": 0.6535222621518072,
                "exact_match_with_null_verb": 0.34871433603381474,
                "hamming_accuracy_with_null_verb": 0.98989080662205,
                "precision_with_null_verb": 0.8609048983571403,
                "recall_with_null_verb": 0.733449571075916,
                "f1_with_null_verb": 0.7830714723840195,
                "num_predictions": 2839,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "34",
                "action_sparsity_with_null_verb": 0.6599999999999999,
                "task": "single_step_action_prediction",
                "method_name": "AutoregressiveIL",
                "exclude_last_n": 6,
                "mAP_standard": 0.7682156541578101,
                "mAP_present_only": 0.2218668389583626,
                "mAP_freq_weighted": 0.6176753590662849,
                "exact_match": 0.38922155688622756,
                "hamming_accuracy": 0.9901336251152264,
                "precision": 0.8610024602200425,
                "recall": 0.7477393705232047,
                "f1": 0.7934895822902222,
                "num_actions_total": 94,
                "num_actions_present": "28",
                "action_sparsity": 0.7021276595744681
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": true
            }
          },
          "planning_evaluation": {
            "AutoregressiveIL": {}
          },
          "summary": {
            "primary_comparison": {
              "AutoregressiveIL": {
                "mAP": 0.2218668389583626,
                "exact_match": 0.38922155688622756,
                "task": "single_step_action_prediction"
              }
            },
            "secondary_analysis": {},
            "overall_ranking": {},
            "paradigm_insights": {
              "fair_comparison_task": "single_step_action_prediction",
              "planning_analysis": "shows_method_specific_strengths",
              "evaluation_approach": "respects_training_paradigms"
            }
          },
          "fairness_report": {
            "evaluation_design": {
              "primary_evaluation": "single_step_fair_comparison",
              "secondary_evaluation": "method_specific_planning_analysis",
              "data_handling": "uses_dataloader_batches_like_training",
              "temporal_structure": "maintained_for_il_model",
              "ground_truth_leakage": "eliminated"
            },
            "method_fairness": {
              "AutoregressiveIL": "evaluated_with_proper_temporal_sequences",
              "WorldModelRL": "evaluated_with_consistent_batch_approach",
              "DirectVideoRL": "evaluated_with_consistent_batch_approach"
            },
            "data_integrity": {
              "temporal_context": "preserved_for_models_that_need_it",
              "batch_structure": "mirrors_training_approach",
              "evaluation_consistency": "matches_model_training_interface"
            },
            "comparison_validity": {
              "single_step_comparison": "valid_and_fair_with_proper_data_handling",
              "planning_comparison": "method_specific_respecting_capabilities",
              "overall_approach": "methodologically_sound_and_consistent_with_training"
            }
          }
        },
        "VID06": {
          "video_id": "VID06",
          "evaluation_type": "comprehensive_fair_evaluation_with_proper_batches",
          "single_step_evaluation": {
            "AutoregressiveIL": {
              "metrics": {
                "mAP": 0.27074326684329064,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "26",
                  "subset_action_sparsity": 0.7234042553191489
                },
                "mAP_standard_with_null_verb": 0.7738887705466343,
                "mAP_present_only_with_null_verb": 0.24629590182211455,
                "mAP_freq_weighted_with_null_verb": 0.7023675462669337,
                "mAP_sample_wise_with_null_verb": 0.777642710032379,
                "mAP_standard_all_actions": 0.7738887705466343,
                "mAP_present_only_all_actions": 0.24629590182211455,
                "mAP_freq_weighted_all_actions": 0.7023675462669337,
                "mAP_sample_wise_all_actions": 0.777642710032379,
                "exact_match_with_null_verb": 0.34370645610775663,
                "hamming_accuracy_with_null_verb": 0.9903576405016257,
                "precision_with_null_verb": 0.897594980677491,
                "recall_with_null_verb": 0.794546212570497,
                "f1_with_null_verb": 0.8381054017205504,
                "num_predictions": 2153,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "30",
                "action_sparsity_with_null_verb": 0.7,
                "task": "single_step_action_prediction",
                "method_name": "AutoregressiveIL",
                "exclude_last_n": 6,
                "mAP_standard": 0.7982906908289953,
                "mAP_present_only": 0.27074326684329064,
                "mAP_freq_weighted": 0.7458237870543974,
                "exact_match": 0.42080817464003717,
                "hamming_accuracy": 0.9911009872419484,
                "precision": 0.8980508656177858,
                "recall": 0.8178959531636358,
                "f1": 0.8533138165724741,
                "num_actions_total": 94,
                "num_actions_present": "26",
                "action_sparsity": 0.7234042553191489
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": true
            }
          },
          "planning_evaluation": {
            "AutoregressiveIL": {}
          },
          "summary": {
            "primary_comparison": {
              "AutoregressiveIL": {
                "mAP": 0.27074326684329064,
                "exact_match": 0.42080817464003717,
                "task": "single_step_action_prediction"
              }
            },
            "secondary_analysis": {},
            "overall_ranking": {},
            "paradigm_insights": {
              "fair_comparison_task": "single_step_action_prediction",
              "planning_analysis": "shows_method_specific_strengths",
              "evaluation_approach": "respects_training_paradigms"
            }
          },
          "fairness_report": {
            "evaluation_design": {
              "primary_evaluation": "single_step_fair_comparison",
              "secondary_evaluation": "method_specific_planning_analysis",
              "data_handling": "uses_dataloader_batches_like_training",
              "temporal_structure": "maintained_for_il_model",
              "ground_truth_leakage": "eliminated"
            },
            "method_fairness": {
              "AutoregressiveIL": "evaluated_with_proper_temporal_sequences",
              "WorldModelRL": "evaluated_with_consistent_batch_approach",
              "DirectVideoRL": "evaluated_with_consistent_batch_approach"
            },
            "data_integrity": {
              "temporal_context": "preserved_for_models_that_need_it",
              "batch_structure": "mirrors_training_approach",
              "evaluation_consistency": "matches_model_training_interface"
            },
            "comparison_validity": {
              "single_step_comparison": "valid_and_fair_with_proper_data_handling",
              "planning_comparison": "method_specific_respecting_capabilities",
              "overall_approach": "methodologically_sound_and_consistent_with_training"
            }
          }
        },
        "VID111": {
          "video_id": "VID111",
          "evaluation_type": "comprehensive_fair_evaluation_with_proper_batches",
          "single_step_evaluation": {
            "AutoregressiveIL": {
              "metrics": {
                "mAP": 0.2724435062408489,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "25",
                  "subset_action_sparsity": 0.7340425531914894
                },
                "mAP_standard_with_null_verb": 0.7864119964279552,
                "mAP_present_only_with_null_verb": 0.2634896428550179,
                "mAP_freq_weighted_with_null_verb": 0.5936649847120035,
                "mAP_sample_wise_with_null_verb": 0.6660448177836414,
                "mAP_standard_all_actions": 0.7864119964279552,
                "mAP_present_only_all_actions": 0.2634896428550179,
                "mAP_freq_weighted_all_actions": 0.5936649847120035,
                "mAP_sample_wise_all_actions": 0.6660448177836414,
                "exact_match_with_null_verb": 0.43496503496503497,
                "hamming_accuracy_with_null_verb": 0.9898088578088579,
                "precision_with_null_verb": 0.8072593884490715,
                "recall_with_null_verb": 0.7133687678405296,
                "f1_with_null_verb": 0.7515865772535373,
                "num_predictions": 2145,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "29",
                "action_sparsity_with_null_verb": 0.71,
                "task": "single_step_action_prediction",
                "method_name": "AutoregressiveIL",
                "exclude_last_n": 6,
                "mAP_standard": 0.8065009325108642,
                "mAP_present_only": 0.2724435062408489,
                "mAP_freq_weighted": 0.6233063188095946,
                "exact_match": 0.49696969696969695,
                "hamming_accuracy": 0.9911967465158954,
                "precision": 0.8080610212543686,
                "recall": 0.7531238318429407,
                "f1": 0.7778265091216463,
                "num_actions_total": 94,
                "num_actions_present": "25",
                "action_sparsity": 0.7340425531914894
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": true
            }
          },
          "planning_evaluation": {
            "AutoregressiveIL": {}
          },
          "summary": {
            "primary_comparison": {
              "AutoregressiveIL": {
                "mAP": 0.2724435062408489,
                "exact_match": 0.49696969696969695,
                "task": "single_step_action_prediction"
              }
            },
            "secondary_analysis": {},
            "overall_ranking": {},
            "paradigm_insights": {
              "fair_comparison_task": "single_step_action_prediction",
              "planning_analysis": "shows_method_specific_strengths",
              "evaluation_approach": "respects_training_paradigms"
            }
          },
          "fairness_report": {
            "evaluation_design": {
              "primary_evaluation": "single_step_fair_comparison",
              "secondary_evaluation": "method_specific_planning_analysis",
              "data_handling": "uses_dataloader_batches_like_training",
              "temporal_structure": "maintained_for_il_model",
              "ground_truth_leakage": "eliminated"
            },
            "method_fairness": {
              "AutoregressiveIL": "evaluated_with_proper_temporal_sequences",
              "WorldModelRL": "evaluated_with_consistent_batch_approach",
              "DirectVideoRL": "evaluated_with_consistent_batch_approach"
            },
            "data_integrity": {
              "temporal_context": "preserved_for_models_that_need_it",
              "batch_structure": "mirrors_training_approach",
              "evaluation_consistency": "matches_model_training_interface"
            },
            "comparison_validity": {
              "single_step_comparison": "valid_and_fair_with_proper_data_handling",
              "planning_comparison": "method_specific_respecting_capabilities",
              "overall_approach": "methodologically_sound_and_consistent_with_training"
            }
          }
        },
        "VID14": {
          "video_id": "VID14",
          "evaluation_type": "comprehensive_fair_evaluation_with_proper_batches",
          "single_step_evaluation": {
            "AutoregressiveIL": {
              "metrics": {
                "mAP": 0.21094587501727186,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "36",
                  "subset_action_sparsity": 0.6170212765957447
                },
                "mAP_standard_with_null_verb": 0.6711611785872655,
                "mAP_present_only_with_null_verb": 0.19795409411528167,
                "mAP_freq_weighted_with_null_verb": 0.6160104537664346,
                "mAP_sample_wise_with_null_verb": 0.7094075693734688,
                "mAP_standard_all_actions": 0.6711611785872655,
                "mAP_present_only_all_actions": 0.19795409411528167,
                "mAP_freq_weighted_all_actions": 0.6160104537664346,
                "mAP_sample_wise_all_actions": 0.7094075693734688,
                "exact_match_with_null_verb": 0.34543325526932084,
                "hamming_accuracy_with_null_verb": 0.9897658079625292,
                "precision_with_null_verb": 0.8794803559444975,
                "recall_with_null_verb": 0.7422186296357114,
                "f1_with_null_verb": 0.7951874719566339,
                "num_predictions": 1708,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "41",
                "action_sparsity_with_null_verb": 0.5900000000000001,
                "task": "single_step_action_prediction",
                "method_name": "AutoregressiveIL",
                "exclude_last_n": 6,
                "mAP_standard": 0.6978090585172531,
                "mAP_present_only": 0.21094587501727186,
                "mAP_freq_weighted": 0.6437910351481272,
                "exact_match": 0.3981264637002342,
                "hamming_accuracy": 0.9901278090587473,
                "precision": 0.8797345579047708,
                "recall": 0.7581344352805139,
                "f1": 0.8069489530426309,
                "num_actions_total": 94,
                "num_actions_present": "36",
                "action_sparsity": 0.6170212765957447
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": true
            }
          },
          "planning_evaluation": {
            "AutoregressiveIL": {}
          },
          "summary": {
            "primary_comparison": {
              "AutoregressiveIL": {
                "mAP": 0.21094587501727186,
                "exact_match": 0.3981264637002342,
                "task": "single_step_action_prediction"
              }
            },
            "secondary_analysis": {},
            "overall_ranking": {},
            "paradigm_insights": {
              "fair_comparison_task": "single_step_action_prediction",
              "planning_analysis": "shows_method_specific_strengths",
              "evaluation_approach": "respects_training_paradigms"
            }
          },
          "fairness_report": {
            "evaluation_design": {
              "primary_evaluation": "single_step_fair_comparison",
              "secondary_evaluation": "method_specific_planning_analysis",
              "data_handling": "uses_dataloader_batches_like_training",
              "temporal_structure": "maintained_for_il_model",
              "ground_truth_leakage": "eliminated"
            },
            "method_fairness": {
              "AutoregressiveIL": "evaluated_with_proper_temporal_sequences",
              "WorldModelRL": "evaluated_with_consistent_batch_approach",
              "DirectVideoRL": "evaluated_with_consistent_batch_approach"
            },
            "data_integrity": {
              "temporal_context": "preserved_for_models_that_need_it",
              "batch_structure": "mirrors_training_approach",
              "evaluation_consistency": "matches_model_training_interface"
            },
            "comparison_validity": {
              "single_step_comparison": "valid_and_fair_with_proper_data_handling",
              "planning_comparison": "method_specific_respecting_capabilities",
              "overall_approach": "methodologically_sound_and_consistent_with_training"
            }
          }
        },
        "VID23": {
          "video_id": "VID23",
          "evaluation_type": "comprehensive_fair_evaluation_with_proper_batches",
          "single_step_evaluation": {
            "AutoregressiveIL": {
              "metrics": {
                "mAP": 0.3035937732134314,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "26",
                  "subset_action_sparsity": 0.7234042553191489
                },
                "mAP_standard_with_null_verb": 0.7638182173558726,
                "mAP_present_only_with_null_verb": 0.2703813463092669,
                "mAP_freq_weighted_with_null_verb": 0.6398349137962944,
                "mAP_sample_wise_with_null_verb": 0.7223793427074332,
                "mAP_standard_all_actions": 0.7638182173558726,
                "mAP_present_only_all_actions": 0.2703813463092669,
                "mAP_freq_weighted_all_actions": 0.6398349137962944,
                "mAP_sample_wise_all_actions": 0.7223793427074332,
                "exact_match_with_null_verb": 0.3657492354740061,
                "hamming_accuracy_with_null_verb": 0.9897431192660551,
                "precision_with_null_verb": 0.8731300692722725,
                "recall_with_null_verb": 0.760117493103595,
                "f1_with_null_verb": 0.8061808583862444,
                "num_predictions": 1635,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "31",
                "action_sparsity_with_null_verb": 0.69,
                "task": "single_step_action_prediction",
                "method_name": "AutoregressiveIL",
                "exclude_last_n": 6,
                "mAP_standard": 0.7967387032292471,
                "mAP_present_only": 0.3035937732134314,
                "mAP_freq_weighted": 0.6692535759472457,
                "exact_match": 0.43669724770642204,
                "hamming_accuracy": 0.9905328908842476,
                "precision": 0.8736142127951555,
                "recall": 0.7845556019314798,
                "f1": 0.8228469448620315,
                "num_actions_total": 94,
                "num_actions_present": "26",
                "action_sparsity": 0.7234042553191489
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": true
            }
          },
          "planning_evaluation": {
            "AutoregressiveIL": {}
          },
          "summary": {
            "primary_comparison": {
              "AutoregressiveIL": {
                "mAP": 0.3035937732134314,
                "exact_match": 0.43669724770642204,
                "task": "single_step_action_prediction"
              }
            },
            "secondary_analysis": {},
            "overall_ranking": {},
            "paradigm_insights": {
              "fair_comparison_task": "single_step_action_prediction",
              "planning_analysis": "shows_method_specific_strengths",
              "evaluation_approach": "respects_training_paradigms"
            }
          },
          "fairness_report": {
            "evaluation_design": {
              "primary_evaluation": "single_step_fair_comparison",
              "secondary_evaluation": "method_specific_planning_analysis",
              "data_handling": "uses_dataloader_batches_like_training",
              "temporal_structure": "maintained_for_il_model",
              "ground_truth_leakage": "eliminated"
            },
            "method_fairness": {
              "AutoregressiveIL": "evaluated_with_proper_temporal_sequences",
              "WorldModelRL": "evaluated_with_consistent_batch_approach",
              "DirectVideoRL": "evaluated_with_consistent_batch_approach"
            },
            "data_integrity": {
              "temporal_context": "preserved_for_models_that_need_it",
              "batch_structure": "mirrors_training_approach",
              "evaluation_consistency": "matches_model_training_interface"
            },
            "comparison_validity": {
              "single_step_comparison": "valid_and_fair_with_proper_data_handling",
              "planning_comparison": "method_specific_respecting_capabilities",
              "overall_approach": "methodologically_sound_and_consistent_with_training"
            }
          }
        },
        "VID25": {
          "video_id": "VID25",
          "evaluation_type": "comprehensive_fair_evaluation_with_proper_batches",
          "single_step_evaluation": {
            "AutoregressiveIL": {
              "metrics": {
                "mAP": 0.43352436743165096,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "21",
                  "subset_action_sparsity": 0.7765957446808511
                },
                "mAP_standard_with_null_verb": 0.8344974726067655,
                "mAP_present_only_with_null_verb": 0.36345181771833,
                "mAP_freq_weighted_with_null_verb": 0.7203723668746504,
                "mAP_sample_wise_with_null_verb": 0.7904423559920836,
                "mAP_standard_all_actions": 0.8344974726067655,
                "mAP_present_only_all_actions": 0.36345181771833,
                "mAP_freq_weighted_all_actions": 0.7203723668746504,
                "mAP_sample_wise_all_actions": 0.7904423559920836,
                "exact_match_with_null_verb": 0.3410051667449507,
                "hamming_accuracy_with_null_verb": 0.9904931892907468,
                "precision_with_null_verb": 0.9005257693592086,
                "recall_with_null_verb": 0.7782214948337243,
                "f1_with_null_verb": 0.8279616320938149,
                "num_predictions": 2129,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "26",
                "action_sparsity_with_null_verb": 0.74,
                "task": "single_step_action_prediction",
                "method_name": "AutoregressiveIL",
                "exclude_last_n": 6,
                "mAP_standard": 0.8734469331496242,
                "mAP_present_only": 0.43352436743165096,
                "mAP_freq_weighted": 0.7616474595061999,
                "exact_match": 0.3954908407703147,
                "hamming_accuracy": 0.9910506380979983,
                "precision": 0.9008760633049305,
                "recall": 0.7979032327163202,
                "f1": 0.8415292054287533,
                "num_actions_total": 94,
                "num_actions_present": "21",
                "action_sparsity": 0.7765957446808511
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": true
            }
          },
          "planning_evaluation": {
            "AutoregressiveIL": {}
          },
          "summary": {
            "primary_comparison": {
              "AutoregressiveIL": {
                "mAP": 0.43352436743165096,
                "exact_match": 0.3954908407703147,
                "task": "single_step_action_prediction"
              }
            },
            "secondary_analysis": {},
            "overall_ranking": {},
            "paradigm_insights": {
              "fair_comparison_task": "single_step_action_prediction",
              "planning_analysis": "shows_method_specific_strengths",
              "evaluation_approach": "respects_training_paradigms"
            }
          },
          "fairness_report": {
            "evaluation_design": {
              "primary_evaluation": "single_step_fair_comparison",
              "secondary_evaluation": "method_specific_planning_analysis",
              "data_handling": "uses_dataloader_batches_like_training",
              "temporal_structure": "maintained_for_il_model",
              "ground_truth_leakage": "eliminated"
            },
            "method_fairness": {
              "AutoregressiveIL": "evaluated_with_proper_temporal_sequences",
              "WorldModelRL": "evaluated_with_consistent_batch_approach",
              "DirectVideoRL": "evaluated_with_consistent_batch_approach"
            },
            "data_integrity": {
              "temporal_context": "preserved_for_models_that_need_it",
              "batch_structure": "mirrors_training_approach",
              "evaluation_consistency": "matches_model_training_interface"
            },
            "comparison_validity": {
              "single_step_comparison": "valid_and_fair_with_proper_data_handling",
              "planning_comparison": "method_specific_respecting_capabilities",
              "overall_approach": "methodologically_sound_and_consistent_with_training"
            }
          }
        },
        "VID50": {
          "video_id": "VID50",
          "evaluation_type": "comprehensive_fair_evaluation_with_proper_batches",
          "single_step_evaluation": {
            "AutoregressiveIL": {
              "metrics": {
                "mAP": 0.4376436876470856,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "16",
                  "subset_action_sparsity": 0.8297872340425532
                },
                "mAP_standard_with_null_verb": 0.8813807312308906,
                "mAP_present_only_with_null_verb": 0.3965596179493921,
                "mAP_freq_weighted_with_null_verb": 0.7514783998140275,
                "mAP_sample_wise_with_null_verb": 0.789802694357155,
                "mAP_standard_all_actions": 0.8813807312308906,
                "mAP_present_only_all_actions": 0.3965596179493921,
                "mAP_freq_weighted_all_actions": 0.7514783998140275,
                "mAP_sample_wise_all_actions": 0.789802694357155,
                "exact_match_with_null_verb": 0.4835466179159049,
                "hamming_accuracy_with_null_verb": 0.9913893967093236,
                "precision_with_null_verb": 0.8922005114754983,
                "recall_with_null_verb": 0.8230039239983478,
                "f1_with_null_verb": 0.8541294343669336,
                "num_predictions": 1094,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "18",
                "action_sparsity_with_null_verb": 0.8200000000000001,
                "task": "single_step_action_prediction",
                "method_name": "AutoregressiveIL",
                "exclude_last_n": 6,
                "mAP_standard": 0.8936414787484401,
                "mAP_present_only": 0.4376436876470856,
                "mAP_freq_weighted": 0.7892953796992516,
                "exact_match": 0.5155393053016454,
                "hamming_accuracy": 0.9917927574001323,
                "precision": 0.892494324902733,
                "recall": 0.8415931143418824,
                "f1": 0.8652115645348268,
                "num_actions_total": 94,
                "num_actions_present": "16",
                "action_sparsity": 0.8297872340425532
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": true
            }
          },
          "planning_evaluation": {
            "AutoregressiveIL": {}
          },
          "summary": {
            "primary_comparison": {
              "AutoregressiveIL": {
                "mAP": 0.4376436876470856,
                "exact_match": 0.5155393053016454,
                "task": "single_step_action_prediction"
              }
            },
            "secondary_analysis": {},
            "overall_ranking": {},
            "paradigm_insights": {
              "fair_comparison_task": "single_step_action_prediction",
              "planning_analysis": "shows_method_specific_strengths",
              "evaluation_approach": "respects_training_paradigms"
            }
          },
          "fairness_report": {
            "evaluation_design": {
              "primary_evaluation": "single_step_fair_comparison",
              "secondary_evaluation": "method_specific_planning_analysis",
              "data_handling": "uses_dataloader_batches_like_training",
              "temporal_structure": "maintained_for_il_model",
              "ground_truth_leakage": "eliminated"
            },
            "method_fairness": {
              "AutoregressiveIL": "evaluated_with_proper_temporal_sequences",
              "WorldModelRL": "evaluated_with_consistent_batch_approach",
              "DirectVideoRL": "evaluated_with_consistent_batch_approach"
            },
            "data_integrity": {
              "temporal_context": "preserved_for_models_that_need_it",
              "batch_structure": "mirrors_training_approach",
              "evaluation_consistency": "matches_model_training_interface"
            },
            "comparison_validity": {
              "single_step_comparison": "valid_and_fair_with_proper_data_handling",
              "planning_comparison": "method_specific_respecting_capabilities",
              "overall_approach": "methodologically_sound_and_consistent_with_training"
            }
          }
        },
        "VID51": {
          "video_id": "VID51",
          "evaluation_type": "comprehensive_fair_evaluation_with_proper_batches",
          "single_step_evaluation": {
            "AutoregressiveIL": {
              "metrics": {
                "mAP": 0.34669021205461287,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "24",
                  "subset_action_sparsity": 0.7446808510638299
                },
                "mAP_standard_with_null_verb": 0.7958392618804798,
                "mAP_present_only_with_null_verb": 0.29599745476027556,
                "mAP_freq_weighted_with_null_verb": 0.6470683326828233,
                "mAP_sample_wise_with_null_verb": 0.690960848702655,
                "mAP_standard_all_actions": 0.7958392618804798,
                "mAP_present_only_all_actions": 0.29599745476027556,
                "mAP_freq_weighted_all_actions": 0.6470683326828233,
                "mAP_sample_wise_all_actions": 0.690960848702655,
                "exact_match_with_null_verb": 0.32404891304347827,
                "hamming_accuracy_with_null_verb": 0.9896263586956522,
                "precision_with_null_verb": 0.8618163282442515,
                "recall_with_null_verb": 0.7476396886552041,
                "f1_with_null_verb": 0.7936645026584399,
                "num_predictions": 2944,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "29",
                "action_sparsity_with_null_verb": 0.71,
                "task": "single_step_action_prediction",
                "method_name": "AutoregressiveIL",
                "exclude_last_n": 6,
                "mAP_standard": 0.833197500950114,
                "mAP_present_only": 0.34669021205461287,
                "mAP_freq_weighted": 0.7086250188300386,
                "exact_match": 0.406929347826087,
                "hamming_accuracy": 0.9905216524051804,
                "precision": 0.8623558266396882,
                "recall": 0.7741990283367645,
                "f1": 0.811966370422305,
                "num_actions_total": 94,
                "num_actions_present": "24",
                "action_sparsity": 0.7446808510638299
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": true
            }
          },
          "planning_evaluation": {
            "AutoregressiveIL": {}
          },
          "summary": {
            "primary_comparison": {
              "AutoregressiveIL": {
                "mAP": 0.34669021205461287,
                "exact_match": 0.406929347826087,
                "task": "single_step_action_prediction"
              }
            },
            "secondary_analysis": {},
            "overall_ranking": {},
            "paradigm_insights": {
              "fair_comparison_task": "single_step_action_prediction",
              "planning_analysis": "shows_method_specific_strengths",
              "evaluation_approach": "respects_training_paradigms"
            }
          },
          "fairness_report": {
            "evaluation_design": {
              "primary_evaluation": "single_step_fair_comparison",
              "secondary_evaluation": "method_specific_planning_analysis",
              "data_handling": "uses_dataloader_batches_like_training",
              "temporal_structure": "maintained_for_il_model",
              "ground_truth_leakage": "eliminated"
            },
            "method_fairness": {
              "AutoregressiveIL": "evaluated_with_proper_temporal_sequences",
              "WorldModelRL": "evaluated_with_consistent_batch_approach",
              "DirectVideoRL": "evaluated_with_consistent_batch_approach"
            },
            "data_integrity": {
              "temporal_context": "preserved_for_models_that_need_it",
              "batch_structure": "mirrors_training_approach",
              "evaluation_consistency": "matches_model_training_interface"
            },
            "comparison_validity": {
              "single_step_comparison": "valid_and_fair_with_proper_data_handling",
              "planning_comparison": "method_specific_respecting_capabilities",
              "overall_approach": "methodologically_sound_and_consistent_with_training"
            }
          }
        },
        "VID66": {
          "video_id": "VID66",
          "evaluation_type": "comprehensive_fair_evaluation_with_proper_batches",
          "single_step_evaluation": {
            "AutoregressiveIL": {
              "metrics": {
                "mAP": 0.4330585546652433,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "20",
                  "subset_action_sparsity": 0.7872340425531915
                },
                "mAP_standard_with_null_verb": 0.8486673476100391,
                "mAP_present_only_with_null_verb": 0.3855102070001699,
                "mAP_freq_weighted_with_null_verb": 0.7993339594447065,
                "mAP_sample_wise_with_null_verb": 0.838959600363341,
                "mAP_standard_all_actions": 0.8486673476100391,
                "mAP_present_only_all_actions": 0.3855102070001699,
                "mAP_freq_weighted_all_actions": 0.7993339594447065,
                "mAP_sample_wise_all_actions": 0.838959600363341,
                "exact_match_with_null_verb": 0.5071271929824561,
                "hamming_accuracy_with_null_verb": 0.9932894736842105,
                "precision_with_null_verb": 0.9238696080059401,
                "recall_with_null_verb": 0.8474211465898072,
                "f1_with_null_verb": 0.881726443768997,
                "num_predictions": 1824,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "23",
                "action_sparsity_with_null_verb": 0.77,
                "task": "single_step_action_prediction",
                "method_name": "AutoregressiveIL",
                "exclude_last_n": 6,
                "mAP_standard": 0.8687358626947327,
                "mAP_present_only": 0.4330585546652433,
                "mAP_freq_weighted": 0.8230422932975506,
                "exact_match": 0.5175438596491229,
                "hamming_accuracy": 0.9933918906308324,
                "precision": 0.9239812338297084,
                "recall": 0.8586895558853527,
                "f1": 0.8885146364607532,
                "num_actions_total": 94,
                "num_actions_present": "20",
                "action_sparsity": 0.7872340425531915
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": true
            }
          },
          "planning_evaluation": {
            "AutoregressiveIL": {}
          },
          "summary": {
            "primary_comparison": {
              "AutoregressiveIL": {
                "mAP": 0.4330585546652433,
                "exact_match": 0.5175438596491229,
                "task": "single_step_action_prediction"
              }
            },
            "secondary_analysis": {},
            "overall_ranking": {},
            "paradigm_insights": {
              "fair_comparison_task": "single_step_action_prediction",
              "planning_analysis": "shows_method_specific_strengths",
              "evaluation_approach": "respects_training_paradigms"
            }
          },
          "fairness_report": {
            "evaluation_design": {
              "primary_evaluation": "single_step_fair_comparison",
              "secondary_evaluation": "method_specific_planning_analysis",
              "data_handling": "uses_dataloader_batches_like_training",
              "temporal_structure": "maintained_for_il_model",
              "ground_truth_leakage": "eliminated"
            },
            "method_fairness": {
              "AutoregressiveIL": "evaluated_with_proper_temporal_sequences",
              "WorldModelRL": "evaluated_with_consistent_batch_approach",
              "DirectVideoRL": "evaluated_with_consistent_batch_approach"
            },
            "data_integrity": {
              "temporal_context": "preserved_for_models_that_need_it",
              "batch_structure": "mirrors_training_approach",
              "evaluation_consistency": "matches_model_training_interface"
            },
            "comparison_validity": {
              "single_step_comparison": "valid_and_fair_with_proper_data_handling",
              "planning_comparison": "method_specific_respecting_capabilities",
              "overall_approach": "methodologically_sound_and_consistent_with_training"
            }
          }
        },
        "VID79": {
          "video_id": "VID79",
          "evaluation_type": "comprehensive_fair_evaluation_with_proper_batches",
          "single_step_evaluation": {
            "AutoregressiveIL": {
              "metrics": {
                "mAP": 0.2659235740008265,
                "mAP_info": {
                  "calculated_from": "subset_excluding_last_classes_present_actions_only",
                  "excluded_classes": 6,
                  "subset_size": 94,
                  "present_actions_in_subset": "31",
                  "subset_action_sparsity": 0.6702127659574468
                },
                "mAP_standard_with_null_verb": 0.7244062039466153,
                "mAP_present_only_with_null_verb": 0.2344616776294864,
                "mAP_freq_weighted_with_null_verb": 0.7153659375415687,
                "mAP_sample_wise_with_null_verb": 0.7552718053061234,
                "mAP_standard_all_actions": 0.7244062039466153,
                "mAP_present_only_all_actions": 0.2344616776294864,
                "mAP_freq_weighted_all_actions": 0.7153659375415687,
                "mAP_sample_wise_all_actions": 0.7552718053061234,
                "exact_match_with_null_verb": 0.408904510837727,
                "hamming_accuracy_with_null_verb": 0.98993848857645,
                "precision_with_null_verb": 0.8730780441795485,
                "recall_with_null_verb": 0.7925422640474398,
                "f1_with_null_verb": 0.8277501059589067,
                "num_predictions": 3414,
                "num_actions_total_with_null_verb": 100,
                "num_actions_present_with_null_verb": "36",
                "action_sparsity_with_null_verb": 0.64,
                "task": "single_step_action_prediction",
                "method_name": "AutoregressiveIL",
                "exclude_last_n": 6,
                "mAP_standard": 0.7579109658938896,
                "mAP_present_only": 0.2659235740008265,
                "mAP_freq_weighted": 0.7506290070830361,
                "exact_match": 0.4379027533684827,
                "hamming_accuracy": 0.9902155081080407,
                "precision": 0.8733194696426526,
                "recall": 0.8085472512024313,
                "f1": 0.8377356713227502,
                "num_actions_total": 94,
                "num_actions_present": "31",
                "action_sparsity": 0.6702127659574468
              },
              "evaluation_type": "next_action_prediction",
              "used_temporal_context": true
            }
          },
          "planning_evaluation": {
            "AutoregressiveIL": {}
          },
          "summary": {
            "primary_comparison": {
              "AutoregressiveIL": {
                "mAP": 0.2659235740008265,
                "exact_match": 0.4379027533684827,
                "task": "single_step_action_prediction"
              }
            },
            "secondary_analysis": {},
            "overall_ranking": {},
            "paradigm_insights": {
              "fair_comparison_task": "single_step_action_prediction",
              "planning_analysis": "shows_method_specific_strengths",
              "evaluation_approach": "respects_training_paradigms"
            }
          },
          "fairness_report": {
            "evaluation_design": {
              "primary_evaluation": "single_step_fair_comparison",
              "secondary_evaluation": "method_specific_planning_analysis",
              "data_handling": "uses_dataloader_batches_like_training",
              "temporal_structure": "maintained_for_il_model",
              "ground_truth_leakage": "eliminated"
            },
            "method_fairness": {
              "AutoregressiveIL": "evaluated_with_proper_temporal_sequences",
              "WorldModelRL": "evaluated_with_consistent_batch_approach",
              "DirectVideoRL": "evaluated_with_consistent_batch_approach"
            },
            "data_integrity": {
              "temporal_context": "preserved_for_models_that_need_it",
              "batch_structure": "mirrors_training_approach",
              "evaluation_consistency": "matches_model_training_interface"
            },
            "comparison_validity": {
              "single_step_comparison": "valid_and_fair_with_proper_data_handling",
              "planning_comparison": "method_specific_respecting_capabilities",
              "overall_approach": "methodologically_sound_and_consistent_with_training"
            }
          }
        }
      },
      "aggregate_results": {
        "single_step_comparison": {
          "AutoregressiveIL": {
            "mean_mAP": 0.3196433656072625,
            "std_mAP": 0.08344180068976159,
            "mean_exact_match": 0.4415229246818271,
            "std_exact_match": 0.047677877035720954,
            "num_videos": 10,
            "evaluation_type": "single_step_fair_comparison"
          }
        },
        "planning_analysis": {},
        "method_rankings": {
          "single_step_ranking": [
            [
              "AutoregressiveIL",
              0.3196433656072625
            ]
          ],
          "planning_ranking": []
        }
      },
      "statistical_tests": {},
      "evaluation_design": {
        "data_handling": "uses_dataloader_batches_like_training",
        "temporal_structure": "maintained_properly",
        "model_interfaces": "consistent_with_training",
        "primary_evaluation": "single_step_action_prediction_with_proper_context",
        "secondary_evaluation": "multi_step_planning_analysis",
        "fairness_approach": "respects_training_paradigms_and_data_structure"
      },
      "timestamp": "2025-06-26 18:55:06.046648"
    },
    "file_paths": {
      "evaluation": "results/2025-06-26_16-08-06/fold0/integrated_evaluation/evaluation_results.json",
      "fair_comparison": "results/2025-06-26_16-08-06/fold0/integrated_evaluation/fair_single_step_comparison.csv",
      "planning_analysis": "results/2025-06-26_16-08-06/fold0/integrated_evaluation/planning_capability_analysis.csv"
    }
  },
  "generated_plots": {
    "per_video_performance": "results/2025-06-26_16-08-06/fold0/publication_plots/per_video_performance_analysis.png",
    "performance_dashboard": "results/2025-06-26_16-08-06/fold0/publication_plots/performance_dashboard.png"
  }
}